{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "173fb19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c6db16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cda9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "# column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "#                 'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "# raw_dataset = pd.read_csv(url, names=column_names,\n",
    "#                           na_values='?', comment='\\t',\n",
    "#                           sep=' ', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7984e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto-mpg.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6426e1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford mustang gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>vw pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge rampage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford ranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.00</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>chevy s-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement horsepower  weight  acceleration  \\\n",
       "0    18.0          8         307.0      130.0  3504.0          12.0   \n",
       "1    15.0          8         350.0      165.0  3693.0          11.5   \n",
       "2    18.0          8         318.0      150.0  3436.0          11.0   \n",
       "3    16.0          8         304.0      150.0  3433.0          12.0   \n",
       "4    17.0          8         302.0      140.0  3449.0          10.5   \n",
       "..    ...        ...           ...        ...     ...           ...   \n",
       "393  27.0          4         140.0      86.00  2790.0          15.6   \n",
       "394  44.0          4          97.0      52.00  2130.0          24.6   \n",
       "395  32.0          4         135.0      84.00  2295.0          11.6   \n",
       "396  28.0          4         120.0      79.00  2625.0          18.6   \n",
       "397  31.0          4         119.0      82.00  2720.0          19.4   \n",
       "\n",
       "     model_year  origin                   car_name  \n",
       "0            70       1  chevrolet chevelle malibu  \n",
       "1            70       1          buick skylark 320  \n",
       "2            70       1         plymouth satellite  \n",
       "3            70       1              amc rebel sst  \n",
       "4            70       1                ford torino  \n",
       "..          ...     ...                        ...  \n",
       "393          82       1            ford mustang gl  \n",
       "394          82       2                  vw pickup  \n",
       "395          82       1              dodge rampage  \n",
       "396          82       1                ford ranger  \n",
       "397          82       1                 chevy s-10  \n",
       "\n",
       "[398 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 패키지를 가져오기\n",
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정 (파일이 현재 작업 디렉토리에 있는 경우)\n",
    "file_path = \"auto-mpg.data\"\n",
    "\n",
    "# 데이터 파일을 데이터프레임으로 읽어오기\n",
    "# \"auto-mpg.data\" 파일은 공백으로 구분된 데이터이므로 delim_whitespace=True로 설정합니다.\n",
    "# 파일에 헤더(열 이름)가 없으므로 header=None으로 설정합니다.\n",
    "# 각 열에 대한 이름은 나중에 추가할 것입니다.\n",
    "df = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
    "\n",
    "# 열 이름 추가 (데이터에 포함된 열 이름을 사용하거나, 원하는 이름으로 변경할 수 있습니다.)\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name']\n",
    "\n",
    "# 데이터프레임 확인\n",
    "df\n",
    "\n",
    "data = df\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e406a593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.00</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cylinders  displacement horsepower  weight  acceleration  model_year  \\\n",
       "0            8         307.0      130.0  3504.0          12.0          70   \n",
       "1            8         350.0      165.0  3693.0          11.5          70   \n",
       "2            8         318.0      150.0  3436.0          11.0          70   \n",
       "3            8         304.0      150.0  3433.0          12.0          70   \n",
       "4            8         302.0      140.0  3449.0          10.5          70   \n",
       "..         ...           ...        ...     ...           ...         ...   \n",
       "393          4         140.0      86.00  2790.0          15.6          82   \n",
       "394          4          97.0      52.00  2130.0          24.6          82   \n",
       "395          4         135.0      84.00  2295.0          11.6          82   \n",
       "396          4         120.0      79.00  2625.0          18.6          82   \n",
       "397          4         119.0      82.00  2720.0          19.4          82   \n",
       "\n",
       "     origin  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "..      ...  \n",
       "393       1  \n",
       "394       2  \n",
       "395       1  \n",
       "396       1  \n",
       "397       1  \n",
       "\n",
       "[398 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['mpg']\n",
    "x = data[['cylinders','displacement','horsepower','weight','acceleration','model_year','origin']]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1b19fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   displacement  398 non-null    float64\n",
      " 3   horsepower    398 non-null    object \n",
      " 4   weight        398 non-null    float64\n",
      " 5   acceleration  398 non-null    float64\n",
      " 6   model_year    398 non-null    int64  \n",
      " 7   origin        398 non-null    int64  \n",
      " 8   car_name      398 non-null    object \n",
      "dtypes: float64(4), int64(3), object(2)\n",
      "memory usage: 28.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db2e9f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.514573</td>\n",
       "      <td>5.454774</td>\n",
       "      <td>193.425879</td>\n",
       "      <td>2970.424623</td>\n",
       "      <td>15.568090</td>\n",
       "      <td>76.010050</td>\n",
       "      <td>1.572864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.815984</td>\n",
       "      <td>1.701004</td>\n",
       "      <td>104.269838</td>\n",
       "      <td>846.841774</td>\n",
       "      <td>2.757689</td>\n",
       "      <td>3.697627</td>\n",
       "      <td>0.802055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1613.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>104.250000</td>\n",
       "      <td>2223.750000</td>\n",
       "      <td>13.825000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>2803.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>3608.000000</td>\n",
       "      <td>17.175000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>5140.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mpg   cylinders  displacement       weight  acceleration  \\\n",
       "count  398.000000  398.000000    398.000000   398.000000    398.000000   \n",
       "mean    23.514573    5.454774    193.425879  2970.424623     15.568090   \n",
       "std      7.815984    1.701004    104.269838   846.841774      2.757689   \n",
       "min      9.000000    3.000000     68.000000  1613.000000      8.000000   \n",
       "25%     17.500000    4.000000    104.250000  2223.750000     13.825000   \n",
       "50%     23.000000    4.000000    148.500000  2803.500000     15.500000   \n",
       "75%     29.000000    8.000000    262.000000  3608.000000     17.175000   \n",
       "max     46.600000    8.000000    455.000000  5140.000000     24.800000   \n",
       "\n",
       "       model_year      origin  \n",
       "count  398.000000  398.000000  \n",
       "mean    76.010050    1.572864  \n",
       "std      3.697627    0.802055  \n",
       "min     70.000000    1.000000  \n",
       "25%     73.000000    1.000000  \n",
       "50%     76.000000    1.000000  \n",
       "75%     79.000000    2.000000  \n",
       "max     82.000000    3.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "886cf771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   cylinders     398 non-null    int64  \n",
      " 1   displacement  398 non-null    float64\n",
      " 2   horsepower    398 non-null    object \n",
      " 3   weight        398 non-null    float64\n",
      " 4   acceleration  398 non-null    float64\n",
      " 5   model_year    398 non-null    int64  \n",
      " 6   origin        398 non-null    int64  \n",
      "dtypes: float64(3), int64(3), object(1)\n",
      "memory usage: 21.9+ KB\n"
     ]
    }
   ],
   "source": [
    "x.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91a8b94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toyou\\AppData\\Local\\Temp\\ipykernel_10736\\3090085185.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x['origin'] = x['origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n"
     ]
    }
   ],
   "source": [
    "# Origin 이 범주형이여서 바꿔준다.\n",
    "x['origin'] = x['origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adde2130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.00</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cylinders  displacement horsepower  weight  acceleration  model_year  \\\n",
       "0            8         307.0      130.0  3504.0          12.0          70   \n",
       "1            8         350.0      165.0  3693.0          11.5          70   \n",
       "2            8         318.0      150.0  3436.0          11.0          70   \n",
       "3            8         304.0      150.0  3433.0          12.0          70   \n",
       "4            8         302.0      140.0  3449.0          10.5          70   \n",
       "..         ...           ...        ...     ...           ...         ...   \n",
       "393          4         140.0      86.00  2790.0          15.6          82   \n",
       "394          4          97.0      52.00  2130.0          24.6          82   \n",
       "395          4         135.0      84.00  2295.0          11.6          82   \n",
       "396          4         120.0      79.00  2625.0          18.6          82   \n",
       "397          4         119.0      82.00  2720.0          19.4          82   \n",
       "\n",
       "     origin  \n",
       "0       USA  \n",
       "1       USA  \n",
       "2       USA  \n",
       "3       USA  \n",
       "4       USA  \n",
       "..      ...  \n",
       "393     USA  \n",
       "394  Europe  \n",
       "395     USA  \n",
       "396     USA  \n",
       "397     USA  \n",
       "\n",
       "[398 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38f2bbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Japan</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.00</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cylinders  displacement horsepower  weight  acceleration  model_year  \\\n",
       "393          4         140.0      86.00  2790.0          15.6          82   \n",
       "394          4          97.0      52.00  2130.0          24.6          82   \n",
       "395          4         135.0      84.00  2295.0          11.6          82   \n",
       "396          4         120.0      79.00  2625.0          18.6          82   \n",
       "397          4         119.0      82.00  2720.0          19.4          82   \n",
       "\n",
       "     Europe  Japan    USA  \n",
       "393   False  False   True  \n",
       "394    True  False  False  \n",
       "395   False  False   True  \n",
       "396   False  False   True  \n",
       "397   False  False   True  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.get_dummies(x, columns=['origin'], prefix='', prefix_sep='')\n",
    "x.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49ddf946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   cylinders     398 non-null    float64\n",
      " 1   displacement  398 non-null    float64\n",
      " 2   horsepower    398 non-null    float64\n",
      " 3   weight        398 non-null    float64\n",
      " 4   acceleration  398 non-null    float64\n",
      " 5   model_year    398 non-null    float64\n",
      " 6   Europe        398 non-null    float64\n",
      " 7   Japan         398 non-null    float64\n",
      " 8   USA           398 non-null    float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 28.1 KB\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# int 타입 : cylinders model_year origin  \n",
    "# object 타입 : horsepower    \n",
    "\n",
    "# 특정 컬럼을 int 타입에서 float 타입으로 변경하려면\n",
    "x['cylinders'] = x['cylinders'].astype(float)\n",
    "x['model_year'] = x['model_year'].astype(float)\n",
    "x['USA'] = x['USA'].astype(float)\n",
    "x['Europe'] = x['Europe'].astype(float)\n",
    "x['Japan'] = x['Japan'].astype(float)\n",
    "\n",
    "# 특정 컬럼을 object 타입에서 float 타입으로 변경하려면\n",
    "# NaN 값을 가진 행을 삭제\n",
    "# \"horsepower\" 컬럼에서 숫자가 아닌 문자를 빈 문자열(\"\")로 대체하여 숫자만 남기기\n",
    "x['horsepower'] = x['horsepower'].apply(lambda x: re.sub(r'[^0-9]', '', x) if isinstance(x, str) else x)\n",
    "\n",
    "# \"horsepower\" 컬럼의 데이터 타입을 float로 변환\n",
    "x['horsepower'] = pd.to_numeric(x['horsepower'], errors='coerce')\n",
    "\n",
    "# # NaN 값을 가진 행을 삭제 - > y 데이터와 개수가 달라, 삭제 말고, 평균 값을 넣어주는 방식으로 진행\n",
    "# x.dropna(subset=['horsepower'], inplace=True)\n",
    "# NaN 값을 평균 값으로 대체\n",
    "average_horsepower = x['horsepower'].mean()\n",
    "x['horsepower'].fillna(average_horsepower, inplace=True)\n",
    "\n",
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db2d98b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Series name: mpg\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "398 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.2 KB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7307fc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    398.000000\n",
       "mean      23.514573\n",
       "std        7.815984\n",
       "min        9.000000\n",
       "25%       17.500000\n",
       "50%       23.000000\n",
       "75%       29.000000\n",
       "max       46.600000\n",
       "Name: mpg, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e5378e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toyou\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\toyou\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\toyou\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "C:\\Users\\toyou\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\toyou\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\toyou\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "C:\\Users\\toyou\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\toyou\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\toyou\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 620.7498 - mae: 23.6082 - val_loss: 590.4590 - val_mae: 23.1580\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 620.6208 - mae: 23.6072 - val_loss: 590.3636 - val_mae: 23.1577\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 620.4920 - mae: 23.6062 - val_loss: 590.2684 - val_mae: 23.1574\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 620.3632 - mae: 23.6052 - val_loss: 590.1732 - val_mae: 23.1570\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 620.2345 - mae: 23.6042 - val_loss: 590.0782 - val_mae: 23.1567\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 620.1058 - mae: 23.6032 - val_loss: 589.9832 - val_mae: 23.1564\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 619.9774 - mae: 23.6022 - val_loss: 589.8883 - val_mae: 23.1561\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 619.8489 - mae: 23.6012 - val_loss: 589.7936 - val_mae: 23.1558\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 619.7206 - mae: 23.6002 - val_loss: 589.6989 - val_mae: 23.1554\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 619.5923 - mae: 23.5992 - val_loss: 589.6041 - val_mae: 23.1551\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 619.4642 - mae: 23.5982 - val_loss: 589.5096 - val_mae: 23.1548\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 619.3361 - mae: 23.5972 - val_loss: 589.4152 - val_mae: 23.1545\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 619.2081 - mae: 23.5962 - val_loss: 589.3208 - val_mae: 23.1541\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 619.0803 - mae: 23.5952 - val_loss: 589.2266 - val_mae: 23.1538\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 618.9524 - mae: 23.5942 - val_loss: 589.1323 - val_mae: 23.1535\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 618.8248 - mae: 23.5932 - val_loss: 589.0383 - val_mae: 23.1532\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 618.6972 - mae: 23.5922 - val_loss: 588.9443 - val_mae: 23.1528\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 618.5697 - mae: 23.5912 - val_loss: 588.8504 - val_mae: 23.1525\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 618.4423 - mae: 23.5902 - val_loss: 588.7567 - val_mae: 23.1522\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 618.3151 - mae: 23.5892 - val_loss: 588.6629 - val_mae: 23.1519\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 618.1879 - mae: 23.5882 - val_loss: 588.5693 - val_mae: 23.1516\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 618.0608 - mae: 23.5872 - val_loss: 588.4758 - val_mae: 23.1512\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 617.9338 - mae: 23.5862 - val_loss: 588.3824 - val_mae: 23.1509\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 617.8069 - mae: 23.5852 - val_loss: 588.2891 - val_mae: 23.1506\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 617.6802 - mae: 23.5842 - val_loss: 588.1958 - val_mae: 23.1503\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 617.5535 - mae: 23.5832 - val_loss: 588.1027 - val_mae: 23.1499\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 617.4270 - mae: 23.5822 - val_loss: 588.0096 - val_mae: 23.1496\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 617.3005 - mae: 23.5812 - val_loss: 587.9167 - val_mae: 23.1493\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 617.1743 - mae: 23.5802 - val_loss: 587.8239 - val_mae: 23.1490\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 617.0480 - mae: 23.5792 - val_loss: 587.7311 - val_mae: 23.1486\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 616.9219 - mae: 23.5782 - val_loss: 587.6385 - val_mae: 23.1483\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 616.7960 - mae: 23.5772 - val_loss: 587.5461 - val_mae: 23.1480\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 616.6700 - mae: 23.5762 - val_loss: 587.4536 - val_mae: 23.1476\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 616.5443 - mae: 23.5752 - val_loss: 587.3612 - val_mae: 23.1473\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 616.4186 - mae: 23.5742 - val_loss: 587.2690 - val_mae: 23.1470\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 616.2930 - mae: 23.5732 - val_loss: 587.1769 - val_mae: 23.1467\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 616.1677 - mae: 23.5722 - val_loss: 587.0848 - val_mae: 23.1463\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 616.0422 - mae: 23.5712 - val_loss: 586.9929 - val_mae: 23.1460\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 615.9171 - mae: 23.5702 - val_loss: 586.9011 - val_mae: 23.1457\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 615.7919 - mae: 23.5692 - val_loss: 586.8093 - val_mae: 23.1453\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 615.6670 - mae: 23.5682 - val_loss: 586.7177 - val_mae: 23.1450\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 615.5421 - mae: 23.5672 - val_loss: 586.6262 - val_mae: 23.1447\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 615.4173 - mae: 23.5662 - val_loss: 586.5348 - val_mae: 23.1444\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 615.2927 - mae: 23.5652 - val_loss: 586.4434 - val_mae: 23.1440\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 615.1682 - mae: 23.5642 - val_loss: 586.3522 - val_mae: 23.1437\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 615.0437 - mae: 23.5632 - val_loss: 586.2610 - val_mae: 23.1434\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 614.9194 - mae: 23.5622 - val_loss: 586.1699 - val_mae: 23.1430\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 614.7952 - mae: 23.5612 - val_loss: 586.0790 - val_mae: 23.1427\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 614.6711 - mae: 23.5602 - val_loss: 585.9882 - val_mae: 23.1424\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 614.5472 - mae: 23.5592 - val_loss: 585.8975 - val_mae: 23.1420\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 614.4233 - mae: 23.5582 - val_loss: 585.8068 - val_mae: 23.1417\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 614.2996 - mae: 23.5572 - val_loss: 585.7163 - val_mae: 23.1414\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 614.1760 - mae: 23.5562 - val_loss: 585.6259 - val_mae: 23.1410\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 614.0524 - mae: 23.5552 - val_loss: 585.5355 - val_mae: 23.1407\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 613.9291 - mae: 23.5542 - val_loss: 585.4453 - val_mae: 23.1404\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 613.8058 - mae: 23.5532 - val_loss: 585.3552 - val_mae: 23.1400\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 613.6826 - mae: 23.5522 - val_loss: 585.2651 - val_mae: 23.1397\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 613.5595 - mae: 23.5512 - val_loss: 585.1752 - val_mae: 23.1394\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 613.4366 - mae: 23.5502 - val_loss: 585.0853 - val_mae: 23.1390\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 613.3138 - mae: 23.5492 - val_loss: 584.9956 - val_mae: 23.1387\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 613.1911 - mae: 23.5482 - val_loss: 584.9059 - val_mae: 23.1384\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 613.0685 - mae: 23.5472 - val_loss: 584.8165 - val_mae: 23.1380\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 612.9460 - mae: 23.5462 - val_loss: 584.7271 - val_mae: 23.1377\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 612.8237 - mae: 23.5452 - val_loss: 584.6377 - val_mae: 23.1374\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 612.7014 - mae: 23.5442 - val_loss: 584.5485 - val_mae: 23.1370\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 612.5792 - mae: 23.5432 - val_loss: 584.4594 - val_mae: 23.1367\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 612.4572 - mae: 23.5422 - val_loss: 584.3702 - val_mae: 23.1364\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 612.3353 - mae: 23.5412 - val_loss: 584.2814 - val_mae: 23.1360\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 612.2134 - mae: 23.5402 - val_loss: 584.1925 - val_mae: 23.1357\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 612.0919 - mae: 23.5392 - val_loss: 584.1037 - val_mae: 23.1353\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 611.9702 - mae: 23.5382 - val_loss: 584.0151 - val_mae: 23.1350\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 611.8488 - mae: 23.5372 - val_loss: 583.9265 - val_mae: 23.1347\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 611.7274 - mae: 23.5362 - val_loss: 583.8381 - val_mae: 23.1343\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 611.6062 - mae: 23.5352 - val_loss: 583.7497 - val_mae: 23.1340\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 611.4850 - mae: 23.5342 - val_loss: 583.6614 - val_mae: 23.1336\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 611.3641 - mae: 23.5332 - val_loss: 583.5734 - val_mae: 23.1333\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 611.2432 - mae: 23.5322 - val_loss: 583.4852 - val_mae: 23.1330\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 611.1224 - mae: 23.5312 - val_loss: 583.3973 - val_mae: 23.1326\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 611.0017 - mae: 23.5302 - val_loss: 583.3094 - val_mae: 23.1323\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 610.8812 - mae: 23.5292 - val_loss: 583.2217 - val_mae: 23.1319\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 610.7607 - mae: 23.5282 - val_loss: 583.1340 - val_mae: 23.1316\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 610.6404 - mae: 23.5272 - val_loss: 583.0464 - val_mae: 23.1313\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 610.5202 - mae: 23.5262 - val_loss: 582.9590 - val_mae: 23.1309\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 610.4001 - mae: 23.5252 - val_loss: 582.8716 - val_mae: 23.1306\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 610.2801 - mae: 23.5242 - val_loss: 582.7843 - val_mae: 23.1302\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 610.1602 - mae: 23.5232 - val_loss: 582.6971 - val_mae: 23.1299\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 610.0405 - mae: 23.5222 - val_loss: 582.6100 - val_mae: 23.1295\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 609.9208 - mae: 23.5212 - val_loss: 582.5231 - val_mae: 23.1292\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 609.8013 - mae: 23.5202 - val_loss: 582.4362 - val_mae: 23.1289\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 609.6818 - mae: 23.5192 - val_loss: 582.3494 - val_mae: 23.1285\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 609.5624 - mae: 23.5182 - val_loss: 582.2627 - val_mae: 23.1282\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 609.4432 - mae: 23.5172 - val_loss: 582.1761 - val_mae: 23.1278\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 609.3242 - mae: 23.5162 - val_loss: 582.0895 - val_mae: 23.1275\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 609.2052 - mae: 23.5152 - val_loss: 582.0032 - val_mae: 23.1271\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 609.0863 - mae: 23.5142 - val_loss: 581.9169 - val_mae: 23.1268\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 608.9676 - mae: 23.5132 - val_loss: 581.8306 - val_mae: 23.1264\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 608.8489 - mae: 23.5122 - val_loss: 581.7445 - val_mae: 23.1261\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 608.7303 - mae: 23.5112 - val_loss: 581.6585 - val_mae: 23.1257\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 608.6119 - mae: 23.5102 - val_loss: 581.5726 - val_mae: 23.1254\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 608.4936 - mae: 23.5092 - val_loss: 581.4867 - val_mae: 23.1251\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 608.3754 - mae: 23.5082 - val_loss: 581.4010 - val_mae: 23.1247\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 608.2572 - mae: 23.5072 - val_loss: 581.3153 - val_mae: 23.1244\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 608.1393 - mae: 23.5063 - val_loss: 581.2298 - val_mae: 23.1240\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 608.0214 - mae: 23.5053 - val_loss: 581.1443 - val_mae: 23.1237\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 607.9036 - mae: 23.5043 - val_loss: 581.0590 - val_mae: 23.1233\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 607.7859 - mae: 23.5033 - val_loss: 580.9736 - val_mae: 23.1230\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 607.6684 - mae: 23.5023 - val_loss: 580.8885 - val_mae: 23.1226\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 607.5510 - mae: 23.5013 - val_loss: 580.8034 - val_mae: 23.1223\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 607.4336 - mae: 23.5003 - val_loss: 580.7184 - val_mae: 23.1219\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 607.3164 - mae: 23.4993 - val_loss: 580.6335 - val_mae: 23.1216\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 607.1992 - mae: 23.4983 - val_loss: 580.5487 - val_mae: 23.1212\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 607.0823 - mae: 23.4973 - val_loss: 580.4640 - val_mae: 23.1209\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 606.9653 - mae: 23.4963 - val_loss: 580.3794 - val_mae: 23.1205\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 606.8486 - mae: 23.4953 - val_loss: 580.2949 - val_mae: 23.1202\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 606.7319 - mae: 23.4943 - val_loss: 580.2104 - val_mae: 23.1198\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 606.6154 - mae: 23.4933 - val_loss: 580.1261 - val_mae: 23.1194\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 606.4989 - mae: 23.4923 - val_loss: 580.0419 - val_mae: 23.1191\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 606.3825 - mae: 23.4913 - val_loss: 579.9578 - val_mae: 23.1187\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 606.2662 - mae: 23.4903 - val_loss: 579.8737 - val_mae: 23.1184\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 606.1501 - mae: 23.4893 - val_loss: 579.7897 - val_mae: 23.1180\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 606.0341 - mae: 23.4883 - val_loss: 579.7059 - val_mae: 23.1177\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 605.9182 - mae: 23.4873 - val_loss: 579.6222 - val_mae: 23.1173\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 605.8024 - mae: 23.4863 - val_loss: 579.5385 - val_mae: 23.1170\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 605.6867 - mae: 23.4853 - val_loss: 579.4548 - val_mae: 23.1166\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 605.5710 - mae: 23.4843 - val_loss: 579.3713 - val_mae: 23.1163\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 605.4556 - mae: 23.4833 - val_loss: 579.2880 - val_mae: 23.1159\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 605.3402 - mae: 23.4823 - val_loss: 579.2047 - val_mae: 23.1155\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 605.2249 - mae: 23.4813 - val_loss: 579.1214 - val_mae: 23.1152\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 605.1097 - mae: 23.4803 - val_loss: 579.0383 - val_mae: 23.1148\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 604.9946 - mae: 23.4793 - val_loss: 578.9552 - val_mae: 23.1145\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 604.8798 - mae: 23.4783 - val_loss: 578.8723 - val_mae: 23.1141\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 604.7649 - mae: 23.4773 - val_loss: 578.7894 - val_mae: 23.1138\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 604.6501 - mae: 23.4763 - val_loss: 578.7067 - val_mae: 23.1134\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 604.5355 - mae: 23.4753 - val_loss: 578.6240 - val_mae: 23.1130\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 604.4210 - mae: 23.4743 - val_loss: 578.5414 - val_mae: 23.1127\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 604.3066 - mae: 23.4733 - val_loss: 578.4589 - val_mae: 23.1123\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 604.1923 - mae: 23.4723 - val_loss: 578.3765 - val_mae: 23.1120\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 604.0781 - mae: 23.4713 - val_loss: 578.2943 - val_mae: 23.1116\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 603.9640 - mae: 23.4703 - val_loss: 578.2120 - val_mae: 23.1112\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 603.8500 - mae: 23.4693 - val_loss: 578.1299 - val_mae: 23.1109\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 603.7361 - mae: 23.4683 - val_loss: 578.0479 - val_mae: 23.1105\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 603.6224 - mae: 23.4673 - val_loss: 577.9659 - val_mae: 23.1102\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 603.5087 - mae: 23.4663 - val_loss: 577.8841 - val_mae: 23.1098\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 603.3951 - mae: 23.4653 - val_loss: 577.8022 - val_mae: 23.1094\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 603.2816 - mae: 23.4643 - val_loss: 577.7206 - val_mae: 23.1091\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 603.1683 - mae: 23.4633 - val_loss: 577.6390 - val_mae: 23.1087\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 603.0550 - mae: 23.4623 - val_loss: 577.5575 - val_mae: 23.1083\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 602.9419 - mae: 23.4613 - val_loss: 577.4761 - val_mae: 23.1080\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 602.8289 - mae: 23.4604 - val_loss: 577.3947 - val_mae: 23.1076\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 602.7159 - mae: 23.4594 - val_loss: 577.3136 - val_mae: 23.1072\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 602.6031 - mae: 23.4584 - val_loss: 577.2324 - val_mae: 23.1069\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 602.4903 - mae: 23.4574 - val_loss: 577.1513 - val_mae: 23.1065\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 602.3777 - mae: 23.4564 - val_loss: 577.0704 - val_mae: 23.1062\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 602.2652 - mae: 23.4554 - val_loss: 576.9895 - val_mae: 23.1058\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 602.1528 - mae: 23.4544 - val_loss: 576.9088 - val_mae: 23.1054\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 602.0405 - mae: 23.4534 - val_loss: 576.8280 - val_mae: 23.1051\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 601.9283 - mae: 23.4524 - val_loss: 576.7474 - val_mae: 23.1047\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 601.8162 - mae: 23.4514 - val_loss: 576.6669 - val_mae: 23.1043\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 601.7042 - mae: 23.4504 - val_loss: 576.5864 - val_mae: 23.1040\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 601.5922 - mae: 23.4494 - val_loss: 576.5061 - val_mae: 23.1036\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 601.4805 - mae: 23.4484 - val_loss: 576.4259 - val_mae: 23.1032\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 601.3688 - mae: 23.4474 - val_loss: 576.3457 - val_mae: 23.1029\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 601.2573 - mae: 23.4464 - val_loss: 576.2656 - val_mae: 23.1025\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 601.1458 - mae: 23.4454 - val_loss: 576.1857 - val_mae: 23.1021\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 601.0344 - mae: 23.4444 - val_loss: 576.1057 - val_mae: 23.1017\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 600.9231 - mae: 23.4434 - val_loss: 576.0259 - val_mae: 23.1014\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 600.8119 - mae: 23.4424 - val_loss: 575.9461 - val_mae: 23.1010\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 600.7009 - mae: 23.4414 - val_loss: 575.8665 - val_mae: 23.1006\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 600.5899 - mae: 23.4404 - val_loss: 575.7869 - val_mae: 23.1003\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 600.4790 - mae: 23.4394 - val_loss: 575.7075 - val_mae: 23.0999\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 600.3683 - mae: 23.4384 - val_loss: 575.6281 - val_mae: 23.0995\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 600.2577 - mae: 23.4374 - val_loss: 575.5488 - val_mae: 23.0992\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 600.1471 - mae: 23.4364 - val_loss: 575.4696 - val_mae: 23.0988\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 600.0367 - mae: 23.4354 - val_loss: 575.3904 - val_mae: 23.0984\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 599.9263 - mae: 23.4344 - val_loss: 575.3114 - val_mae: 23.0980\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 599.8162 - mae: 23.4334 - val_loss: 575.2325 - val_mae: 23.0977\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 599.7059 - mae: 23.4324 - val_loss: 575.1536 - val_mae: 23.0973\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step - loss: 599.5959 - mae: 23.4314 - val_loss: 575.0748 - val_mae: 23.0969\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 599.4860 - mae: 23.4304 - val_loss: 574.9962 - val_mae: 23.0965\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 599.3762 - mae: 23.4294 - val_loss: 574.9175 - val_mae: 23.0962\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 599.2663 - mae: 23.4284 - val_loss: 574.8390 - val_mae: 23.0958\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 599.1567 - mae: 23.4275 - val_loss: 574.7606 - val_mae: 23.0954\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 599.0472 - mae: 23.4265 - val_loss: 574.6823 - val_mae: 23.0950\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 598.9378 - mae: 23.4255 - val_loss: 574.6039 - val_mae: 23.0947\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 598.8284 - mae: 23.4245 - val_loss: 574.5258 - val_mae: 23.0943\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 598.7192 - mae: 23.4235 - val_loss: 574.4476 - val_mae: 23.0939\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 598.6101 - mae: 23.4225 - val_loss: 574.3696 - val_mae: 23.0935\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 598.5011 - mae: 23.4215 - val_loss: 574.2917 - val_mae: 23.0932\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 598.3922 - mae: 23.4205 - val_loss: 574.2139 - val_mae: 23.0928\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 598.2833 - mae: 23.4195 - val_loss: 574.1361 - val_mae: 23.0924\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 598.1746 - mae: 23.4185 - val_loss: 574.0585 - val_mae: 23.0920\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 598.0660 - mae: 23.4175 - val_loss: 573.9808 - val_mae: 23.0917\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 597.9575 - mae: 23.4165 - val_loss: 573.9034 - val_mae: 23.0913\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 597.8491 - mae: 23.4155 - val_loss: 573.8259 - val_mae: 23.0909\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 597.7407 - mae: 23.4145 - val_loss: 573.7485 - val_mae: 23.0905\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 597.6325 - mae: 23.4135 - val_loss: 573.6713 - val_mae: 23.0901\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 597.5244 - mae: 23.4125 - val_loss: 573.5941 - val_mae: 23.0898\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 597.4164 - mae: 23.4115 - val_loss: 573.5170 - val_mae: 23.0894\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 597.3085 - mae: 23.4105 - val_loss: 573.4401 - val_mae: 23.0890\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 597.2006 - mae: 23.4095 - val_loss: 573.3632 - val_mae: 23.0886\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 597.0929 - mae: 23.4085 - val_loss: 573.2863 - val_mae: 23.0882\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 596.9852 - mae: 23.4075 - val_loss: 573.2096 - val_mae: 23.0879\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 596.8777 - mae: 23.4065 - val_loss: 573.1329 - val_mae: 23.0875\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 596.7703 - mae: 23.4055 - val_loss: 573.0563 - val_mae: 23.0871\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 596.6630 - mae: 23.4045 - val_loss: 572.9798 - val_mae: 23.0867\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 596.5558 - mae: 23.4035 - val_loss: 572.9034 - val_mae: 23.0863\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 596.4487 - mae: 23.4025 - val_loss: 572.8270 - val_mae: 23.0859\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 596.3416 - mae: 23.4015 - val_loss: 572.7508 - val_mae: 23.0856\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 596.2347 - mae: 23.4006 - val_loss: 572.6746 - val_mae: 23.0852\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 596.1279 - mae: 23.3996 - val_loss: 572.5985 - val_mae: 23.0848\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 596.0212 - mae: 23.3986 - val_loss: 572.5225 - val_mae: 23.0844\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 595.9145 - mae: 23.3976 - val_loss: 572.4466 - val_mae: 23.0840\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 595.8079 - mae: 23.3966 - val_loss: 572.3707 - val_mae: 23.0836\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 595.7015 - mae: 23.3956 - val_loss: 572.2950 - val_mae: 23.0833\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 595.5952 - mae: 23.3946 - val_loss: 572.2192 - val_mae: 23.0829\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 595.4889 - mae: 23.3936 - val_loss: 572.1437 - val_mae: 23.0825\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 595.3828 - mae: 23.3926 - val_loss: 572.0682 - val_mae: 23.0821\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 595.2767 - mae: 23.3916 - val_loss: 571.9927 - val_mae: 23.0817\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 595.1708 - mae: 23.3906 - val_loss: 571.9174 - val_mae: 23.0813\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 595.0649 - mae: 23.3896 - val_loss: 571.8420 - val_mae: 23.0809\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 594.9592 - mae: 23.3886 - val_loss: 571.7669 - val_mae: 23.0805\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 594.8535 - mae: 23.3876 - val_loss: 571.6918 - val_mae: 23.0802\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 594.7480 - mae: 23.3866 - val_loss: 571.6167 - val_mae: 23.0798\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 594.6425 - mae: 23.3856 - val_loss: 571.5417 - val_mae: 23.0794\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 594.5372 - mae: 23.3846 - val_loss: 571.4669 - val_mae: 23.0790\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 594.4319 - mae: 23.3836 - val_loss: 571.3920 - val_mae: 23.0786\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 594.3267 - mae: 23.3826 - val_loss: 571.3174 - val_mae: 23.0782\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 594.2217 - mae: 23.3816 - val_loss: 571.2428 - val_mae: 23.0778\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 594.1166 - mae: 23.3806 - val_loss: 571.1682 - val_mae: 23.0774\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 594.0118 - mae: 23.3796 - val_loss: 571.0937 - val_mae: 23.0770\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 593.9070 - mae: 23.3786 - val_loss: 571.0193 - val_mae: 23.0767\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 593.8023 - mae: 23.3776 - val_loss: 570.9450 - val_mae: 23.0763\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 593.6977 - mae: 23.3766 - val_loss: 570.8707 - val_mae: 23.0759\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 593.5932 - mae: 23.3757 - val_loss: 570.7966 - val_mae: 23.0755\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 593.4889 - mae: 23.3747 - val_loss: 570.7225 - val_mae: 23.0751\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 593.3845 - mae: 23.3737 - val_loss: 570.6486 - val_mae: 23.0747\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step - loss: 593.2803 - mae: 23.3727 - val_loss: 570.5746 - val_mae: 23.0743\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 593.1761 - mae: 23.3717 - val_loss: 570.5008 - val_mae: 23.0739\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 593.0722 - mae: 23.3707 - val_loss: 570.4269 - val_mae: 23.0735\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 592.9683 - mae: 23.3697 - val_loss: 570.3533 - val_mae: 23.0731\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 592.8644 - mae: 23.3687 - val_loss: 570.2797 - val_mae: 23.0727\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 592.7607 - mae: 23.3677 - val_loss: 570.2062 - val_mae: 23.0723\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 592.6570 - mae: 23.3667 - val_loss: 570.1327 - val_mae: 23.0719\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 592.5535 - mae: 23.3657 - val_loss: 570.0594 - val_mae: 23.0715\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 592.4500 - mae: 23.3647 - val_loss: 569.9861 - val_mae: 23.0711\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 592.3467 - mae: 23.3637 - val_loss: 569.9128 - val_mae: 23.0707\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 592.2434 - mae: 23.3627 - val_loss: 569.8397 - val_mae: 23.0704\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 592.1403 - mae: 23.3617 - val_loss: 569.7667 - val_mae: 23.0700\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 592.0372 - mae: 23.3607 - val_loss: 569.6937 - val_mae: 23.0696\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 591.9342 - mae: 23.3597 - val_loss: 569.6208 - val_mae: 23.0692\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 591.8314 - mae: 23.3587 - val_loss: 569.5480 - val_mae: 23.0688\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 591.7285 - mae: 23.3577 - val_loss: 569.4752 - val_mae: 23.0684\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 591.6259 - mae: 23.3567 - val_loss: 569.4025 - val_mae: 23.0680\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 591.5233 - mae: 23.3557 - val_loss: 569.3300 - val_mae: 23.0676\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 591.4208 - mae: 23.3547 - val_loss: 569.2574 - val_mae: 23.0672\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 591.3183 - mae: 23.3538 - val_loss: 569.1849 - val_mae: 23.0668\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 591.2161 - mae: 23.3528 - val_loss: 569.1126 - val_mae: 23.0664\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 591.1138 - mae: 23.3518 - val_loss: 569.0403 - val_mae: 23.0660\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 591.0117 - mae: 23.3508 - val_loss: 568.9681 - val_mae: 23.0656\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 590.9097 - mae: 23.3498 - val_loss: 568.8960 - val_mae: 23.0652\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 590.8077 - mae: 23.3488 - val_loss: 568.8239 - val_mae: 23.0648\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 590.7058 - mae: 23.3478 - val_loss: 568.7520 - val_mae: 23.0644\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 590.6041 - mae: 23.3468 - val_loss: 568.6801 - val_mae: 23.0640\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 590.5024 - mae: 23.3458 - val_loss: 568.6082 - val_mae: 23.0636\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 590.4008 - mae: 23.3448 - val_loss: 568.5365 - val_mae: 23.0632\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 590.2993 - mae: 23.3438 - val_loss: 568.4647 - val_mae: 23.0628\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 590.1979 - mae: 23.3428 - val_loss: 568.3932 - val_mae: 23.0624\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 590.0967 - mae: 23.3418 - val_loss: 568.3217 - val_mae: 23.0619\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 589.9955 - mae: 23.3408 - val_loss: 568.2502 - val_mae: 23.0615\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 589.8943 - mae: 23.3398 - val_loss: 568.1788 - val_mae: 23.0611\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 589.7934 - mae: 23.3388 - val_loss: 568.1075 - val_mae: 23.0607\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 589.6924 - mae: 23.3378 - val_loss: 568.0363 - val_mae: 23.0603\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 589.5916 - mae: 23.3368 - val_loss: 567.9651 - val_mae: 23.0599\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 589.4908 - mae: 23.3358 - val_loss: 567.8941 - val_mae: 23.0595\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 589.3902 - mae: 23.3348 - val_loss: 567.8231 - val_mae: 23.0591\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 589.2897 - mae: 23.3339 - val_loss: 567.7521 - val_mae: 23.0587\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 589.1891 - mae: 23.3329 - val_loss: 567.6813 - val_mae: 23.0583\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 589.0888 - mae: 23.3319 - val_loss: 567.6105 - val_mae: 23.0579\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 588.9885 - mae: 23.3309 - val_loss: 567.5398 - val_mae: 23.0575\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 588.8883 - mae: 23.3299 - val_loss: 567.4691 - val_mae: 23.0571\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 588.7881 - mae: 23.3289 - val_loss: 567.3986 - val_mae: 23.0567\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 588.6882 - mae: 23.3279 - val_loss: 567.3281 - val_mae: 23.0563\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 588.5883 - mae: 23.3269 - val_loss: 567.2577 - val_mae: 23.0559\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 588.4884 - mae: 23.3259 - val_loss: 567.1874 - val_mae: 23.0554\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 588.3887 - mae: 23.3249 - val_loss: 567.1171 - val_mae: 23.0550\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 588.2890 - mae: 23.3239 - val_loss: 567.0470 - val_mae: 23.0546\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 588.1894 - mae: 23.3229 - val_loss: 566.9769 - val_mae: 23.0542\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 588.0900 - mae: 23.3219 - val_loss: 566.9068 - val_mae: 23.0538\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 587.9905 - mae: 23.3209 - val_loss: 566.8368 - val_mae: 23.0534\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 587.8914 - mae: 23.3199 - val_loss: 566.7669 - val_mae: 23.0530\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 587.7921 - mae: 23.3189 - val_loss: 566.6971 - val_mae: 23.0526\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 587.6931 - mae: 23.3179 - val_loss: 566.6273 - val_mae: 23.0522\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 587.5940 - mae: 23.3169 - val_loss: 566.5577 - val_mae: 23.0517\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 587.4951 - mae: 23.3160 - val_loss: 566.4881 - val_mae: 23.0513\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 587.3962 - mae: 23.3150 - val_loss: 566.4185 - val_mae: 23.0509\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step - loss: 587.2975 - mae: 23.3140 - val_loss: 566.3491 - val_mae: 23.0505\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 587.1988 - mae: 23.3130 - val_loss: 566.2797 - val_mae: 23.0501\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 587.1002 - mae: 23.3120 - val_loss: 566.2103 - val_mae: 23.0497\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 587.0017 - mae: 23.3110 - val_loss: 566.1411 - val_mae: 23.0493\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 586.9034 - mae: 23.3100 - val_loss: 566.0719 - val_mae: 23.0489\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 586.8051 - mae: 23.3090 - val_loss: 566.0028 - val_mae: 23.0484\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 586.7069 - mae: 23.3080 - val_loss: 565.9338 - val_mae: 23.0480\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 586.6087 - mae: 23.3070 - val_loss: 565.8649 - val_mae: 23.0476\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 586.5107 - mae: 23.3060 - val_loss: 565.7960 - val_mae: 23.0472\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 586.4127 - mae: 23.3050 - val_loss: 565.7271 - val_mae: 23.0468\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 586.3149 - mae: 23.3040 - val_loss: 565.6584 - val_mae: 23.0464\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 586.2171 - mae: 23.3030 - val_loss: 565.5897 - val_mae: 23.0459\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 586.1194 - mae: 23.3020 - val_loss: 565.5211 - val_mae: 23.0455\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 586.0218 - mae: 23.3010 - val_loss: 565.4526 - val_mae: 23.0451\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 585.9243 - mae: 23.3000 - val_loss: 565.3842 - val_mae: 23.0447\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 585.8268 - mae: 23.2990 - val_loss: 565.3157 - val_mae: 23.0443\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 585.7295 - mae: 23.2981 - val_loss: 565.2474 - val_mae: 23.0439\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 585.6323 - mae: 23.2971 - val_loss: 565.1791 - val_mae: 23.0434\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 585.5352 - mae: 23.2961 - val_loss: 565.1110 - val_mae: 23.0430\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 585.4380 - mae: 23.2951 - val_loss: 565.0428 - val_mae: 23.0426\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 585.3411 - mae: 23.2941 - val_loss: 564.9748 - val_mae: 23.0422\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 585.2442 - mae: 23.2931 - val_loss: 564.9069 - val_mae: 23.0418\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 585.1473 - mae: 23.2921 - val_loss: 564.8390 - val_mae: 23.0413\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 585.0507 - mae: 23.2911 - val_loss: 564.7711 - val_mae: 23.0409\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 584.9540 - mae: 23.2901 - val_loss: 564.7034 - val_mae: 23.0405\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 584.8575 - mae: 23.2891 - val_loss: 564.6357 - val_mae: 23.0401\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 584.7610 - mae: 23.2881 - val_loss: 564.5681 - val_mae: 23.0396\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 584.6647 - mae: 23.2871 - val_loss: 564.5005 - val_mae: 23.0392\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 584.5683 - mae: 23.2861 - val_loss: 564.4330 - val_mae: 23.0388\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 584.4722 - mae: 23.2851 - val_loss: 564.3656 - val_mae: 23.0384\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 584.3761 - mae: 23.2841 - val_loss: 564.2982 - val_mae: 23.0380\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 584.2800 - mae: 23.2831 - val_loss: 564.2310 - val_mae: 23.0375\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 584.1841 - mae: 23.2822 - val_loss: 564.1638 - val_mae: 23.0371\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 584.0881 - mae: 23.2812 - val_loss: 564.0966 - val_mae: 23.0367\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 583.9924 - mae: 23.2802 - val_loss: 564.0296 - val_mae: 23.0363\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 583.8968 - mae: 23.2792 - val_loss: 563.9626 - val_mae: 23.0358\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 583.8011 - mae: 23.2782 - val_loss: 563.8956 - val_mae: 23.0354\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 583.7056 - mae: 23.2772 - val_loss: 563.8287 - val_mae: 23.0350\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 583.6102 - mae: 23.2762 - val_loss: 563.7620 - val_mae: 23.0346\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 583.5148 - mae: 23.2752 - val_loss: 563.6953 - val_mae: 23.0341\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 583.4196 - mae: 23.2742 - val_loss: 563.6285 - val_mae: 23.0337\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 583.3245 - mae: 23.2732 - val_loss: 563.5620 - val_mae: 23.0333\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 583.2293 - mae: 23.2722 - val_loss: 563.4955 - val_mae: 23.0329\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 583.1343 - mae: 23.2712 - val_loss: 563.4290 - val_mae: 23.0324\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 583.0394 - mae: 23.2702 - val_loss: 563.3626 - val_mae: 23.0320\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 582.9446 - mae: 23.2692 - val_loss: 563.2963 - val_mae: 23.0316\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 582.8499 - mae: 23.2682 - val_loss: 563.2300 - val_mae: 23.0311\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 582.7552 - mae: 23.2672 - val_loss: 563.1639 - val_mae: 23.0307\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 582.6606 - mae: 23.2663 - val_loss: 563.0977 - val_mae: 23.0303\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 582.5661 - mae: 23.2653 - val_loss: 563.0316 - val_mae: 23.0299\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 582.4717 - mae: 23.2643 - val_loss: 562.9656 - val_mae: 23.0294\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 582.3774 - mae: 23.2633 - val_loss: 562.8997 - val_mae: 23.0290\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 582.2831 - mae: 23.2623 - val_loss: 562.8339 - val_mae: 23.0286\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 582.1890 - mae: 23.2613 - val_loss: 562.7681 - val_mae: 23.0281\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 582.0949 - mae: 23.2603 - val_loss: 562.7023 - val_mae: 23.0277\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 582.0009 - mae: 23.2593 - val_loss: 562.6367 - val_mae: 23.0273\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 581.9070 - mae: 23.2583 - val_loss: 562.5711 - val_mae: 23.0268\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 581.8132 - mae: 23.2573 - val_loss: 562.5056 - val_mae: 23.0264\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 581.7194 - mae: 23.2563 - val_loss: 562.4401 - val_mae: 23.0260\n",
      "Epoch 355/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step - loss: 581.6258 - mae: 23.2553 - val_loss: 562.3747 - val_mae: 23.0255\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 581.5322 - mae: 23.2543 - val_loss: 562.3094 - val_mae: 23.0251\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 581.4387 - mae: 23.2533 - val_loss: 562.2441 - val_mae: 23.0247\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 581.3453 - mae: 23.2523 - val_loss: 562.1789 - val_mae: 23.0242\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 581.2520 - mae: 23.2514 - val_loss: 562.1138 - val_mae: 23.0238\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 581.1588 - mae: 23.2504 - val_loss: 562.0487 - val_mae: 23.0234\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 581.0656 - mae: 23.2494 - val_loss: 561.9837 - val_mae: 23.0229\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 580.9725 - mae: 23.2484 - val_loss: 561.9188 - val_mae: 23.0225\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 580.8796 - mae: 23.2474 - val_loss: 561.8539 - val_mae: 23.0220\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 580.7867 - mae: 23.2464 - val_loss: 561.7891 - val_mae: 23.0216\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 580.6937 - mae: 23.2454 - val_loss: 561.7243 - val_mae: 23.0212\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 580.6010 - mae: 23.2444 - val_loss: 561.6597 - val_mae: 23.0207\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 580.5084 - mae: 23.2434 - val_loss: 561.5950 - val_mae: 23.0203\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 580.4158 - mae: 23.2424 - val_loss: 561.5305 - val_mae: 23.0199\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 580.3234 - mae: 23.2414 - val_loss: 561.4660 - val_mae: 23.0194\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 580.2308 - mae: 23.2404 - val_loss: 561.4016 - val_mae: 23.0190\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 580.1385 - mae: 23.2394 - val_loss: 561.3372 - val_mae: 23.0185\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 580.0463 - mae: 23.2384 - val_loss: 561.2729 - val_mae: 23.0181\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 579.9542 - mae: 23.2374 - val_loss: 561.2086 - val_mae: 23.0177\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 579.8621 - mae: 23.2365 - val_loss: 561.1445 - val_mae: 23.0172\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 579.7700 - mae: 23.2355 - val_loss: 561.0804 - val_mae: 23.0168\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 579.6781 - mae: 23.2345 - val_loss: 561.0164 - val_mae: 23.0163\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 579.5862 - mae: 23.2335 - val_loss: 560.9524 - val_mae: 23.0159\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 579.4945 - mae: 23.2325 - val_loss: 560.8885 - val_mae: 23.0155\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 579.4028 - mae: 23.2315 - val_loss: 560.8246 - val_mae: 23.0150\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 579.3112 - mae: 23.2305 - val_loss: 560.7609 - val_mae: 23.0146\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 579.2197 - mae: 23.2295 - val_loss: 560.6971 - val_mae: 23.0141\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 579.1282 - mae: 23.2285 - val_loss: 560.6334 - val_mae: 23.0137\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 579.0369 - mae: 23.2275 - val_loss: 560.5698 - val_mae: 23.0133\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 578.9456 - mae: 23.2265 - val_loss: 560.5062 - val_mae: 23.0128\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 578.8544 - mae: 23.2255 - val_loss: 560.4427 - val_mae: 23.0124\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 578.7632 - mae: 23.2245 - val_loss: 560.3794 - val_mae: 23.0119\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 578.6722 - mae: 23.2235 - val_loss: 560.3160 - val_mae: 23.0115\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 578.5813 - mae: 23.2226 - val_loss: 560.2528 - val_mae: 23.0110\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 578.4904 - mae: 23.2216 - val_loss: 560.1895 - val_mae: 23.0106\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 578.3996 - mae: 23.2206 - val_loss: 560.1263 - val_mae: 23.0101\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 578.3089 - mae: 23.2196 - val_loss: 560.0633 - val_mae: 23.0097\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 578.2182 - mae: 23.2186 - val_loss: 560.0002 - val_mae: 23.0093\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 578.1276 - mae: 23.2176 - val_loss: 559.9373 - val_mae: 23.0088\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 578.0372 - mae: 23.2166 - val_loss: 559.8743 - val_mae: 23.0084\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 577.9468 - mae: 23.2156 - val_loss: 559.8114 - val_mae: 23.0079\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 577.8565 - mae: 23.2146 - val_loss: 559.7487 - val_mae: 23.0075\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 577.7662 - mae: 23.2136 - val_loss: 559.6859 - val_mae: 23.0070\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 577.6760 - mae: 23.2126 - val_loss: 559.6232 - val_mae: 23.0066\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 577.5860 - mae: 23.2116 - val_loss: 559.5607 - val_mae: 23.0061\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 577.4959 - mae: 23.2106 - val_loss: 559.4980 - val_mae: 23.0057\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 577.4061 - mae: 23.2097 - val_loss: 559.4357 - val_mae: 23.0052\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 577.3162 - mae: 23.2087 - val_loss: 559.3732 - val_mae: 23.0048\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 577.2264 - mae: 23.2077 - val_loss: 559.3107 - val_mae: 23.0043\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 577.1367 - mae: 23.2067 - val_loss: 559.2484 - val_mae: 23.0039\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 577.0471 - mae: 23.2057 - val_loss: 559.1862 - val_mae: 23.0034\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 576.9575 - mae: 23.2047 - val_loss: 559.1240 - val_mae: 23.0030\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 576.8680 - mae: 23.2037 - val_loss: 559.0619 - val_mae: 23.0025\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 576.7787 - mae: 23.2027 - val_loss: 558.9998 - val_mae: 23.0021\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 576.6894 - mae: 23.2017 - val_loss: 558.9378 - val_mae: 23.0016\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 576.6002 - mae: 23.2007 - val_loss: 558.8759 - val_mae: 23.0012\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 576.5110 - mae: 23.1997 - val_loss: 558.8140 - val_mae: 23.0007\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 576.4220 - mae: 23.1987 - val_loss: 558.7521 - val_mae: 23.0002\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 576.3329 - mae: 23.1977 - val_loss: 558.6903 - val_mae: 22.9998\n",
      "Epoch 414/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step - loss: 576.2441 - mae: 23.1968 - val_loss: 558.6287 - val_mae: 22.9993\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 576.1552 - mae: 23.1958 - val_loss: 558.5670 - val_mae: 22.9989\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 576.0665 - mae: 23.1948 - val_loss: 558.5054 - val_mae: 22.9984\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 575.9778 - mae: 23.1938 - val_loss: 558.4438 - val_mae: 22.9980\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 575.8892 - mae: 23.1928 - val_loss: 558.3823 - val_mae: 22.9975\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 575.8007 - mae: 23.1918 - val_loss: 558.3209 - val_mae: 22.9971\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 575.7122 - mae: 23.1908 - val_loss: 558.2596 - val_mae: 22.9966\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 575.6238 - mae: 23.1898 - val_loss: 558.1982 - val_mae: 22.9962\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 575.5355 - mae: 23.1888 - val_loss: 558.1370 - val_mae: 22.9957\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 575.4473 - mae: 23.1878 - val_loss: 558.0759 - val_mae: 22.9952\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 575.3593 - mae: 23.1868 - val_loss: 558.0148 - val_mae: 22.9948\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 575.2711 - mae: 23.1858 - val_loss: 557.9537 - val_mae: 22.9943\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 575.1831 - mae: 23.1848 - val_loss: 557.8926 - val_mae: 22.9939\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 575.0952 - mae: 23.1839 - val_loss: 557.8317 - val_mae: 22.9934\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 575.0073 - mae: 23.1829 - val_loss: 557.7708 - val_mae: 22.9930\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 574.9196 - mae: 23.1819 - val_loss: 557.7100 - val_mae: 22.9925\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 574.8319 - mae: 23.1809 - val_loss: 557.6492 - val_mae: 22.9920\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 574.7443 - mae: 23.1799 - val_loss: 557.5885 - val_mae: 22.9916\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 574.6567 - mae: 23.1789 - val_loss: 557.5278 - val_mae: 22.9911\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 574.5693 - mae: 23.1779 - val_loss: 557.4672 - val_mae: 22.9907\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 574.4819 - mae: 23.1769 - val_loss: 557.4066 - val_mae: 22.9902\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 574.3946 - mae: 23.1759 - val_loss: 557.3461 - val_mae: 22.9897\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 574.3074 - mae: 23.1749 - val_loss: 557.2857 - val_mae: 22.9893\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 574.2202 - mae: 23.1739 - val_loss: 557.2253 - val_mae: 22.9888\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 574.1332 - mae: 23.1729 - val_loss: 557.1649 - val_mae: 22.9883\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 574.0460 - mae: 23.1720 - val_loss: 557.1047 - val_mae: 22.9879\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 573.9592 - mae: 23.1710 - val_loss: 557.0446 - val_mae: 22.9874\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 573.8723 - mae: 23.1700 - val_loss: 556.9844 - val_mae: 22.9870\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 573.7856 - mae: 23.1690 - val_loss: 556.9243 - val_mae: 22.9865\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 573.6987 - mae: 23.1680 - val_loss: 556.8642 - val_mae: 22.9860\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 573.6122 - mae: 23.1670 - val_loss: 556.8043 - val_mae: 22.9856\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 573.5256 - mae: 23.1660 - val_loss: 556.7443 - val_mae: 22.9851\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 573.4391 - mae: 23.1650 - val_loss: 556.6844 - val_mae: 22.9846\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 573.3527 - mae: 23.1640 - val_loss: 556.6246 - val_mae: 22.9842\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 573.2664 - mae: 23.1630 - val_loss: 556.5648 - val_mae: 22.9837\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 573.1801 - mae: 23.1620 - val_loss: 556.5052 - val_mae: 22.9832\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 573.0939 - mae: 23.1610 - val_loss: 556.4454 - val_mae: 22.9828\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 573.0079 - mae: 23.1601 - val_loss: 556.3859 - val_mae: 22.9823\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 572.9218 - mae: 23.1591 - val_loss: 556.3264 - val_mae: 22.9818\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 572.8358 - mae: 23.1581 - val_loss: 556.2669 - val_mae: 22.9814\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 572.7499 - mae: 23.1571 - val_loss: 556.2075 - val_mae: 22.9809\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 572.6641 - mae: 23.1561 - val_loss: 556.1481 - val_mae: 22.9804\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 572.5783 - mae: 23.1551 - val_loss: 556.0887 - val_mae: 22.9800\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 572.4927 - mae: 23.1541 - val_loss: 556.0295 - val_mae: 22.9795\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 572.4070 - mae: 23.1531 - val_loss: 555.9702 - val_mae: 22.9790\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 572.3216 - mae: 23.1521 - val_loss: 555.9111 - val_mae: 22.9785\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 572.2361 - mae: 23.1511 - val_loss: 555.8520 - val_mae: 22.9781\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 572.1508 - mae: 23.1501 - val_loss: 555.7930 - val_mae: 22.9776\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 572.0654 - mae: 23.1491 - val_loss: 555.7340 - val_mae: 22.9771\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 571.9801 - mae: 23.1482 - val_loss: 555.6750 - val_mae: 22.9767\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 571.8950 - mae: 23.1472 - val_loss: 555.6161 - val_mae: 22.9762\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 571.8099 - mae: 23.1462 - val_loss: 555.5573 - val_mae: 22.9757\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 571.7249 - mae: 23.1452 - val_loss: 555.4985 - val_mae: 22.9753\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 571.6400 - mae: 23.1442 - val_loss: 555.4398 - val_mae: 22.9748\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 571.5551 - mae: 23.1432 - val_loss: 555.3812 - val_mae: 22.9743\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 571.4703 - mae: 23.1422 - val_loss: 555.3226 - val_mae: 22.9738\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 571.3856 - mae: 23.1412 - val_loss: 555.2640 - val_mae: 22.9734\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 571.3009 - mae: 23.1402 - val_loss: 555.2054 - val_mae: 22.9729\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 571.2163 - mae: 23.1392 - val_loss: 555.1470 - val_mae: 22.9724\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step - loss: 571.1318 - mae: 23.1382 - val_loss: 555.0886 - val_mae: 22.9719\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 571.0472 - mae: 23.1373 - val_loss: 555.0303 - val_mae: 22.9715\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 570.9629 - mae: 23.1363 - val_loss: 554.9720 - val_mae: 22.9710\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 570.8787 - mae: 23.1353 - val_loss: 554.9137 - val_mae: 22.9705\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 570.7944 - mae: 23.1343 - val_loss: 554.8555 - val_mae: 22.9700\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 570.7103 - mae: 23.1333 - val_loss: 554.7974 - val_mae: 22.9696\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 570.6262 - mae: 23.1323 - val_loss: 554.7393 - val_mae: 22.9691\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 570.5421 - mae: 23.1313 - val_loss: 554.6813 - val_mae: 22.9686\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 570.4581 - mae: 23.1303 - val_loss: 554.6233 - val_mae: 22.9681\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 570.3744 - mae: 23.1293 - val_loss: 554.5654 - val_mae: 22.9676\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 570.2905 - mae: 23.1283 - val_loss: 554.5074 - val_mae: 22.9672\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 570.2068 - mae: 23.1273 - val_loss: 554.4496 - val_mae: 22.9667\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 570.1231 - mae: 23.1264 - val_loss: 554.3919 - val_mae: 22.9662\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 570.0395 - mae: 23.1254 - val_loss: 554.3342 - val_mae: 22.9657\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 569.9561 - mae: 23.1244 - val_loss: 554.2765 - val_mae: 22.9653\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 569.8726 - mae: 23.1234 - val_loss: 554.2189 - val_mae: 22.9648\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 569.7892 - mae: 23.1224 - val_loss: 554.1613 - val_mae: 22.9643\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 569.7059 - mae: 23.1214 - val_loss: 554.1038 - val_mae: 22.9638\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 569.6226 - mae: 23.1204 - val_loss: 554.0463 - val_mae: 22.9633\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 569.5394 - mae: 23.1194 - val_loss: 553.9890 - val_mae: 22.9628\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 569.4564 - mae: 23.1184 - val_loss: 553.9315 - val_mae: 22.9624\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 569.3734 - mae: 23.1174 - val_loss: 553.8742 - val_mae: 22.9619\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 569.2903 - mae: 23.1164 - val_loss: 553.8170 - val_mae: 22.9614\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 569.2075 - mae: 23.1155 - val_loss: 553.7598 - val_mae: 22.9609\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 569.1246 - mae: 23.1145 - val_loss: 553.7026 - val_mae: 22.9604\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 569.0419 - mae: 23.1135 - val_loss: 553.6455 - val_mae: 22.9599\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 568.9592 - mae: 23.1125 - val_loss: 553.5884 - val_mae: 22.9595\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 568.8766 - mae: 23.1115 - val_loss: 553.5314 - val_mae: 22.9590\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 568.7941 - mae: 23.1105 - val_loss: 553.4745 - val_mae: 22.9585\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 568.7115 - mae: 23.1095 - val_loss: 553.4176 - val_mae: 22.9580\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 568.6292 - mae: 23.1085 - val_loss: 553.3607 - val_mae: 22.9575\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 568.5468 - mae: 23.1075 - val_loss: 553.3039 - val_mae: 22.9570\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 568.4646 - mae: 23.1065 - val_loss: 553.2472 - val_mae: 22.9566\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 568.3824 - mae: 23.1055 - val_loss: 553.1905 - val_mae: 22.9561\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 568.3002 - mae: 23.1046 - val_loss: 553.1339 - val_mae: 22.9556\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 568.2181 - mae: 23.1036 - val_loss: 553.0772 - val_mae: 22.9551\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 568.1362 - mae: 23.1026 - val_loss: 553.0206 - val_mae: 22.9546\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 568.0542 - mae: 23.1016 - val_loss: 552.9642 - val_mae: 22.9541\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 567.9724 - mae: 23.1006 - val_loss: 552.9077 - val_mae: 22.9536\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 567.8906 - mae: 23.0996 - val_loss: 552.8513 - val_mae: 22.9531\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 567.8089 - mae: 23.0986 - val_loss: 552.7949 - val_mae: 22.9526\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 567.7272 - mae: 23.0976 - val_loss: 552.7386 - val_mae: 22.9522\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 567.6456 - mae: 23.0966 - val_loss: 552.6823 - val_mae: 22.9517\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 567.5641 - mae: 23.0956 - val_loss: 552.6261 - val_mae: 22.9512\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 567.4826 - mae: 23.0947 - val_loss: 552.5700 - val_mae: 22.9507\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 567.4013 - mae: 23.0937 - val_loss: 552.5139 - val_mae: 22.9502\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 567.3199 - mae: 23.0927 - val_loss: 552.4578 - val_mae: 22.9497\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 567.2387 - mae: 23.0917 - val_loss: 552.4017 - val_mae: 22.9492\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 567.1575 - mae: 23.0907 - val_loss: 552.3458 - val_mae: 22.9487\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 567.0764 - mae: 23.0897 - val_loss: 552.2899 - val_mae: 22.9482\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 566.9954 - mae: 23.0887 - val_loss: 552.2340 - val_mae: 22.9477\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 566.9144 - mae: 23.0877 - val_loss: 552.1782 - val_mae: 22.9472\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 566.8334 - mae: 23.0867 - val_loss: 552.1224 - val_mae: 22.9468\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 566.7526 - mae: 23.0857 - val_loss: 552.0667 - val_mae: 22.9463\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 566.6718 - mae: 23.0848 - val_loss: 552.0110 - val_mae: 22.9458\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 566.5911 - mae: 23.0838 - val_loss: 551.9554 - val_mae: 22.9453\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 566.5104 - mae: 23.0828 - val_loss: 551.8998 - val_mae: 22.9448\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 566.4298 - mae: 23.0818 - val_loss: 551.8442 - val_mae: 22.9443\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 566.3494 - mae: 23.0808 - val_loss: 551.7887 - val_mae: 22.9438\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step - loss: 566.2689 - mae: 23.0798 - val_loss: 551.7333 - val_mae: 22.9433\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 566.1884 - mae: 23.0788 - val_loss: 551.6779 - val_mae: 22.9428\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 566.1082 - mae: 23.0778 - val_loss: 551.6226 - val_mae: 22.9423\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 566.0278 - mae: 23.0768 - val_loss: 551.5673 - val_mae: 22.9418\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 565.9478 - mae: 23.0758 - val_loss: 551.5120 - val_mae: 22.9413\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 565.8676 - mae: 23.0749 - val_loss: 551.4568 - val_mae: 22.9408\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 565.7876 - mae: 23.0739 - val_loss: 551.4016 - val_mae: 22.9403\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 565.7076 - mae: 23.0729 - val_loss: 551.3465 - val_mae: 22.9398\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 565.6277 - mae: 23.0719 - val_loss: 551.2914 - val_mae: 22.9393\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 565.5478 - mae: 23.0709 - val_loss: 551.2365 - val_mae: 22.9388\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 565.4680 - mae: 23.0699 - val_loss: 551.1815 - val_mae: 22.9383\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 565.3882 - mae: 23.0689 - val_loss: 551.1265 - val_mae: 22.9378\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 565.3087 - mae: 23.0679 - val_loss: 551.0716 - val_mae: 22.9373\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 565.2290 - mae: 23.0669 - val_loss: 551.0168 - val_mae: 22.9368\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 565.1495 - mae: 23.0659 - val_loss: 550.9620 - val_mae: 22.9363\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 565.0700 - mae: 23.0650 - val_loss: 550.9072 - val_mae: 22.9358\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 564.9906 - mae: 23.0640 - val_loss: 550.8525 - val_mae: 22.9353\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 564.9113 - mae: 23.0630 - val_loss: 550.7979 - val_mae: 22.9348\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 564.8320 - mae: 23.0620 - val_loss: 550.7433 - val_mae: 22.9343\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 564.7527 - mae: 23.0610 - val_loss: 550.6887 - val_mae: 22.9338\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 564.6736 - mae: 23.0600 - val_loss: 550.6342 - val_mae: 22.9333\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 564.5946 - mae: 23.0590 - val_loss: 550.5797 - val_mae: 22.9328\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 564.5155 - mae: 23.0580 - val_loss: 550.5253 - val_mae: 22.9323\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 564.4366 - mae: 23.0570 - val_loss: 550.4709 - val_mae: 22.9318\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 564.3577 - mae: 23.0560 - val_loss: 550.4166 - val_mae: 22.9313\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 564.2789 - mae: 23.0551 - val_loss: 550.3623 - val_mae: 22.9308\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 564.2001 - mae: 23.0541 - val_loss: 550.3080 - val_mae: 22.9303\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 564.1214 - mae: 23.0531 - val_loss: 550.2538 - val_mae: 22.9298\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 564.0427 - mae: 23.0521 - val_loss: 550.1997 - val_mae: 22.9293\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 563.9643 - mae: 23.0511 - val_loss: 550.1455 - val_mae: 22.9288\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 563.8857 - mae: 23.0501 - val_loss: 550.0915 - val_mae: 22.9282\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 563.8073 - mae: 23.0491 - val_loss: 550.0375 - val_mae: 22.9277\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 563.7289 - mae: 23.0481 - val_loss: 549.9835 - val_mae: 22.9272\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 563.6506 - mae: 23.0471 - val_loss: 549.9296 - val_mae: 22.9267\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 563.5723 - mae: 23.0461 - val_loss: 549.8756 - val_mae: 22.9262\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 563.4941 - mae: 23.0452 - val_loss: 549.8218 - val_mae: 22.9257\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 563.4160 - mae: 23.0442 - val_loss: 549.7680 - val_mae: 22.9252\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 563.3380 - mae: 23.0432 - val_loss: 549.7142 - val_mae: 22.9247\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 563.2599 - mae: 23.0422 - val_loss: 549.6605 - val_mae: 22.9242\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 563.1820 - mae: 23.0412 - val_loss: 549.6068 - val_mae: 22.9237\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 563.1041 - mae: 23.0402 - val_loss: 549.5532 - val_mae: 22.9232\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 563.0263 - mae: 23.0392 - val_loss: 549.4996 - val_mae: 22.9226\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 562.9486 - mae: 23.0382 - val_loss: 549.4461 - val_mae: 22.9221\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 562.8709 - mae: 23.0372 - val_loss: 549.3926 - val_mae: 22.9216\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 562.7933 - mae: 23.0363 - val_loss: 549.3392 - val_mae: 22.9211\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 562.7156 - mae: 23.0353 - val_loss: 549.2858 - val_mae: 22.9206\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 562.6382 - mae: 23.0343 - val_loss: 549.2324 - val_mae: 22.9201\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 562.5607 - mae: 23.0333 - val_loss: 549.1790 - val_mae: 22.9196\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 562.4833 - mae: 23.0323 - val_loss: 549.1257 - val_mae: 22.9191\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 562.4060 - mae: 23.0313 - val_loss: 549.0724 - val_mae: 22.9186\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 562.3287 - mae: 23.0303 - val_loss: 549.0193 - val_mae: 22.9180\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 562.2516 - mae: 23.0293 - val_loss: 548.9661 - val_mae: 22.9175\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 562.1745 - mae: 23.0283 - val_loss: 548.9130 - val_mae: 22.9170\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 562.0974 - mae: 23.0274 - val_loss: 548.8600 - val_mae: 22.9165\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 562.0204 - mae: 23.0264 - val_loss: 548.8069 - val_mae: 22.9160\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 561.9434 - mae: 23.0254 - val_loss: 548.7539 - val_mae: 22.9155\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 561.8666 - mae: 23.0244 - val_loss: 548.7010 - val_mae: 22.9149\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 561.7897 - mae: 23.0234 - val_loss: 548.6481 - val_mae: 22.9144\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 561.7130 - mae: 23.0224 - val_loss: 548.5952 - val_mae: 22.9139\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step - loss: 561.6364 - mae: 23.0214 - val_loss: 548.5424 - val_mae: 22.9134\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 561.5596 - mae: 23.0204 - val_loss: 548.4896 - val_mae: 22.9129\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 561.4831 - mae: 23.0194 - val_loss: 548.4369 - val_mae: 22.9124\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 561.4066 - mae: 23.0184 - val_loss: 548.3842 - val_mae: 22.9118\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 561.3300 - mae: 23.0175 - val_loss: 548.3315 - val_mae: 22.9113\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 561.2537 - mae: 23.0165 - val_loss: 548.2789 - val_mae: 22.9108\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 561.1774 - mae: 23.0155 - val_loss: 548.2264 - val_mae: 22.9103\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 561.1011 - mae: 23.0145 - val_loss: 548.1738 - val_mae: 22.9098\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 561.0248 - mae: 23.0135 - val_loss: 548.1213 - val_mae: 22.9092\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 560.9487 - mae: 23.0125 - val_loss: 548.0688 - val_mae: 22.9087\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 560.8726 - mae: 23.0115 - val_loss: 548.0165 - val_mae: 22.9082\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 560.7966 - mae: 23.0105 - val_loss: 547.9641 - val_mae: 22.9077\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 560.7206 - mae: 23.0095 - val_loss: 547.9117 - val_mae: 22.9072\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 560.6447 - mae: 23.0086 - val_loss: 547.8595 - val_mae: 22.9066\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 560.5688 - mae: 23.0076 - val_loss: 547.8073 - val_mae: 22.9061\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 560.4930 - mae: 23.0066 - val_loss: 547.7550 - val_mae: 22.9056\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 560.4172 - mae: 23.0056 - val_loss: 547.7029 - val_mae: 22.9051\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 560.3416 - mae: 23.0046 - val_loss: 547.6507 - val_mae: 22.9045\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 560.2660 - mae: 23.0036 - val_loss: 547.5986 - val_mae: 22.9040\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 560.1904 - mae: 23.0026 - val_loss: 547.5466 - val_mae: 22.9035\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 560.1149 - mae: 23.0016 - val_loss: 547.4946 - val_mae: 22.9030\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 560.0394 - mae: 23.0007 - val_loss: 547.4427 - val_mae: 22.9025\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 559.9641 - mae: 22.9997 - val_loss: 547.3907 - val_mae: 22.9019\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 559.8887 - mae: 22.9987 - val_loss: 547.3388 - val_mae: 22.9014\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 559.8135 - mae: 22.9977 - val_loss: 547.2870 - val_mae: 22.9009\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 559.7383 - mae: 22.9967 - val_loss: 547.2352 - val_mae: 22.9004\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 559.6631 - mae: 22.9957 - val_loss: 547.1834 - val_mae: 22.8998\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 559.5881 - mae: 22.9947 - val_loss: 547.1317 - val_mae: 22.8993\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 559.5131 - mae: 22.9937 - val_loss: 547.0800 - val_mae: 22.8988\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 559.4380 - mae: 22.9927 - val_loss: 547.0283 - val_mae: 22.8982\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 559.3632 - mae: 22.9918 - val_loss: 546.9767 - val_mae: 22.8977\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 559.2883 - mae: 22.9908 - val_loss: 546.9252 - val_mae: 22.8972\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 559.2135 - mae: 22.9898 - val_loss: 546.8737 - val_mae: 22.8967\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 559.1387 - mae: 22.9888 - val_loss: 546.8221 - val_mae: 22.8961\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 559.0641 - mae: 22.9878 - val_loss: 546.7707 - val_mae: 22.8956\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 558.9894 - mae: 22.9868 - val_loss: 546.7192 - val_mae: 22.8951\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 558.9149 - mae: 22.9858 - val_loss: 546.6678 - val_mae: 22.8945\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 558.8403 - mae: 22.9848 - val_loss: 546.6165 - val_mae: 22.8940\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 558.7659 - mae: 22.9838 - val_loss: 546.5652 - val_mae: 22.8935\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 558.6915 - mae: 22.9829 - val_loss: 546.5140 - val_mae: 22.8929\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 558.6171 - mae: 22.9819 - val_loss: 546.4628 - val_mae: 22.8924\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 558.5428 - mae: 22.9809 - val_loss: 546.4116 - val_mae: 22.8919\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 558.4687 - mae: 22.9799 - val_loss: 546.3605 - val_mae: 22.8913\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 558.3945 - mae: 22.9789 - val_loss: 546.3093 - val_mae: 22.8908\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 558.3204 - mae: 22.9779 - val_loss: 546.2582 - val_mae: 22.8903\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 558.2463 - mae: 22.9769 - val_loss: 546.2072 - val_mae: 22.8897\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 558.1724 - mae: 22.9759 - val_loss: 546.1562 - val_mae: 22.8892\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 558.0984 - mae: 22.9750 - val_loss: 546.1053 - val_mae: 22.8887\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 558.0245 - mae: 22.9740 - val_loss: 546.0543 - val_mae: 22.8881\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 557.9507 - mae: 22.9730 - val_loss: 546.0035 - val_mae: 22.8876\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 557.8770 - mae: 22.9720 - val_loss: 545.9526 - val_mae: 22.8871\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 557.8032 - mae: 22.9710 - val_loss: 545.9019 - val_mae: 22.8865\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 557.7296 - mae: 22.9700 - val_loss: 545.8511 - val_mae: 22.8860\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 557.6560 - mae: 22.9690 - val_loss: 545.8003 - val_mae: 22.8855\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 557.5825 - mae: 22.9680 - val_loss: 545.7496 - val_mae: 22.8849\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 557.5090 - mae: 22.9670 - val_loss: 545.6989 - val_mae: 22.8844\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 557.4355 - mae: 22.9661 - val_loss: 545.6483 - val_mae: 22.8839\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 557.3622 - mae: 22.9651 - val_loss: 545.5978 - val_mae: 22.8833\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 557.2889 - mae: 22.9641 - val_loss: 545.5472 - val_mae: 22.8828\n",
      "Epoch 650/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 557.2156 - mae: 22.9631 - val_loss: 545.4967 - val_mae: 22.8822\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 557.1425 - mae: 22.9621 - val_loss: 545.4462 - val_mae: 22.8817\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 557.0693 - mae: 22.9611 - val_loss: 545.3958 - val_mae: 22.8812\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 556.9962 - mae: 22.9601 - val_loss: 545.3453 - val_mae: 22.8806\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 556.9232 - mae: 22.9591 - val_loss: 545.2950 - val_mae: 22.8801\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 556.8502 - mae: 22.9582 - val_loss: 545.2446 - val_mae: 22.8795\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 556.7773 - mae: 22.9572 - val_loss: 545.1943 - val_mae: 22.8790\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 556.7044 - mae: 22.9562 - val_loss: 545.1441 - val_mae: 22.8785\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 556.6315 - mae: 22.9552 - val_loss: 545.0939 - val_mae: 22.8779\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 556.5588 - mae: 22.9542 - val_loss: 545.0436 - val_mae: 22.8774\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 556.4861 - mae: 22.9532 - val_loss: 544.9935 - val_mae: 22.8768\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 556.4135 - mae: 22.9522 - val_loss: 544.9434 - val_mae: 22.8763\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 556.3409 - mae: 22.9512 - val_loss: 544.8934 - val_mae: 22.8758\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 556.2684 - mae: 22.9503 - val_loss: 544.8433 - val_mae: 22.8752\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 556.1959 - mae: 22.9493 - val_loss: 544.7933 - val_mae: 22.8747\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 556.1234 - mae: 22.9483 - val_loss: 544.7433 - val_mae: 22.8741\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 556.0510 - mae: 22.9473 - val_loss: 544.6934 - val_mae: 22.8736\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 555.9786 - mae: 22.9463 - val_loss: 544.6434 - val_mae: 22.8730\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 555.9064 - mae: 22.9453 - val_loss: 544.5936 - val_mae: 22.8725\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 555.8343 - mae: 22.9443 - val_loss: 544.5438 - val_mae: 22.8719\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 555.7621 - mae: 22.9433 - val_loss: 544.4940 - val_mae: 22.8714\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 555.6899 - mae: 22.9424 - val_loss: 544.4442 - val_mae: 22.8709\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 555.6179 - mae: 22.9414 - val_loss: 544.3945 - val_mae: 22.8703\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 555.5460 - mae: 22.9404 - val_loss: 544.3448 - val_mae: 22.8698\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 555.4739 - mae: 22.9394 - val_loss: 544.2950 - val_mae: 22.8692\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 555.4021 - mae: 22.9384 - val_loss: 544.2455 - val_mae: 22.8687\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 555.3303 - mae: 22.9374 - val_loss: 544.1959 - val_mae: 22.8681\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 555.2585 - mae: 22.9364 - val_loss: 544.1464 - val_mae: 22.8676\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 555.1868 - mae: 22.9354 - val_loss: 544.0968 - val_mae: 22.8670\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 555.1151 - mae: 22.9344 - val_loss: 544.0473 - val_mae: 22.8665\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 555.0435 - mae: 22.9335 - val_loss: 543.9979 - val_mae: 22.8659\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 554.9719 - mae: 22.9325 - val_loss: 543.9484 - val_mae: 22.8654\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 554.9003 - mae: 22.9315 - val_loss: 543.8990 - val_mae: 22.8648\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 554.8290 - mae: 22.9305 - val_loss: 543.8497 - val_mae: 22.8643\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 554.7575 - mae: 22.9295 - val_loss: 543.8004 - val_mae: 22.8637\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 554.6862 - mae: 22.9285 - val_loss: 543.7511 - val_mae: 22.8632\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 554.6148 - mae: 22.9275 - val_loss: 543.7018 - val_mae: 22.8626\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 554.5436 - mae: 22.9265 - val_loss: 543.6526 - val_mae: 22.8621\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 554.4724 - mae: 22.9256 - val_loss: 543.6034 - val_mae: 22.8615\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 554.4013 - mae: 22.9246 - val_loss: 543.5543 - val_mae: 22.8610\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 554.3303 - mae: 22.9236 - val_loss: 543.5052 - val_mae: 22.8604\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 554.2592 - mae: 22.9226 - val_loss: 543.4561 - val_mae: 22.8599\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 554.1881 - mae: 22.9216 - val_loss: 543.4070 - val_mae: 22.8593\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 554.1172 - mae: 22.9206 - val_loss: 543.3580 - val_mae: 22.8587\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 554.0464 - mae: 22.9196 - val_loss: 543.3090 - val_mae: 22.8582\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 553.9755 - mae: 22.9187 - val_loss: 543.2601 - val_mae: 22.8576\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 553.9047 - mae: 22.9177 - val_loss: 543.2111 - val_mae: 22.8571\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 553.8340 - mae: 22.9167 - val_loss: 543.1622 - val_mae: 22.8565\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 553.7634 - mae: 22.9157 - val_loss: 543.1134 - val_mae: 22.8560\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 553.6928 - mae: 22.9147 - val_loss: 543.0646 - val_mae: 22.8554\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 553.6222 - mae: 22.9137 - val_loss: 543.0158 - val_mae: 22.8549\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 553.5517 - mae: 22.9127 - val_loss: 542.9670 - val_mae: 22.8543\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 553.4812 - mae: 22.9117 - val_loss: 542.9183 - val_mae: 22.8537\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 553.4108 - mae: 22.9108 - val_loss: 542.8696 - val_mae: 22.8532\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 553.3405 - mae: 22.9098 - val_loss: 542.8210 - val_mae: 22.8526\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 553.2701 - mae: 22.9088 - val_loss: 542.7723 - val_mae: 22.8521\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 553.2000 - mae: 22.9078 - val_loss: 542.7238 - val_mae: 22.8515\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 553.1297 - mae: 22.9068 - val_loss: 542.6752 - val_mae: 22.8509\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 553.0595 - mae: 22.9058 - val_loss: 542.6266 - val_mae: 22.8504\n",
      "Epoch 709/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step - loss: 552.9894 - mae: 22.9048 - val_loss: 542.5782 - val_mae: 22.8498\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 552.9194 - mae: 22.9038 - val_loss: 542.5297 - val_mae: 22.8493\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 552.8494 - mae: 22.9029 - val_loss: 542.4813 - val_mae: 22.8487\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 552.7794 - mae: 22.9019 - val_loss: 542.4328 - val_mae: 22.8481\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 552.7095 - mae: 22.9009 - val_loss: 542.3845 - val_mae: 22.8476\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 552.6397 - mae: 22.8999 - val_loss: 542.3361 - val_mae: 22.8470\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 552.5699 - mae: 22.8989 - val_loss: 542.2878 - val_mae: 22.8465\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 552.5001 - mae: 22.8979 - val_loss: 542.2395 - val_mae: 22.8459\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 552.4305 - mae: 22.8969 - val_loss: 542.1913 - val_mae: 22.8453\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 552.3608 - mae: 22.8960 - val_loss: 542.1430 - val_mae: 22.8448\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 552.2912 - mae: 22.8950 - val_loss: 542.0948 - val_mae: 22.8442\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 552.2217 - mae: 22.8940 - val_loss: 542.0467 - val_mae: 22.8436\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 552.1522 - mae: 22.8930 - val_loss: 541.9985 - val_mae: 22.8431\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 552.0828 - mae: 22.8920 - val_loss: 541.9505 - val_mae: 22.8425\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 552.0133 - mae: 22.8910 - val_loss: 541.9025 - val_mae: 22.8419\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 551.9440 - mae: 22.8900 - val_loss: 541.8544 - val_mae: 22.8414\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 551.8748 - mae: 22.8890 - val_loss: 541.8063 - val_mae: 22.8408\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 551.8055 - mae: 22.8881 - val_loss: 541.7584 - val_mae: 22.8403\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 551.7363 - mae: 22.8871 - val_loss: 541.7104 - val_mae: 22.8397\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 551.6672 - mae: 22.8861 - val_loss: 541.6625 - val_mae: 22.8391\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 551.5980 - mae: 22.8851 - val_loss: 541.6146 - val_mae: 22.8385\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 551.5290 - mae: 22.8841 - val_loss: 541.5668 - val_mae: 22.8380\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 551.4600 - mae: 22.8831 - val_loss: 541.5189 - val_mae: 22.8374\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 551.3911 - mae: 22.8821 - val_loss: 541.4712 - val_mae: 22.8368\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 551.3221 - mae: 22.8811 - val_loss: 541.4235 - val_mae: 22.8363\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 551.2533 - mae: 22.8802 - val_loss: 541.3757 - val_mae: 22.8357\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 551.1846 - mae: 22.8792 - val_loss: 541.3280 - val_mae: 22.8351\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 551.1157 - mae: 22.8782 - val_loss: 541.2803 - val_mae: 22.8346\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 551.0471 - mae: 22.8772 - val_loss: 541.2326 - val_mae: 22.8340\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 550.9784 - mae: 22.8762 - val_loss: 541.1851 - val_mae: 22.8334\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 550.9098 - mae: 22.8752 - val_loss: 541.1375 - val_mae: 22.8329\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 550.8412 - mae: 22.8742 - val_loss: 541.0900 - val_mae: 22.8323\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 550.7727 - mae: 22.8733 - val_loss: 541.0424 - val_mae: 22.8317\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 550.7043 - mae: 22.8723 - val_loss: 540.9949 - val_mae: 22.8311\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 550.6358 - mae: 22.8713 - val_loss: 540.9474 - val_mae: 22.8306\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 550.5676 - mae: 22.8703 - val_loss: 540.9000 - val_mae: 22.8300\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 550.4991 - mae: 22.8693 - val_loss: 540.8527 - val_mae: 22.8294\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 550.4309 - mae: 22.8683 - val_loss: 540.8052 - val_mae: 22.8288\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 550.3627 - mae: 22.8673 - val_loss: 540.7579 - val_mae: 22.8283\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 550.2947 - mae: 22.8664 - val_loss: 540.7106 - val_mae: 22.8277\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 550.2264 - mae: 22.8654 - val_loss: 540.6632 - val_mae: 22.8271\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 550.1584 - mae: 22.8644 - val_loss: 540.6159 - val_mae: 22.8265\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 550.0903 - mae: 22.8634 - val_loss: 540.5687 - val_mae: 22.8260\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 550.0224 - mae: 22.8624 - val_loss: 540.5215 - val_mae: 22.8254\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 549.9545 - mae: 22.8614 - val_loss: 540.4743 - val_mae: 22.8248\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 549.8866 - mae: 22.8604 - val_loss: 540.4271 - val_mae: 22.8242\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 549.8188 - mae: 22.8594 - val_loss: 540.3801 - val_mae: 22.8237\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 549.7510 - mae: 22.8585 - val_loss: 540.3329 - val_mae: 22.8231\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 549.6833 - mae: 22.8575 - val_loss: 540.2859 - val_mae: 22.8225\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 549.6155 - mae: 22.8565 - val_loss: 540.2389 - val_mae: 22.8219\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 549.5479 - mae: 22.8555 - val_loss: 540.1918 - val_mae: 22.8214\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 549.4803 - mae: 22.8545 - val_loss: 540.1449 - val_mae: 22.8208\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 549.4128 - mae: 22.8535 - val_loss: 540.0980 - val_mae: 22.8202\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 549.3453 - mae: 22.8525 - val_loss: 540.0510 - val_mae: 22.8196\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 549.2778 - mae: 22.8516 - val_loss: 540.0040 - val_mae: 22.8190\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 549.2104 - mae: 22.8506 - val_loss: 539.9572 - val_mae: 22.8185\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 549.1430 - mae: 22.8496 - val_loss: 539.9103 - val_mae: 22.8179\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 549.0757 - mae: 22.8486 - val_loss: 539.8635 - val_mae: 22.8173\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 549.0085 - mae: 22.8476 - val_loss: 539.8168 - val_mae: 22.8167\n",
      "Epoch 768/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step - loss: 548.9413 - mae: 22.8466 - val_loss: 539.7700 - val_mae: 22.8161\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 548.8741 - mae: 22.8456 - val_loss: 539.7233 - val_mae: 22.8156\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 548.8070 - mae: 22.8447 - val_loss: 539.6766 - val_mae: 22.8150\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 548.7399 - mae: 22.8437 - val_loss: 539.6299 - val_mae: 22.8144\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 548.6729 - mae: 22.8427 - val_loss: 539.5832 - val_mae: 22.8138\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 548.6059 - mae: 22.8417 - val_loss: 539.5365 - val_mae: 22.8132\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 548.5389 - mae: 22.8407 - val_loss: 539.4899 - val_mae: 22.8126\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 548.4720 - mae: 22.8397 - val_loss: 539.4434 - val_mae: 22.8121\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 548.4052 - mae: 22.8387 - val_loss: 539.3969 - val_mae: 22.8115\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 548.3384 - mae: 22.8378 - val_loss: 539.3503 - val_mae: 22.8109\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 548.2717 - mae: 22.8368 - val_loss: 539.3038 - val_mae: 22.8103\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 548.2050 - mae: 22.8358 - val_loss: 539.2574 - val_mae: 22.8097\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 548.1382 - mae: 22.8348 - val_loss: 539.2109 - val_mae: 22.8091\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 548.0717 - mae: 22.8338 - val_loss: 539.1645 - val_mae: 22.8085\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 548.0051 - mae: 22.8328 - val_loss: 539.1181 - val_mae: 22.8080\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 547.9385 - mae: 22.8318 - val_loss: 539.0717 - val_mae: 22.8074\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 547.8721 - mae: 22.8309 - val_loss: 539.0254 - val_mae: 22.8068\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 547.8056 - mae: 22.8299 - val_loss: 538.9791 - val_mae: 22.8062\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 547.7393 - mae: 22.8289 - val_loss: 538.9328 - val_mae: 22.8056\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 547.6730 - mae: 22.8279 - val_loss: 538.8865 - val_mae: 22.8050\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 547.6066 - mae: 22.8269 - val_loss: 538.8403 - val_mae: 22.8044\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 547.5404 - mae: 22.8259 - val_loss: 538.7941 - val_mae: 22.8038\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 547.4742 - mae: 22.8249 - val_loss: 538.7479 - val_mae: 22.8033\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 547.4080 - mae: 22.8239 - val_loss: 538.7018 - val_mae: 22.8027\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 547.3419 - mae: 22.8230 - val_loss: 538.6556 - val_mae: 22.8021\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 547.2758 - mae: 22.8220 - val_loss: 538.6095 - val_mae: 22.8015\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 547.2098 - mae: 22.8210 - val_loss: 538.5635 - val_mae: 22.8009\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 547.1438 - mae: 22.8200 - val_loss: 538.5175 - val_mae: 22.8003\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 547.0779 - mae: 22.8190 - val_loss: 538.4714 - val_mae: 22.7997\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 547.0120 - mae: 22.8180 - val_loss: 538.4254 - val_mae: 22.7991\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 546.9461 - mae: 22.8171 - val_loss: 538.3794 - val_mae: 22.7985\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 546.8803 - mae: 22.8161 - val_loss: 538.3334 - val_mae: 22.7979\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 546.8146 - mae: 22.8151 - val_loss: 538.2875 - val_mae: 22.7973\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 546.7488 - mae: 22.8141 - val_loss: 538.2416 - val_mae: 22.7967\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 546.6832 - mae: 22.8131 - val_loss: 538.1957 - val_mae: 22.7961\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 546.6175 - mae: 22.8121 - val_loss: 538.1498 - val_mae: 22.7956\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 546.5519 - mae: 22.8111 - val_loss: 538.1040 - val_mae: 22.7950\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 546.4864 - mae: 22.8102 - val_loss: 538.0582 - val_mae: 22.7944\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 546.4210 - mae: 22.8092 - val_loss: 538.0125 - val_mae: 22.7938\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 546.3555 - mae: 22.8082 - val_loss: 537.9667 - val_mae: 22.7932\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 546.2901 - mae: 22.8072 - val_loss: 537.9210 - val_mae: 22.7926\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 546.2247 - mae: 22.8062 - val_loss: 537.8752 - val_mae: 22.7920\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 546.1594 - mae: 22.8052 - val_loss: 537.8296 - val_mae: 22.7914\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 546.0941 - mae: 22.8042 - val_loss: 537.7839 - val_mae: 22.7908\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 546.0289 - mae: 22.8033 - val_loss: 537.7383 - val_mae: 22.7902\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 545.9637 - mae: 22.8023 - val_loss: 537.6927 - val_mae: 22.7896\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 545.8986 - mae: 22.8013 - val_loss: 537.6471 - val_mae: 22.7890\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 545.8334 - mae: 22.8003 - val_loss: 537.6016 - val_mae: 22.7884\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 545.7684 - mae: 22.7993 - val_loss: 537.5560 - val_mae: 22.7878\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 545.7033 - mae: 22.7983 - val_loss: 537.5104 - val_mae: 22.7872\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 545.6384 - mae: 22.7973 - val_loss: 537.4650 - val_mae: 22.7866\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 545.5735 - mae: 22.7964 - val_loss: 537.4196 - val_mae: 22.7860\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 545.5086 - mae: 22.7954 - val_loss: 537.3741 - val_mae: 22.7854\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 545.4437 - mae: 22.7944 - val_loss: 537.3286 - val_mae: 22.7848\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 545.3789 - mae: 22.7934 - val_loss: 537.2832 - val_mae: 22.7842\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 545.3141 - mae: 22.7924 - val_loss: 537.2379 - val_mae: 22.7836\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 545.2495 - mae: 22.7914 - val_loss: 537.1925 - val_mae: 22.7830\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 545.1848 - mae: 22.7905 - val_loss: 537.1472 - val_mae: 22.7824\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 545.1201 - mae: 22.7895 - val_loss: 537.1019 - val_mae: 22.7818\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step - loss: 545.0555 - mae: 22.7885 - val_loss: 537.0566 - val_mae: 22.7812\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 544.9910 - mae: 22.7875 - val_loss: 537.0114 - val_mae: 22.7806\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 544.9265 - mae: 22.7865 - val_loss: 536.9661 - val_mae: 22.7800\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 544.8620 - mae: 22.7855 - val_loss: 536.9209 - val_mae: 22.7794\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 544.7976 - mae: 22.7845 - val_loss: 536.8757 - val_mae: 22.7788\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 544.7332 - mae: 22.7836 - val_loss: 536.8306 - val_mae: 22.7782\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 544.6689 - mae: 22.7826 - val_loss: 536.7855 - val_mae: 22.7776\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 544.6046 - mae: 22.7816 - val_loss: 536.7403 - val_mae: 22.7769\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 544.5403 - mae: 22.7806 - val_loss: 536.6952 - val_mae: 22.7763\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 544.4762 - mae: 22.7796 - val_loss: 536.6501 - val_mae: 22.7757\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 544.4120 - mae: 22.7786 - val_loss: 536.6051 - val_mae: 22.7751\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 544.3478 - mae: 22.7776 - val_loss: 536.5600 - val_mae: 22.7745\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 544.2838 - mae: 22.7767 - val_loss: 536.5150 - val_mae: 22.7739\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 544.2197 - mae: 22.7757 - val_loss: 536.4700 - val_mae: 22.7733\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 544.1557 - mae: 22.7747 - val_loss: 536.4251 - val_mae: 22.7727\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 544.0919 - mae: 22.7737 - val_loss: 536.3802 - val_mae: 22.7721\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 544.0278 - mae: 22.7727 - val_loss: 536.3353 - val_mae: 22.7715\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 543.9639 - mae: 22.7717 - val_loss: 536.2903 - val_mae: 22.7709\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 543.9001 - mae: 22.7708 - val_loss: 536.2454 - val_mae: 22.7703\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 543.8364 - mae: 22.7698 - val_loss: 536.2006 - val_mae: 22.7696\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 543.7726 - mae: 22.7688 - val_loss: 536.1557 - val_mae: 22.7690\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 543.7089 - mae: 22.7678 - val_loss: 536.1110 - val_mae: 22.7684\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 543.6452 - mae: 22.7668 - val_loss: 536.0661 - val_mae: 22.7678\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 543.5815 - mae: 22.7658 - val_loss: 536.0214 - val_mae: 22.7672\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 543.5180 - mae: 22.7648 - val_loss: 535.9766 - val_mae: 22.7666\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 543.4544 - mae: 22.7639 - val_loss: 535.9319 - val_mae: 22.7660\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 543.3910 - mae: 22.7629 - val_loss: 535.8872 - val_mae: 22.7654\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 543.3275 - mae: 22.7619 - val_loss: 535.8425 - val_mae: 22.7648\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 543.2640 - mae: 22.7609 - val_loss: 535.7979 - val_mae: 22.7641\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 543.2006 - mae: 22.7599 - val_loss: 535.7532 - val_mae: 22.7635\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 543.1373 - mae: 22.7589 - val_loss: 535.7086 - val_mae: 22.7629\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 543.0740 - mae: 22.7579 - val_loss: 535.6640 - val_mae: 22.7623\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 543.0107 - mae: 22.7570 - val_loss: 535.6194 - val_mae: 22.7617\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 542.9475 - mae: 22.7560 - val_loss: 535.5749 - val_mae: 22.7611\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 542.8843 - mae: 22.7550 - val_loss: 535.5304 - val_mae: 22.7605\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 542.8212 - mae: 22.7540 - val_loss: 535.4858 - val_mae: 22.7598\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 542.7581 - mae: 22.7530 - val_loss: 535.4413 - val_mae: 22.7592\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 542.6950 - mae: 22.7520 - val_loss: 535.3969 - val_mae: 22.7586\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 542.6320 - mae: 22.7511 - val_loss: 535.3524 - val_mae: 22.7580\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 542.5690 - mae: 22.7501 - val_loss: 535.3080 - val_mae: 22.7574\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 542.5061 - mae: 22.7491 - val_loss: 535.2635 - val_mae: 22.7568\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 542.4432 - mae: 22.7481 - val_loss: 535.2192 - val_mae: 22.7561\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 542.3804 - mae: 22.7471 - val_loss: 535.1748 - val_mae: 22.7555\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 542.3175 - mae: 22.7461 - val_loss: 535.1305 - val_mae: 22.7549\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 542.2546 - mae: 22.7451 - val_loss: 535.0861 - val_mae: 22.7543\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 542.1920 - mae: 22.7442 - val_loss: 535.0418 - val_mae: 22.7537\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 542.1293 - mae: 22.7432 - val_loss: 534.9976 - val_mae: 22.7530\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 542.0665 - mae: 22.7422 - val_loss: 534.9532 - val_mae: 22.7524\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 542.0040 - mae: 22.7412 - val_loss: 534.9091 - val_mae: 22.7518\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 541.9413 - mae: 22.7402 - val_loss: 534.8649 - val_mae: 22.7512\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 541.8788 - mae: 22.7392 - val_loss: 534.8206 - val_mae: 22.7506\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 541.8163 - mae: 22.7383 - val_loss: 534.7764 - val_mae: 22.7499\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 541.7538 - mae: 22.7373 - val_loss: 534.7322 - val_mae: 22.7493\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 541.6914 - mae: 22.7363 - val_loss: 534.6881 - val_mae: 22.7487\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 541.6290 - mae: 22.7353 - val_loss: 534.6440 - val_mae: 22.7481\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 541.5666 - mae: 22.7343 - val_loss: 534.5999 - val_mae: 22.7474\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 541.5043 - mae: 22.7333 - val_loss: 534.5558 - val_mae: 22.7468\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 541.4420 - mae: 22.7324 - val_loss: 534.5117 - val_mae: 22.7462\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 541.3799 - mae: 22.7314 - val_loss: 534.4677 - val_mae: 22.7456\n",
      "Epoch 886/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step - loss: 541.3176 - mae: 22.7304 - val_loss: 534.4236 - val_mae: 22.7450\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 541.2554 - mae: 22.7294 - val_loss: 534.3796 - val_mae: 22.7443\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 541.1933 - mae: 22.7284 - val_loss: 534.3356 - val_mae: 22.7437\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 541.1312 - mae: 22.7274 - val_loss: 534.2916 - val_mae: 22.7431\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 541.0692 - mae: 22.7264 - val_loss: 534.2477 - val_mae: 22.7425\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 541.0072 - mae: 22.7255 - val_loss: 534.2037 - val_mae: 22.7418\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 540.9452 - mae: 22.7245 - val_loss: 534.1598 - val_mae: 22.7412\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 540.8833 - mae: 22.7235 - val_loss: 534.1159 - val_mae: 22.7406\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 540.8215 - mae: 22.7225 - val_loss: 534.0720 - val_mae: 22.7399\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 540.7595 - mae: 22.7215 - val_loss: 534.0281 - val_mae: 22.7393\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 540.6978 - mae: 22.7205 - val_loss: 533.9843 - val_mae: 22.7387\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 540.6360 - mae: 22.7196 - val_loss: 533.9405 - val_mae: 22.7381\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 540.5742 - mae: 22.7186 - val_loss: 533.8967 - val_mae: 22.7374\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 540.5125 - mae: 22.7176 - val_loss: 533.8528 - val_mae: 22.7368\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 540.4507 - mae: 22.7166 - val_loss: 533.8091 - val_mae: 22.7362\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 540.3892 - mae: 22.7156 - val_loss: 533.7654 - val_mae: 22.7355\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 540.3275 - mae: 22.7146 - val_loss: 533.7216 - val_mae: 22.7349\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 540.2661 - mae: 22.7137 - val_loss: 533.6779 - val_mae: 22.7343\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 540.2045 - mae: 22.7127 - val_loss: 533.6342 - val_mae: 22.7336\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 540.1430 - mae: 22.7117 - val_loss: 533.5905 - val_mae: 22.7330\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 540.0815 - mae: 22.7107 - val_loss: 533.5469 - val_mae: 22.7324\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 540.0202 - mae: 22.7097 - val_loss: 533.5032 - val_mae: 22.7318\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 539.9588 - mae: 22.7087 - val_loss: 533.4596 - val_mae: 22.7311\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 539.8975 - mae: 22.7078 - val_loss: 533.4160 - val_mae: 22.7305\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 539.8362 - mae: 22.7068 - val_loss: 533.3724 - val_mae: 22.7299\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 539.7749 - mae: 22.7058 - val_loss: 533.3289 - val_mae: 22.7292\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 539.7137 - mae: 22.7048 - val_loss: 533.2853 - val_mae: 22.7286\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 539.6526 - mae: 22.7038 - val_loss: 533.2418 - val_mae: 22.7280\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 539.5914 - mae: 22.7028 - val_loss: 533.1982 - val_mae: 22.7273\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 539.5303 - mae: 22.7019 - val_loss: 533.1547 - val_mae: 22.7267\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 539.4692 - mae: 22.7009 - val_loss: 533.1112 - val_mae: 22.7260\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 539.4082 - mae: 22.6999 - val_loss: 533.0677 - val_mae: 22.7254\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 539.3472 - mae: 22.6989 - val_loss: 533.0243 - val_mae: 22.7248\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 539.2862 - mae: 22.6979 - val_loss: 532.9809 - val_mae: 22.7241\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 539.2252 - mae: 22.6969 - val_loss: 532.9375 - val_mae: 22.7235\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 539.1644 - mae: 22.6959 - val_loss: 532.8941 - val_mae: 22.7229\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 539.1035 - mae: 22.6950 - val_loss: 532.8507 - val_mae: 22.7222\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 539.0427 - mae: 22.6940 - val_loss: 532.8074 - val_mae: 22.7216\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 538.9819 - mae: 22.6930 - val_loss: 532.7640 - val_mae: 22.7209\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 538.9212 - mae: 22.6920 - val_loss: 532.7207 - val_mae: 22.7203\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 538.8605 - mae: 22.6910 - val_loss: 532.6774 - val_mae: 22.7197\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 538.7997 - mae: 22.6900 - val_loss: 532.6341 - val_mae: 22.7190\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 538.7392 - mae: 22.6891 - val_loss: 532.5908 - val_mae: 22.7184\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 538.6785 - mae: 22.6881 - val_loss: 532.5475 - val_mae: 22.7178\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 538.6180 - mae: 22.6871 - val_loss: 532.5043 - val_mae: 22.7171\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 538.5574 - mae: 22.6861 - val_loss: 532.4611 - val_mae: 22.7165\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 538.4969 - mae: 22.6851 - val_loss: 532.4178 - val_mae: 22.7158\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 538.4365 - mae: 22.6841 - val_loss: 532.3746 - val_mae: 22.7152\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 538.3761 - mae: 22.6832 - val_loss: 532.3314 - val_mae: 22.7145\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 538.3157 - mae: 22.6822 - val_loss: 532.2883 - val_mae: 22.7139\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 538.2553 - mae: 22.6812 - val_loss: 532.2451 - val_mae: 22.7133\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 538.1949 - mae: 22.6802 - val_loss: 532.2020 - val_mae: 22.7126\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 538.1347 - mae: 22.6792 - val_loss: 532.1589 - val_mae: 22.7120\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 538.0744 - mae: 22.6782 - val_loss: 532.1158 - val_mae: 22.7113\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 538.0142 - mae: 22.6773 - val_loss: 532.0728 - val_mae: 22.7107\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 537.9540 - mae: 22.6763 - val_loss: 532.0297 - val_mae: 22.7100\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 537.8939 - mae: 22.6753 - val_loss: 531.9866 - val_mae: 22.7094\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 537.8338 - mae: 22.6743 - val_loss: 531.9435 - val_mae: 22.7088\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 537.7737 - mae: 22.6733 - val_loss: 531.9005 - val_mae: 22.7081\n",
      "Epoch 945/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 537.7136 - mae: 22.6723 - val_loss: 531.8575 - val_mae: 22.7075\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 537.6536 - mae: 22.6714 - val_loss: 531.8146 - val_mae: 22.7068\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 537.5938 - mae: 22.6704 - val_loss: 531.7716 - val_mae: 22.7062\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 537.5338 - mae: 22.6694 - val_loss: 531.7286 - val_mae: 22.7055\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 537.4739 - mae: 22.6684 - val_loss: 531.6857 - val_mae: 22.7049\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 537.4140 - mae: 22.6674 - val_loss: 531.6428 - val_mae: 22.7042\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 537.3542 - mae: 22.6664 - val_loss: 531.5999 - val_mae: 22.7036\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 537.2944 - mae: 22.6655 - val_loss: 531.5569 - val_mae: 22.7029\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 537.2346 - mae: 22.6645 - val_loss: 531.5140 - val_mae: 22.7023\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 537.1749 - mae: 22.6635 - val_loss: 531.4712 - val_mae: 22.7016\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 537.1152 - mae: 22.6625 - val_loss: 531.4284 - val_mae: 22.7010\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 537.0555 - mae: 22.6615 - val_loss: 531.3856 - val_mae: 22.7003\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 536.9959 - mae: 22.6605 - val_loss: 531.3427 - val_mae: 22.6997\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 536.9363 - mae: 22.6596 - val_loss: 531.2999 - val_mae: 22.6990\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 536.8768 - mae: 22.6586 - val_loss: 531.2571 - val_mae: 22.6984\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 536.8173 - mae: 22.6576 - val_loss: 531.2144 - val_mae: 22.6977\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 536.7578 - mae: 22.6566 - val_loss: 531.1716 - val_mae: 22.6971\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 536.6984 - mae: 22.6556 - val_loss: 531.1288 - val_mae: 22.6964\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 536.6389 - mae: 22.6547 - val_loss: 531.0861 - val_mae: 22.6958\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 536.5795 - mae: 22.6537 - val_loss: 531.0433 - val_mae: 22.6951\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 536.5201 - mae: 22.6527 - val_loss: 531.0007 - val_mae: 22.6945\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 536.4608 - mae: 22.6517 - val_loss: 530.9580 - val_mae: 22.6938\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 536.4016 - mae: 22.6507 - val_loss: 530.9153 - val_mae: 22.6932\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 536.3423 - mae: 22.6497 - val_loss: 530.8727 - val_mae: 22.6925\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 536.2830 - mae: 22.6488 - val_loss: 530.8300 - val_mae: 22.6918\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 536.2238 - mae: 22.6478 - val_loss: 530.7874 - val_mae: 22.6912\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 536.1647 - mae: 22.6468 - val_loss: 530.7448 - val_mae: 22.6905\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 536.1055 - mae: 22.6458 - val_loss: 530.7022 - val_mae: 22.6899\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 536.0465 - mae: 22.6448 - val_loss: 530.6596 - val_mae: 22.6892\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 535.9875 - mae: 22.6438 - val_loss: 530.6171 - val_mae: 22.6886\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 535.9284 - mae: 22.6429 - val_loss: 530.5745 - val_mae: 22.6879\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 535.8694 - mae: 22.6419 - val_loss: 530.5319 - val_mae: 22.6873\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 535.8104 - mae: 22.6409 - val_loss: 530.4894 - val_mae: 22.6866\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 535.7515 - mae: 22.6399 - val_loss: 530.4469 - val_mae: 22.6859\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 535.6926 - mae: 22.6389 - val_loss: 530.4044 - val_mae: 22.6853\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 535.6338 - mae: 22.6379 - val_loss: 530.3619 - val_mae: 22.6846\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 535.5750 - mae: 22.6370 - val_loss: 530.3195 - val_mae: 22.6840\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 535.5162 - mae: 22.6360 - val_loss: 530.2770 - val_mae: 22.6833\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 535.4575 - mae: 22.6350 - val_loss: 530.2345 - val_mae: 22.6826\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 535.3986 - mae: 22.6340 - val_loss: 530.1921 - val_mae: 22.6820\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 535.3400 - mae: 22.6330 - val_loss: 530.1497 - val_mae: 22.6813\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 535.2813 - mae: 22.6320 - val_loss: 530.1073 - val_mae: 22.6807\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 535.2227 - mae: 22.6311 - val_loss: 530.0649 - val_mae: 22.6800\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 535.1641 - mae: 22.6301 - val_loss: 530.0225 - val_mae: 22.6793\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 535.1055 - mae: 22.6291 - val_loss: 529.9801 - val_mae: 22.6787\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 535.0470 - mae: 22.6281 - val_loss: 529.9378 - val_mae: 22.6780\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 534.9885 - mae: 22.6271 - val_loss: 529.8954 - val_mae: 22.6774\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 534.9301 - mae: 22.6262 - val_loss: 529.8531 - val_mae: 22.6767\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 534.8716 - mae: 22.6252 - val_loss: 529.8109 - val_mae: 22.6760\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 534.8132 - mae: 22.6242 - val_loss: 529.7686 - val_mae: 22.6754\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 534.7548 - mae: 22.6232 - val_loss: 529.7262 - val_mae: 22.6747\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 534.6965 - mae: 22.6222 - val_loss: 529.6840 - val_mae: 22.6740\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 534.6382 - mae: 22.6212 - val_loss: 529.6417 - val_mae: 22.6734\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 534.5799 - mae: 22.6203 - val_loss: 529.5994 - val_mae: 22.6727\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 534.5216 - mae: 22.6193 - val_loss: 529.5573 - val_mae: 22.6720\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 534.4633 - mae: 22.6183 - val_loss: 529.5150 - val_mae: 22.6714\n",
      "1/1 - 0s - loss: 9466748.0000 - mae: 2562.7803 - 173ms/epoch - 173ms/step\n",
      "Mean Squared Error (MSE): 9466748.0\n"
     ]
    }
   ],
   "source": [
    "# 데이터 표준화\n",
    "# 데이터 split\n",
    "from  tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "train_input, test_input, train_target, test_target = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "train_scaled = ss.fit_transform(train_input)\n",
    "test_scaled = ss.transform(test_input)\n",
    "\n",
    "# Optimizer - Stochastic gradient descent - 확률적 경사 하강법\n",
    "# sgd = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "\n",
    "\n",
    "model = keras.Sequential() # 도화지 한장 만드는, 인공신경망을 만들기 위한...\n",
    "model.add(keras.layers.Dense(7, input_shape = (9,))) # input_shape은 입력층임, 한개의 입력층에서 하나의 출력층으로 간다는 뜻)\n",
    "\n",
    "# 총 컴퓨터가 학습해야 되는 파라미터는 10개!! 9개의 컬럼과 1개의 절편. model.summary() 코드로 확인가능!!!\n",
    "model.compile(loss= 'mse', optimizer = 'adam', metrics = 'mae') # adam은 학습률을 직접 자동으로 조절해준다!! # metrics = 'mae' 절대 오차를 보여준다.\n",
    "# 컴퓨터한테 mse 방법으로 계산해달라고 하고, 학습률을 자동으로 맞춰주게 amda을 사용하였고, 거기서 내가 보고 싶은 데이터인 절대오차를 보여달라고 metrics = 'mae'를 사용한거\n",
    "\n",
    "# MSE 평균제곱오차\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(patience=5, restore_best_weights = True) # patience=5 : 컴퓨터가 참는 횟수(과대적합이 이어지는 수 현재는 5번연속 과대적합일때, 5번연속 모델이 좋아지지 않았을때, 주기!),\n",
    "# restore_best_weights = True, 과대적합이(모델이 5번연속 모델이 좋아지지 않앗을때) 5번 연속 일어났을때, 그것을 제외하고(이전의) 모델을 보여줘!라는 뜻\n",
    "\n",
    "hist = model.fit(train_scaled, train_target, epochs = 1000, validation_data = (test_scaled, test_target), callbacks=[es], batch_size = 1000) # epochs 학습 횟수!\n",
    "# validation_data = (test_scaled, test_target) # 쪽지시험, 훈련을 한번 할때마다 쪽지 시험, 훈련데이터는 떨어지는, 쪽지시험은 올라가는 과대적합을 확인 할 수 있음!!\n",
    "# val_loss인 쪽지시험의 결과를 확인 해야된다!!! - > 과대적합을 확인했을 경우 -> 얼리스탑핑 적용, 이렇게 하여, 최적의 모델을 확인 할 수 있음??!\n",
    "\n",
    "\n",
    "\n",
    "# 손실 함수 계산\n",
    "loss, mse = model.evaluate(train_input, train_target, batch_size=1000, verbose=2)\n",
    "print('Mean Squared Error (MSE):', loss)\n",
    "\n",
    "\n",
    "# MSE는 평균 제곱 오차를 나타냅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6913d3ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 7)                 70        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70 (280.00 Byte)\n",
      "Trainable params: 70 (280.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9d95a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step - loss: 9435014.0000 - mae: 2556.2539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9435014.0, 2556.25390625]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_input, test_target)\n",
    "\n",
    "# 1 번째 [17,370,756.0, 4,028.35888671875]\n",
    "# 2 번째 [17,784,066.0, 3556.08984375] 노드 수 증가(32), batch 수 증가 (50)\n",
    "# 3 번째 [488,604,064.0, 16541.791015625] , - layer추가 , 노드 수 증가(100), batch 수 증가\n",
    "# 4 번쨰 [19,545,324.0, 3,618.091796875] , 1층 , batch_size=100\n",
    "# 5 번째 [83,356,568.0, 8,674.251953125] , 1층 , SGD 사용 , activation = 'linear', batch_size=100\n",
    "# 6 번째 [20,712,244.0, 3,883.132,080,078,125], 1층, adam 사용, activation = 'linear', batch_size=100\n",
    "# 7 번째 [15,668,128.0, 3,406.31,298,828,125],  1층, adam사용, activation='없음', batch_size=100, epochs = 1000\n",
    "# 8 번째 [18,041,990.0, 3,678.059326171875], 1층 , adam사용, activation='없음', batch_size=500, epochs = 3000\n",
    "# 9 번째 [17,900,314.0, 3416.20849609375] , 1층, adam사용, activation='없음', batch_size=100, epochs = 1000, epochs = 1000, 노드 14개\n",
    "# 10 번째  , 1층 , adam사용, activation='없음', batch_size=100, epochs = 1000, 노드 1개\n",
    "# 11 번째, [29,574,182.0, 4,019.82080078125], 노드 1개\n",
    "# 12 번째, [16,696,080.0, 3,279.92333984375], 노드 64개\n",
    "# 13번째 , [14,905,614.0, 3,380.693359375], 노드 7개, adam사용, avtivation='없음' , 배치:100, 에폭:1000, \n",
    "# 14번째, [19,363,676.0, 3,983.610107421875], 노드 4개, adam사용, activation='없음', 배치:100, 에폭:1000\n",
    "# 15번째, [17,679,988.0, 3,634.688232421875], 노드 9개, adam사용, activation='없음', 배치:100, 에폭:1000\n",
    "# 16번쨰, [172,240,864.0, 12,587.046875] , 노드 7개, 2층 노드7개, adam사용, activation='없음', 배치:100, 에폭:1000\n",
    "# 17번째, [162,252,000.0, 12,270.5830078125], 1층 노드 7개, adam사용, activation='없음', 배치:1000, 에폭:5000\n",
    "# 18번째,   1층 노드 7개, adam사용, activation='없음', 배치:1000, 에폭:1000\n",
    "# 19번째, [9,435,014.0, 2,556.25390625], origin 전처리, 1층 노드 7개, adam사용, activation='없음', 배치:1000, 에폭:1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b64bbaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfbb89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9921b689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5255e7af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0006cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
