{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "173fb19f",
      "metadata": {
        "id": "173fb19f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Make NumPy printouts easier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "3c6db16c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c6db16c",
        "outputId": "d2592940-0fac-4134-b81c-317dc714fdac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.13.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "3cda9cc1",
      "metadata": {
        "id": "3cda9cc1"
      },
      "outputs": [],
      "source": [
        "# url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
        "# column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
        "#                 'Acceleration', 'Model Year', 'Origin']\n",
        "\n",
        "# raw_dataset = pd.read_csv(url, names=column_names,\n",
        "#                           na_values='?', comment='\\t',\n",
        "#                           sep=' ', skipinitialspace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "6a7984e9",
      "metadata": {
        "id": "6a7984e9"
      },
      "outputs": [],
      "source": [
        "# auto-mpg.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "6426e1ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "6426e1ea",
        "outputId": "f547aeb6-42d4-4b11-9b53-7813b1c6a1ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      mpg  cylinders  displacement horsepower  weight  acceleration  \\\n",
              "0    18.0          8         307.0      130.0  3504.0          12.0   \n",
              "1    15.0          8         350.0      165.0  3693.0          11.5   \n",
              "2    18.0          8         318.0      150.0  3436.0          11.0   \n",
              "3    16.0          8         304.0      150.0  3433.0          12.0   \n",
              "4    17.0          8         302.0      140.0  3449.0          10.5   \n",
              "..    ...        ...           ...        ...     ...           ...   \n",
              "393  27.0          4         140.0      86.00  2790.0          15.6   \n",
              "394  44.0          4          97.0      52.00  2130.0          24.6   \n",
              "395  32.0          4         135.0      84.00  2295.0          11.6   \n",
              "396  28.0          4         120.0      79.00  2625.0          18.6   \n",
              "397  31.0          4         119.0      82.00  2720.0          19.4   \n",
              "\n",
              "     model_year  origin                   car_name  \n",
              "0            70       1  chevrolet chevelle malibu  \n",
              "1            70       1          buick skylark 320  \n",
              "2            70       1         plymouth satellite  \n",
              "3            70       1              amc rebel sst  \n",
              "4            70       1                ford torino  \n",
              "..          ...     ...                        ...  \n",
              "393          82       1            ford mustang gl  \n",
              "394          82       2                  vw pickup  \n",
              "395          82       1              dodge rampage  \n",
              "396          82       1                ford ranger  \n",
              "397          82       1                 chevy s-10  \n",
              "\n",
              "[398 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4094a414-920b-4d7f-b022-078ad5753efd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model_year</th>\n",
              "      <th>origin</th>\n",
              "      <th>car_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>3504.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>chevrolet chevelle malibu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>3693.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>buick skylark 320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.0</td>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3436.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>plymouth satellite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.0</td>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3433.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>amc rebel sst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17.0</td>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>3449.0</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>ford torino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>27.0</td>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>86.00</td>\n",
              "      <td>2790.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>ford mustang gl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>44.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>52.00</td>\n",
              "      <td>2130.0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>2</td>\n",
              "      <td>vw pickup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>32.0</td>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.00</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>dodge rampage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>28.0</td>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>79.00</td>\n",
              "      <td>2625.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>ford ranger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>31.0</td>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>82.00</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>chevy s-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>398 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4094a414-920b-4d7f-b022-078ad5753efd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4094a414-920b-4d7f-b022-078ad5753efd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4094a414-920b-4d7f-b022-078ad5753efd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b5e8636-1d5d-487f-a184-8b24310a91c8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b5e8636-1d5d-487f-a184-8b24310a91c8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b5e8636-1d5d-487f-a184-8b24310a91c8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "# 필요한 패키지를 가져오기\n",
        "import pandas as pd\n",
        "\n",
        "# 파일 경로 설정 (파일이 현재 작업 디렉토리에 있는 경우)\n",
        "file_path = \"auto-mpg.data\"\n",
        "\n",
        "# 데이터 파일을 데이터프레임으로 읽어오기\n",
        "# \"auto-mpg.data\" 파일은 공백으로 구분된 데이터이므로 delim_whitespace=True로 설정합니다.\n",
        "# 파일에 헤더(열 이름)가 없으므로 header=None으로 설정합니다.\n",
        "# 각 열에 대한 이름은 나중에 추가할 것입니다.\n",
        "df = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
        "\n",
        "# 열 이름 추가 (데이터에 포함된 열 이름을 사용하거나, 원하는 이름으로 변경할 수 있습니다.)\n",
        "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name']\n",
        "\n",
        "# 데이터프레임 확인\n",
        "df\n",
        "\n",
        "data = df\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train, target 나누기"
      ],
      "metadata": {
        "id": "fom_CSpmP15Q"
      },
      "id": "fom_CSpmP15Q"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "e406a593",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "e406a593",
        "outputId": "edb7f1c1-587d-4ec3-92e7-b60ff254b93b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cylinders  displacement horsepower  weight  acceleration  model_year  \\\n",
              "0            8         307.0      130.0  3504.0          12.0          70   \n",
              "1            8         350.0      165.0  3693.0          11.5          70   \n",
              "2            8         318.0      150.0  3436.0          11.0          70   \n",
              "3            8         304.0      150.0  3433.0          12.0          70   \n",
              "4            8         302.0      140.0  3449.0          10.5          70   \n",
              "..         ...           ...        ...     ...           ...         ...   \n",
              "393          4         140.0      86.00  2790.0          15.6          82   \n",
              "394          4          97.0      52.00  2130.0          24.6          82   \n",
              "395          4         135.0      84.00  2295.0          11.6          82   \n",
              "396          4         120.0      79.00  2625.0          18.6          82   \n",
              "397          4         119.0      82.00  2720.0          19.4          82   \n",
              "\n",
              "     origin  \n",
              "0         1  \n",
              "1         1  \n",
              "2         1  \n",
              "3         1  \n",
              "4         1  \n",
              "..      ...  \n",
              "393       1  \n",
              "394       2  \n",
              "395       1  \n",
              "396       1  \n",
              "397       1  \n",
              "\n",
              "[398 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45c8e220-bd93-4ecc-8701-eb505b2cf951\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model_year</th>\n",
              "      <th>origin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>3504.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>3693.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3436.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3433.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>3449.0</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>86.00</td>\n",
              "      <td>2790.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>52.00</td>\n",
              "      <td>2130.0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.00</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>79.00</td>\n",
              "      <td>2625.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>82.00</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>398 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45c8e220-bd93-4ecc-8701-eb505b2cf951')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-45c8e220-bd93-4ecc-8701-eb505b2cf951 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-45c8e220-bd93-4ecc-8701-eb505b2cf951');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a6f885a9-aa8e-44bc-88ed-1365455cc9d2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6f885a9-aa8e-44bc-88ed-1365455cc9d2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a6f885a9-aa8e-44bc-88ed-1365455cc9d2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "y = data['mpg']\n",
        "x = data[['cylinders','displacement','horsepower','weight','acceleration','model_year','origin']]\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "Nf5DNBM5PzDK"
      },
      "id": "Nf5DNBM5PzDK"
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "b1b19fc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1b19fc2",
        "outputId": "56015bf4-48aa-4883-913f-83403cbfe04c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 398 entries, 0 to 397\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   mpg           398 non-null    float64\n",
            " 1   cylinders     398 non-null    int64  \n",
            " 2   displacement  398 non-null    float64\n",
            " 3   horsepower    398 non-null    object \n",
            " 4   weight        398 non-null    float64\n",
            " 5   acceleration  398 non-null    float64\n",
            " 6   model_year    398 non-null    int64  \n",
            " 7   origin        398 non-null    int64  \n",
            " 8   car_name      398 non-null    object \n",
            "dtypes: float64(4), int64(3), object(2)\n",
            "memory usage: 28.1+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "db2e9f3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "db2e9f3a",
        "outputId": "4403c192-b9b8-49a5-e486-ad831d9e6cef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              mpg   cylinders  displacement       weight  acceleration  \\\n",
              "count  398.000000  398.000000    398.000000   398.000000    398.000000   \n",
              "mean    23.514573    5.454774    193.425879  2970.424623     15.568090   \n",
              "std      7.815984    1.701004    104.269838   846.841774      2.757689   \n",
              "min      9.000000    3.000000     68.000000  1613.000000      8.000000   \n",
              "25%     17.500000    4.000000    104.250000  2223.750000     13.825000   \n",
              "50%     23.000000    4.000000    148.500000  2803.500000     15.500000   \n",
              "75%     29.000000    8.000000    262.000000  3608.000000     17.175000   \n",
              "max     46.600000    8.000000    455.000000  5140.000000     24.800000   \n",
              "\n",
              "       model_year      origin  \n",
              "count  398.000000  398.000000  \n",
              "mean    76.010050    1.572864  \n",
              "std      3.697627    0.802055  \n",
              "min     70.000000    1.000000  \n",
              "25%     73.000000    1.000000  \n",
              "50%     76.000000    1.000000  \n",
              "75%     79.000000    2.000000  \n",
              "max     82.000000    3.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd330be4-86f7-4569-ac7b-6309477aff41\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mpg</th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model_year</th>\n",
              "      <th>origin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>398.000000</td>\n",
              "      <td>398.000000</td>\n",
              "      <td>398.000000</td>\n",
              "      <td>398.000000</td>\n",
              "      <td>398.000000</td>\n",
              "      <td>398.000000</td>\n",
              "      <td>398.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>23.514573</td>\n",
              "      <td>5.454774</td>\n",
              "      <td>193.425879</td>\n",
              "      <td>2970.424623</td>\n",
              "      <td>15.568090</td>\n",
              "      <td>76.010050</td>\n",
              "      <td>1.572864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.815984</td>\n",
              "      <td>1.701004</td>\n",
              "      <td>104.269838</td>\n",
              "      <td>846.841774</td>\n",
              "      <td>2.757689</td>\n",
              "      <td>3.697627</td>\n",
              "      <td>0.802055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>1613.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>17.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>104.250000</td>\n",
              "      <td>2223.750000</td>\n",
              "      <td>13.825000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>148.500000</td>\n",
              "      <td>2803.500000</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>262.000000</td>\n",
              "      <td>3608.000000</td>\n",
              "      <td>17.175000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>46.600000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>455.000000</td>\n",
              "      <td>5140.000000</td>\n",
              "      <td>24.800000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd330be4-86f7-4569-ac7b-6309477aff41')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd330be4-86f7-4569-ac7b-6309477aff41 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd330be4-86f7-4569-ac7b-6309477aff41');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f2fd7bdc-85e8-45ba-95ff-18484578a781\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2fd7bdc-85e8-45ba-95ff-18484578a781')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f2fd7bdc-85e8-45ba-95ff-18484578a781 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "886cf771",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "886cf771",
        "outputId": "da5f8239-d221-42f4-8165-8d8a04604ff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 398 entries, 0 to 397\n",
            "Data columns (total 7 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   cylinders     398 non-null    int64  \n",
            " 1   displacement  398 non-null    float64\n",
            " 2   horsepower    398 non-null    object \n",
            " 3   weight        398 non-null    float64\n",
            " 4   acceleration  398 non-null    float64\n",
            " 5   model_year    398 non-null    int64  \n",
            " 6   origin        398 non-null    int64  \n",
            "dtypes: float64(3), int64(3), object(1)\n",
            "memory usage: 21.9+ KB\n"
          ]
        }
      ],
      "source": [
        "x.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리"
      ],
      "metadata": {
        "id": "SGBXb-9GPuKc"
      },
      "id": "SGBXb-9GPuKc"
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "91a8b94a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91a8b94a",
        "outputId": "c1b915e2-e6a7-4cae-d3a6-33ea46892b38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-87-c0c66538b686>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x['origin'] = x['origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n"
          ]
        }
      ],
      "source": [
        "# Origin 이 범주형이여서 바꿔준다.\n",
        "x['origin'] = x['origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "adde2130",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "adde2130",
        "outputId": "09a83e56-8283-46fd-c6f8-6209cca519c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cylinders  displacement horsepower  weight  acceleration  model_year  \\\n",
              "0            8         307.0      130.0  3504.0          12.0          70   \n",
              "1            8         350.0      165.0  3693.0          11.5          70   \n",
              "2            8         318.0      150.0  3436.0          11.0          70   \n",
              "3            8         304.0      150.0  3433.0          12.0          70   \n",
              "4            8         302.0      140.0  3449.0          10.5          70   \n",
              "..         ...           ...        ...     ...           ...         ...   \n",
              "393          4         140.0      86.00  2790.0          15.6          82   \n",
              "394          4          97.0      52.00  2130.0          24.6          82   \n",
              "395          4         135.0      84.00  2295.0          11.6          82   \n",
              "396          4         120.0      79.00  2625.0          18.6          82   \n",
              "397          4         119.0      82.00  2720.0          19.4          82   \n",
              "\n",
              "     origin  \n",
              "0       USA  \n",
              "1       USA  \n",
              "2       USA  \n",
              "3       USA  \n",
              "4       USA  \n",
              "..      ...  \n",
              "393     USA  \n",
              "394  Europe  \n",
              "395     USA  \n",
              "396     USA  \n",
              "397     USA  \n",
              "\n",
              "[398 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d939414-0cb3-437a-9959-74602cb1eafd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model_year</th>\n",
              "      <th>origin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>307.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>3504.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>350.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>3693.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>70</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>318.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3436.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>304.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3433.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>70</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>302.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>3449.0</td>\n",
              "      <td>10.5</td>\n",
              "      <td>70</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>86.00</td>\n",
              "      <td>2790.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>52.00</td>\n",
              "      <td>2130.0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>Europe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.00</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>79.00</td>\n",
              "      <td>2625.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>82.00</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>398 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d939414-0cb3-437a-9959-74602cb1eafd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d939414-0cb3-437a-9959-74602cb1eafd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d939414-0cb3-437a-9959-74602cb1eafd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b8df8252-d9dd-4368-8d2a-a5ea44f5a2e9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b8df8252-d9dd-4368-8d2a-a5ea44f5a2e9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b8df8252-d9dd-4368-8d2a-a5ea44f5a2e9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "38f2bbd8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "38f2bbd8",
        "outputId": "300c782a-0843-4669-f047-55f4c530470c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cylinders  displacement horsepower  weight  acceleration  model_year  \\\n",
              "393          4         140.0      86.00  2790.0          15.6          82   \n",
              "394          4          97.0      52.00  2130.0          24.6          82   \n",
              "395          4         135.0      84.00  2295.0          11.6          82   \n",
              "396          4         120.0      79.00  2625.0          18.6          82   \n",
              "397          4         119.0      82.00  2720.0          19.4          82   \n",
              "\n",
              "     Europe  Japan  USA  \n",
              "393       0      0    1  \n",
              "394       1      0    0  \n",
              "395       0      0    1  \n",
              "396       0      0    1  \n",
              "397       0      0    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a97ccea3-cb50-45c6-87fe-48e7e961e4ab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model_year</th>\n",
              "      <th>Europe</th>\n",
              "      <th>Japan</th>\n",
              "      <th>USA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>86.00</td>\n",
              "      <td>2790.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>52.00</td>\n",
              "      <td>2130.0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.00</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>79.00</td>\n",
              "      <td>2625.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>82.00</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a97ccea3-cb50-45c6-87fe-48e7e961e4ab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a97ccea3-cb50-45c6-87fe-48e7e961e4ab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a97ccea3-cb50-45c6-87fe-48e7e961e4ab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a1fb80a-f1fe-48de-ba0a-bf033865e25c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a1fb80a-f1fe-48de-ba0a-bf033865e25c')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a1fb80a-f1fe-48de-ba0a-bf033865e25c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "x = pd.get_dummies(x, columns=['origin'], prefix='', prefix_sep='')\n",
        "x.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "49ddf946",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49ddf946",
        "outputId": "26f928f6-4ebb-4082-c2cb-e3cba45b9d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 398 entries, 0 to 397\n",
            "Data columns (total 9 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   cylinders     398 non-null    float64\n",
            " 1   displacement  398 non-null    float64\n",
            " 2   horsepower    398 non-null    float64\n",
            " 3   weight        398 non-null    float64\n",
            " 4   acceleration  398 non-null    float64\n",
            " 5   model_year    398 non-null    float64\n",
            " 6   Europe        398 non-null    float64\n",
            " 7   Japan         398 non-null    float64\n",
            " 8   USA           398 non-null    float64\n",
            "dtypes: float64(9)\n",
            "memory usage: 28.1 KB\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# int 타입 : cylinders model_year origin\n",
        "# object 타입 : horsepower\n",
        "\n",
        "# 특정 컬럼을 int 타입에서 float 타입으로 변경하려면\n",
        "x['cylinders'] = x['cylinders'].astype(float)\n",
        "x['model_year'] = x['model_year'].astype(float)\n",
        "x['USA'] = x['USA'].astype(float)\n",
        "x['Europe'] = x['Europe'].astype(float)\n",
        "x['Japan'] = x['Japan'].astype(float)\n",
        "\n",
        "# 특정 컬럼을 object 타입에서 float 타입으로 변경하려면\n",
        "# NaN 값을 가진 행을 삭제\n",
        "# \"horsepower\" 컬럼에서 숫자가 아닌 문자를 빈 문자열(\"\")로 대체하여 숫자만 남기기\n",
        "x['horsepower'] = x['horsepower'].apply(lambda x: re.sub(r'[^0-9]', '', x) if isinstance(x, str) else x)\n",
        "\n",
        "# \"horsepower\" 컬럼의 데이터 타입을 float로 변환\n",
        "x['horsepower'] = pd.to_numeric(x['horsepower'], errors='coerce')\n",
        "\n",
        "# # NaN 값을 가진 행을 삭제 - > y 데이터와 개수가 달라, 삭제 말고, 평균 값을 넣어주는 방식으로 진행\n",
        "# x.dropna(subset=['horsepower'], inplace=True)\n",
        "# NaN 값을 평균 값으로 대체\n",
        "average_horsepower = x['horsepower'].mean()\n",
        "x['horsepower'].fillna(average_horsepower, inplace=True)\n",
        "\n",
        "x.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "db2d98b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db2d98b8",
        "outputId": "2a504deb-e455-4223-fb0b-015118192f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 398 entries, 0 to 397\n",
            "Series name: mpg\n",
            "Non-Null Count  Dtype  \n",
            "--------------  -----  \n",
            "398 non-null    float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 3.2 KB\n"
          ]
        }
      ],
      "source": [
        "y.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "7307fc4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7307fc4f",
        "outputId": "70558662-a769-4e07-886b-113c8c04ac77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    398.000000\n",
              "mean      23.514573\n",
              "std        7.815984\n",
              "min        9.000000\n",
              "25%       17.500000\n",
              "50%       23.000000\n",
              "75%       29.000000\n",
              "max       46.600000\n",
              "Name: mpg, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "y.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 구성_ 표준화, split, Sequential()"
      ],
      "metadata": {
        "id": "BXfy4znVPhVR"
      },
      "id": "BXfy4znVPhVR"
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "5e5378e3",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e5378e3",
        "outputId": "67761c37-9daa-4a78-cb33-b84e5ca83e9f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 7502/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 280.5208 - mae: 16.3898 - val_loss: 280.7501 - val_mae: 16.4940\n",
            "Epoch 7503/10000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 280.4895 - mae: 16.3888 - val_loss: 280.7180 - val_mae: 16.4930\n",
            "Epoch 7504/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 280.4583 - mae: 16.3879 - val_loss: 280.6858 - val_mae: 16.4921\n",
            "Epoch 7505/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 280.4270 - mae: 16.3870 - val_loss: 280.6537 - val_mae: 16.4911\n",
            "Epoch 7506/10000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 280.3958 - mae: 16.3860 - val_loss: 280.6216 - val_mae: 16.4901\n",
            "Epoch 7507/10000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 280.3645 - mae: 16.3851 - val_loss: 280.5894 - val_mae: 16.4892\n",
            "Epoch 7508/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 280.3333 - mae: 16.3841 - val_loss: 280.5573 - val_mae: 16.4882\n",
            "Epoch 7509/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 280.3020 - mae: 16.3832 - val_loss: 280.5252 - val_mae: 16.4872\n",
            "Epoch 7510/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 280.2708 - mae: 16.3822 - val_loss: 280.4931 - val_mae: 16.4863\n",
            "Epoch 7511/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 280.2396 - mae: 16.3813 - val_loss: 280.4609 - val_mae: 16.4853\n",
            "Epoch 7512/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 280.2083 - mae: 16.3803 - val_loss: 280.4288 - val_mae: 16.4843\n",
            "Epoch 7513/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 280.1771 - mae: 16.3794 - val_loss: 280.3967 - val_mae: 16.4833\n",
            "Epoch 7514/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 280.1458 - mae: 16.3785 - val_loss: 280.3646 - val_mae: 16.4824\n",
            "Epoch 7515/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 280.1146 - mae: 16.3775 - val_loss: 280.3325 - val_mae: 16.4814\n",
            "Epoch 7516/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 280.0834 - mae: 16.3766 - val_loss: 280.3004 - val_mae: 16.4804\n",
            "Epoch 7517/10000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 280.0522 - mae: 16.3756 - val_loss: 280.2682 - val_mae: 16.4795\n",
            "Epoch 7518/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 280.0209 - mae: 16.3747 - val_loss: 280.2362 - val_mae: 16.4785\n",
            "Epoch 7519/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 279.9897 - mae: 16.3737 - val_loss: 280.2041 - val_mae: 16.4775\n",
            "Epoch 7520/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 279.9585 - mae: 16.3728 - val_loss: 280.1720 - val_mae: 16.4765\n",
            "Epoch 7521/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 279.9273 - mae: 16.3718 - val_loss: 280.1399 - val_mae: 16.4756\n",
            "Epoch 7522/10000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 279.8961 - mae: 16.3709 - val_loss: 280.1078 - val_mae: 16.4746\n",
            "Epoch 7523/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 279.8648 - mae: 16.3700 - val_loss: 280.0756 - val_mae: 16.4736\n",
            "Epoch 7524/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 279.8336 - mae: 16.3690 - val_loss: 280.0436 - val_mae: 16.4727\n",
            "Epoch 7525/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 279.8024 - mae: 16.3681 - val_loss: 280.0115 - val_mae: 16.4717\n",
            "Epoch 7526/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 279.7712 - mae: 16.3671 - val_loss: 279.9794 - val_mae: 16.4707\n",
            "Epoch 7527/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 279.7400 - mae: 16.3662 - val_loss: 279.9473 - val_mae: 16.4697\n",
            "Epoch 7528/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 279.7088 - mae: 16.3652 - val_loss: 279.9152 - val_mae: 16.4688\n",
            "Epoch 7529/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 279.6776 - mae: 16.3643 - val_loss: 279.8831 - val_mae: 16.4678\n",
            "Epoch 7530/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 279.6464 - mae: 16.3633 - val_loss: 279.8510 - val_mae: 16.4668\n",
            "Epoch 7531/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 279.6152 - mae: 16.3624 - val_loss: 279.8190 - val_mae: 16.4659\n",
            "Epoch 7532/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 279.5840 - mae: 16.3615 - val_loss: 279.7869 - val_mae: 16.4649\n",
            "Epoch 7533/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 279.5527 - mae: 16.3605 - val_loss: 279.7548 - val_mae: 16.4639\n",
            "Epoch 7534/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 279.5215 - mae: 16.3596 - val_loss: 279.7227 - val_mae: 16.4629\n",
            "Epoch 7535/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 279.4904 - mae: 16.3586 - val_loss: 279.6907 - val_mae: 16.4620\n",
            "Epoch 7536/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 279.4592 - mae: 16.3577 - val_loss: 279.6586 - val_mae: 16.4610\n",
            "Epoch 7537/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 279.4280 - mae: 16.3567 - val_loss: 279.6266 - val_mae: 16.4600\n",
            "Epoch 7538/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 279.3968 - mae: 16.3558 - val_loss: 279.5945 - val_mae: 16.4591\n",
            "Epoch 7539/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 279.3656 - mae: 16.3548 - val_loss: 279.5624 - val_mae: 16.4581\n",
            "Epoch 7540/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 279.3344 - mae: 16.3539 - val_loss: 279.5303 - val_mae: 16.4571\n",
            "Epoch 7541/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 279.3032 - mae: 16.3530 - val_loss: 279.4983 - val_mae: 16.4562\n",
            "Epoch 7542/10000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 279.2720 - mae: 16.3520 - val_loss: 279.4662 - val_mae: 16.4552\n",
            "Epoch 7543/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 279.2409 - mae: 16.3511 - val_loss: 279.4341 - val_mae: 16.4542\n",
            "Epoch 7544/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 279.2097 - mae: 16.3501 - val_loss: 279.4021 - val_mae: 16.4532\n",
            "Epoch 7545/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 279.1785 - mae: 16.3492 - val_loss: 279.3701 - val_mae: 16.4523\n",
            "Epoch 7546/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 279.1474 - mae: 16.3482 - val_loss: 279.3380 - val_mae: 16.4513\n",
            "Epoch 7547/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 279.1162 - mae: 16.3473 - val_loss: 279.3060 - val_mae: 16.4503\n",
            "Epoch 7548/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 279.0850 - mae: 16.3463 - val_loss: 279.2739 - val_mae: 16.4494\n",
            "Epoch 7549/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 279.0539 - mae: 16.3454 - val_loss: 279.2419 - val_mae: 16.4484\n",
            "Epoch 7550/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 279.0227 - mae: 16.3444 - val_loss: 279.2098 - val_mae: 16.4474\n",
            "Epoch 7551/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 278.9915 - mae: 16.3435 - val_loss: 279.1778 - val_mae: 16.4464\n",
            "Epoch 7552/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 278.9604 - mae: 16.3426 - val_loss: 279.1458 - val_mae: 16.4455\n",
            "Epoch 7553/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 278.9292 - mae: 16.3416 - val_loss: 279.1137 - val_mae: 16.4445\n",
            "Epoch 7554/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 278.8980 - mae: 16.3407 - val_loss: 279.0817 - val_mae: 16.4435\n",
            "Epoch 7555/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 278.8669 - mae: 16.3397 - val_loss: 279.0496 - val_mae: 16.4426\n",
            "Epoch 7556/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 278.8357 - mae: 16.3388 - val_loss: 279.0176 - val_mae: 16.4416\n",
            "Epoch 7557/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 278.8046 - mae: 16.3378 - val_loss: 278.9856 - val_mae: 16.4406\n",
            "Epoch 7558/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 278.7734 - mae: 16.3369 - val_loss: 278.9536 - val_mae: 16.4396\n",
            "Epoch 7559/10000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 278.7422 - mae: 16.3359 - val_loss: 278.9215 - val_mae: 16.4387\n",
            "Epoch 7560/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 278.7111 - mae: 16.3350 - val_loss: 278.8895 - val_mae: 16.4377\n",
            "Epoch 7561/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 278.6800 - mae: 16.3341 - val_loss: 278.8575 - val_mae: 16.4367\n",
            "Epoch 7562/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 278.6488 - mae: 16.3331 - val_loss: 278.8254 - val_mae: 16.4358\n",
            "Epoch 7563/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 278.6177 - mae: 16.3322 - val_loss: 278.7935 - val_mae: 16.4348\n",
            "Epoch 7564/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 278.5865 - mae: 16.3312 - val_loss: 278.7614 - val_mae: 16.4338\n",
            "Epoch 7565/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 278.5554 - mae: 16.3303 - val_loss: 278.7294 - val_mae: 16.4328\n",
            "Epoch 7566/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 278.5243 - mae: 16.3293 - val_loss: 278.6974 - val_mae: 16.4319\n",
            "Epoch 7567/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 278.4932 - mae: 16.3284 - val_loss: 278.6654 - val_mae: 16.4309\n",
            "Epoch 7568/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 278.4620 - mae: 16.3274 - val_loss: 278.6334 - val_mae: 16.4299\n",
            "Epoch 7569/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 278.4309 - mae: 16.3265 - val_loss: 278.6014 - val_mae: 16.4290\n",
            "Epoch 7570/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 278.3997 - mae: 16.3256 - val_loss: 278.5694 - val_mae: 16.4280\n",
            "Epoch 7571/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 278.3686 - mae: 16.3246 - val_loss: 278.5374 - val_mae: 16.4270\n",
            "Epoch 7572/10000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 278.3375 - mae: 16.3237 - val_loss: 278.5054 - val_mae: 16.4261\n",
            "Epoch 7573/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 278.3064 - mae: 16.3227 - val_loss: 278.4734 - val_mae: 16.4251\n",
            "Epoch 7574/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 278.2752 - mae: 16.3218 - val_loss: 278.4414 - val_mae: 16.4241\n",
            "Epoch 7575/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 278.2441 - mae: 16.3208 - val_loss: 278.4094 - val_mae: 16.4231\n",
            "Epoch 7576/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 278.2130 - mae: 16.3199 - val_loss: 278.3774 - val_mae: 16.4222\n",
            "Epoch 7577/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 278.1819 - mae: 16.3189 - val_loss: 278.3454 - val_mae: 16.4212\n",
            "Epoch 7578/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 278.1508 - mae: 16.3180 - val_loss: 278.3134 - val_mae: 16.4202\n",
            "Epoch 7579/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 278.1197 - mae: 16.3171 - val_loss: 278.2814 - val_mae: 16.4193\n",
            "Epoch 7580/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 278.0885 - mae: 16.3161 - val_loss: 278.2495 - val_mae: 16.4183\n",
            "Epoch 7581/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 278.0575 - mae: 16.3152 - val_loss: 278.2175 - val_mae: 16.4173\n",
            "Epoch 7582/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 278.0263 - mae: 16.3142 - val_loss: 278.1855 - val_mae: 16.4163\n",
            "Epoch 7583/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 277.9953 - mae: 16.3133 - val_loss: 278.1535 - val_mae: 16.4154\n",
            "Epoch 7584/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 277.9641 - mae: 16.3123 - val_loss: 278.1215 - val_mae: 16.4144\n",
            "Epoch 7585/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 277.9330 - mae: 16.3114 - val_loss: 278.0895 - val_mae: 16.4134\n",
            "Epoch 7586/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 277.9019 - mae: 16.3104 - val_loss: 278.0576 - val_mae: 16.4125\n",
            "Epoch 7587/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 277.8708 - mae: 16.3095 - val_loss: 278.0256 - val_mae: 16.4115\n",
            "Epoch 7588/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 277.8398 - mae: 16.3086 - val_loss: 277.9937 - val_mae: 16.4105\n",
            "Epoch 7589/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 277.8087 - mae: 16.3076 - val_loss: 277.9617 - val_mae: 16.4095\n",
            "Epoch 7590/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 277.7776 - mae: 16.3067 - val_loss: 277.9297 - val_mae: 16.4086\n",
            "Epoch 7591/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 277.7465 - mae: 16.3057 - val_loss: 277.8978 - val_mae: 16.4076\n",
            "Epoch 7592/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 277.7154 - mae: 16.3048 - val_loss: 277.8658 - val_mae: 16.4066\n",
            "Epoch 7593/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 277.6843 - mae: 16.3038 - val_loss: 277.8338 - val_mae: 16.4057\n",
            "Epoch 7594/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 277.6532 - mae: 16.3029 - val_loss: 277.8019 - val_mae: 16.4047\n",
            "Epoch 7595/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 277.6222 - mae: 16.3019 - val_loss: 277.7699 - val_mae: 16.4037\n",
            "Epoch 7596/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 277.5911 - mae: 16.3010 - val_loss: 277.7380 - val_mae: 16.4028\n",
            "Epoch 7597/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 277.5600 - mae: 16.3001 - val_loss: 277.7060 - val_mae: 16.4018\n",
            "Epoch 7598/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 277.5289 - mae: 16.2991 - val_loss: 277.6741 - val_mae: 16.4008\n",
            "Epoch 7599/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 277.4978 - mae: 16.2982 - val_loss: 277.6422 - val_mae: 16.3998\n",
            "Epoch 7600/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 277.4668 - mae: 16.2972 - val_loss: 277.6102 - val_mae: 16.3989\n",
            "Epoch 7601/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 277.4357 - mae: 16.2963 - val_loss: 277.5782 - val_mae: 16.3979\n",
            "Epoch 7602/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 277.4046 - mae: 16.2953 - val_loss: 277.5463 - val_mae: 16.3969\n",
            "Epoch 7603/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 277.3736 - mae: 16.2944 - val_loss: 277.5143 - val_mae: 16.3960\n",
            "Epoch 7604/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 277.3425 - mae: 16.2934 - val_loss: 277.4824 - val_mae: 16.3950\n",
            "Epoch 7605/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 277.3114 - mae: 16.2925 - val_loss: 277.4505 - val_mae: 16.3940\n",
            "Epoch 7606/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 277.2804 - mae: 16.2916 - val_loss: 277.4185 - val_mae: 16.3930\n",
            "Epoch 7607/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 277.2493 - mae: 16.2906 - val_loss: 277.3866 - val_mae: 16.3921\n",
            "Epoch 7608/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 277.2183 - mae: 16.2897 - val_loss: 277.3547 - val_mae: 16.3911\n",
            "Epoch 7609/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 277.1872 - mae: 16.2887 - val_loss: 277.3228 - val_mae: 16.3901\n",
            "Epoch 7610/10000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 277.1562 - mae: 16.2878 - val_loss: 277.2908 - val_mae: 16.3892\n",
            "Epoch 7611/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 277.1251 - mae: 16.2868 - val_loss: 277.2589 - val_mae: 16.3882\n",
            "Epoch 7612/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 277.0941 - mae: 16.2859 - val_loss: 277.2271 - val_mae: 16.3872\n",
            "Epoch 7613/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 277.0631 - mae: 16.2849 - val_loss: 277.1951 - val_mae: 16.3862\n",
            "Epoch 7614/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 277.0320 - mae: 16.2840 - val_loss: 277.1633 - val_mae: 16.3853\n",
            "Epoch 7615/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 277.0010 - mae: 16.2831 - val_loss: 277.1313 - val_mae: 16.3843\n",
            "Epoch 7616/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 276.9700 - mae: 16.2821 - val_loss: 277.0995 - val_mae: 16.3833\n",
            "Epoch 7617/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 276.9390 - mae: 16.2812 - val_loss: 277.0676 - val_mae: 16.3824\n",
            "Epoch 7618/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 276.9079 - mae: 16.2802 - val_loss: 277.0356 - val_mae: 16.3814\n",
            "Epoch 7619/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 276.8769 - mae: 16.2793 - val_loss: 277.0038 - val_mae: 16.3804\n",
            "Epoch 7620/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 276.8459 - mae: 16.2783 - val_loss: 276.9719 - val_mae: 16.3795\n",
            "Epoch 7621/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 276.8148 - mae: 16.2774 - val_loss: 276.9400 - val_mae: 16.3785\n",
            "Epoch 7622/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 276.7838 - mae: 16.2764 - val_loss: 276.9081 - val_mae: 16.3775\n",
            "Epoch 7623/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 276.7528 - mae: 16.2755 - val_loss: 276.8763 - val_mae: 16.3765\n",
            "Epoch 7624/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 276.7218 - mae: 16.2746 - val_loss: 276.8443 - val_mae: 16.3756\n",
            "Epoch 7625/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 276.6908 - mae: 16.2736 - val_loss: 276.8124 - val_mae: 16.3746\n",
            "Epoch 7626/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 276.6599 - mae: 16.2727 - val_loss: 276.7806 - val_mae: 16.3736\n",
            "Epoch 7627/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 276.6288 - mae: 16.2717 - val_loss: 276.7487 - val_mae: 16.3727\n",
            "Epoch 7628/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 276.5978 - mae: 16.2708 - val_loss: 276.7169 - val_mae: 16.3717\n",
            "Epoch 7629/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 276.5668 - mae: 16.2698 - val_loss: 276.6850 - val_mae: 16.3707\n",
            "Epoch 7630/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 276.5358 - mae: 16.2689 - val_loss: 276.6531 - val_mae: 16.3698\n",
            "Epoch 7631/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 276.5048 - mae: 16.2679 - val_loss: 276.6212 - val_mae: 16.3688\n",
            "Epoch 7632/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 276.4738 - mae: 16.2670 - val_loss: 276.5894 - val_mae: 16.3678\n",
            "Epoch 7633/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 276.4428 - mae: 16.2661 - val_loss: 276.5575 - val_mae: 16.3668\n",
            "Epoch 7634/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 276.4118 - mae: 16.2651 - val_loss: 276.5256 - val_mae: 16.3659\n",
            "Epoch 7635/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 276.3809 - mae: 16.2642 - val_loss: 276.4938 - val_mae: 16.3649\n",
            "Epoch 7636/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 276.3499 - mae: 16.2632 - val_loss: 276.4619 - val_mae: 16.3639\n",
            "Epoch 7637/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 276.3189 - mae: 16.2623 - val_loss: 276.4301 - val_mae: 16.3630\n",
            "Epoch 7638/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 276.2879 - mae: 16.2613 - val_loss: 276.3982 - val_mae: 16.3620\n",
            "Epoch 7639/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 276.2569 - mae: 16.2604 - val_loss: 276.3664 - val_mae: 16.3610\n",
            "Epoch 7640/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 276.2259 - mae: 16.2594 - val_loss: 276.3345 - val_mae: 16.3601\n",
            "Epoch 7641/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 276.1949 - mae: 16.2585 - val_loss: 276.3026 - val_mae: 16.3591\n",
            "Epoch 7642/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 276.1639 - mae: 16.2576 - val_loss: 276.2708 - val_mae: 16.3581\n",
            "Epoch 7643/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 276.1330 - mae: 16.2566 - val_loss: 276.2390 - val_mae: 16.3571\n",
            "Epoch 7644/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 276.1020 - mae: 16.2557 - val_loss: 276.2071 - val_mae: 16.3562\n",
            "Epoch 7645/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 276.0710 - mae: 16.2547 - val_loss: 276.1753 - val_mae: 16.3552\n",
            "Epoch 7646/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 276.0401 - mae: 16.2538 - val_loss: 276.1434 - val_mae: 16.3542\n",
            "Epoch 7647/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 276.0091 - mae: 16.2528 - val_loss: 276.1116 - val_mae: 16.3533\n",
            "Epoch 7648/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 275.9781 - mae: 16.2519 - val_loss: 276.0798 - val_mae: 16.3523\n",
            "Epoch 7649/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 275.9472 - mae: 16.2509 - val_loss: 276.0479 - val_mae: 16.3513\n",
            "Epoch 7650/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 275.9162 - mae: 16.2500 - val_loss: 276.0161 - val_mae: 16.3503\n",
            "Epoch 7651/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 275.8853 - mae: 16.2491 - val_loss: 275.9843 - val_mae: 16.3494\n",
            "Epoch 7652/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 275.8543 - mae: 16.2481 - val_loss: 275.9525 - val_mae: 16.3484\n",
            "Epoch 7653/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 275.8233 - mae: 16.2472 - val_loss: 275.9206 - val_mae: 16.3474\n",
            "Epoch 7654/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 275.7924 - mae: 16.2462 - val_loss: 275.8888 - val_mae: 16.3465\n",
            "Epoch 7655/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 275.7614 - mae: 16.2453 - val_loss: 275.8570 - val_mae: 16.3455\n",
            "Epoch 7656/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 275.7305 - mae: 16.2443 - val_loss: 275.8251 - val_mae: 16.3445\n",
            "Epoch 7657/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 275.6995 - mae: 16.2434 - val_loss: 275.7933 - val_mae: 16.3436\n",
            "Epoch 7658/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 275.6685 - mae: 16.2425 - val_loss: 275.7615 - val_mae: 16.3426\n",
            "Epoch 7659/10000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 275.6376 - mae: 16.2415 - val_loss: 275.7297 - val_mae: 16.3416\n",
            "Epoch 7660/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 275.6067 - mae: 16.2406 - val_loss: 275.6979 - val_mae: 16.3406\n",
            "Epoch 7661/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 275.5757 - mae: 16.2396 - val_loss: 275.6661 - val_mae: 16.3397\n",
            "Epoch 7662/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 275.5448 - mae: 16.2387 - val_loss: 275.6343 - val_mae: 16.3387\n",
            "Epoch 7663/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 275.5139 - mae: 16.2377 - val_loss: 275.6025 - val_mae: 16.3377\n",
            "Epoch 7664/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 275.4829 - mae: 16.2368 - val_loss: 275.5706 - val_mae: 16.3368\n",
            "Epoch 7665/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 275.4520 - mae: 16.2358 - val_loss: 275.5389 - val_mae: 16.3358\n",
            "Epoch 7666/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 275.4211 - mae: 16.2349 - val_loss: 275.5070 - val_mae: 16.3348\n",
            "Epoch 7667/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 275.3901 - mae: 16.2340 - val_loss: 275.4753 - val_mae: 16.3339\n",
            "Epoch 7668/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 275.3592 - mae: 16.2330 - val_loss: 275.4435 - val_mae: 16.3329\n",
            "Epoch 7669/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 275.3283 - mae: 16.2321 - val_loss: 275.4117 - val_mae: 16.3319\n",
            "Epoch 7670/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 275.2973 - mae: 16.2311 - val_loss: 275.3799 - val_mae: 16.3309\n",
            "Epoch 7671/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 275.2664 - mae: 16.2302 - val_loss: 275.3481 - val_mae: 16.3300\n",
            "Epoch 7672/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 275.2355 - mae: 16.2292 - val_loss: 275.3163 - val_mae: 16.3290\n",
            "Epoch 7673/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 275.2046 - mae: 16.2283 - val_loss: 275.2845 - val_mae: 16.3280\n",
            "Epoch 7674/10000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 275.1737 - mae: 16.2273 - val_loss: 275.2527 - val_mae: 16.3271\n",
            "Epoch 7675/10000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 275.1428 - mae: 16.2264 - val_loss: 275.2210 - val_mae: 16.3261\n",
            "Epoch 7676/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 275.1118 - mae: 16.2255 - val_loss: 275.1891 - val_mae: 16.3251\n",
            "Epoch 7677/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 275.0809 - mae: 16.2245 - val_loss: 275.1574 - val_mae: 16.3241\n",
            "Epoch 7678/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 275.0500 - mae: 16.2236 - val_loss: 275.1256 - val_mae: 16.3232\n",
            "Epoch 7679/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 275.0191 - mae: 16.2226 - val_loss: 275.0938 - val_mae: 16.3222\n",
            "Epoch 7680/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 274.9882 - mae: 16.2217 - val_loss: 275.0621 - val_mae: 16.3212\n",
            "Epoch 7681/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 274.9573 - mae: 16.2207 - val_loss: 275.0303 - val_mae: 16.3203\n",
            "Epoch 7682/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 274.9264 - mae: 16.2198 - val_loss: 274.9985 - val_mae: 16.3193\n",
            "Epoch 7683/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 274.8955 - mae: 16.2189 - val_loss: 274.9668 - val_mae: 16.3183\n",
            "Epoch 7684/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 274.8646 - mae: 16.2179 - val_loss: 274.9350 - val_mae: 16.3174\n",
            "Epoch 7685/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 274.8337 - mae: 16.2170 - val_loss: 274.9033 - val_mae: 16.3164\n",
            "Epoch 7686/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 274.8028 - mae: 16.2160 - val_loss: 274.8715 - val_mae: 16.3154\n",
            "Epoch 7687/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 274.7719 - mae: 16.2151 - val_loss: 274.8398 - val_mae: 16.3144\n",
            "Epoch 7688/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 274.7410 - mae: 16.2141 - val_loss: 274.8080 - val_mae: 16.3135\n",
            "Epoch 7689/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 274.7101 - mae: 16.2132 - val_loss: 274.7762 - val_mae: 16.3125\n",
            "Epoch 7690/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 274.6793 - mae: 16.2122 - val_loss: 274.7444 - val_mae: 16.3115\n",
            "Epoch 7691/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 274.6484 - mae: 16.2113 - val_loss: 274.7127 - val_mae: 16.3106\n",
            "Epoch 7692/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 274.6175 - mae: 16.2104 - val_loss: 274.6810 - val_mae: 16.3096\n",
            "Epoch 7693/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 274.5866 - mae: 16.2094 - val_loss: 274.6492 - val_mae: 16.3086\n",
            "Epoch 7694/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 274.5557 - mae: 16.2085 - val_loss: 274.6175 - val_mae: 16.3077\n",
            "Epoch 7695/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 274.5248 - mae: 16.2075 - val_loss: 274.5858 - val_mae: 16.3067\n",
            "Epoch 7696/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 274.4940 - mae: 16.2066 - val_loss: 274.5540 - val_mae: 16.3057\n",
            "Epoch 7697/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 274.4631 - mae: 16.2056 - val_loss: 274.5223 - val_mae: 16.3047\n",
            "Epoch 7698/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 274.4323 - mae: 16.2047 - val_loss: 274.4905 - val_mae: 16.3038\n",
            "Epoch 7699/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 274.4013 - mae: 16.2037 - val_loss: 274.4588 - val_mae: 16.3028\n",
            "Epoch 7700/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 274.3705 - mae: 16.2028 - val_loss: 274.4271 - val_mae: 16.3018\n",
            "Epoch 7701/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 274.3396 - mae: 16.2019 - val_loss: 274.3953 - val_mae: 16.3009\n",
            "Epoch 7702/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 274.3088 - mae: 16.2009 - val_loss: 274.3636 - val_mae: 16.2999\n",
            "Epoch 7703/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 274.2779 - mae: 16.2000 - val_loss: 274.3318 - val_mae: 16.2989\n",
            "Epoch 7704/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 274.2470 - mae: 16.1990 - val_loss: 274.3001 - val_mae: 16.2979\n",
            "Epoch 7705/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 274.2162 - mae: 16.1981 - val_loss: 274.2684 - val_mae: 16.2970\n",
            "Epoch 7706/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 274.1853 - mae: 16.1971 - val_loss: 274.2367 - val_mae: 16.2960\n",
            "Epoch 7707/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 274.1544 - mae: 16.1962 - val_loss: 274.2050 - val_mae: 16.2950\n",
            "Epoch 7708/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 274.1236 - mae: 16.1952 - val_loss: 274.1733 - val_mae: 16.2941\n",
            "Epoch 7709/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 274.0927 - mae: 16.1943 - val_loss: 274.1415 - val_mae: 16.2931\n",
            "Epoch 7710/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 274.0619 - mae: 16.1934 - val_loss: 274.1098 - val_mae: 16.2921\n",
            "Epoch 7711/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 274.0310 - mae: 16.1924 - val_loss: 274.0781 - val_mae: 16.2912\n",
            "Epoch 7712/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 274.0002 - mae: 16.1915 - val_loss: 274.0464 - val_mae: 16.2902\n",
            "Epoch 7713/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 273.9694 - mae: 16.1905 - val_loss: 274.0147 - val_mae: 16.2892\n",
            "Epoch 7714/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 273.9385 - mae: 16.1896 - val_loss: 273.9830 - val_mae: 16.2882\n",
            "Epoch 7715/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 273.9077 - mae: 16.1886 - val_loss: 273.9513 - val_mae: 16.2873\n",
            "Epoch 7716/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 273.8769 - mae: 16.1877 - val_loss: 273.9196 - val_mae: 16.2863\n",
            "Epoch 7717/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 273.8460 - mae: 16.1868 - val_loss: 273.8879 - val_mae: 16.2853\n",
            "Epoch 7718/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 273.8152 - mae: 16.1858 - val_loss: 273.8562 - val_mae: 16.2844\n",
            "Epoch 7719/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 273.7843 - mae: 16.1849 - val_loss: 273.8245 - val_mae: 16.2834\n",
            "Epoch 7720/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 273.7535 - mae: 16.1839 - val_loss: 273.7928 - val_mae: 16.2824\n",
            "Epoch 7721/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 273.7227 - mae: 16.1830 - val_loss: 273.7611 - val_mae: 16.2815\n",
            "Epoch 7722/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 273.6919 - mae: 16.1820 - val_loss: 273.7294 - val_mae: 16.2805\n",
            "Epoch 7723/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 273.6611 - mae: 16.1811 - val_loss: 273.6978 - val_mae: 16.2795\n",
            "Epoch 7724/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 273.6302 - mae: 16.1801 - val_loss: 273.6660 - val_mae: 16.2785\n",
            "Epoch 7725/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 273.5994 - mae: 16.1792 - val_loss: 273.6344 - val_mae: 16.2776\n",
            "Epoch 7726/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 273.5686 - mae: 16.1783 - val_loss: 273.6027 - val_mae: 16.2766\n",
            "Epoch 7727/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 273.5378 - mae: 16.1773 - val_loss: 273.5710 - val_mae: 16.2756\n",
            "Epoch 7728/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 273.5069 - mae: 16.1764 - val_loss: 273.5393 - val_mae: 16.2747\n",
            "Epoch 7729/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 273.4761 - mae: 16.1754 - val_loss: 273.5077 - val_mae: 16.2737\n",
            "Epoch 7730/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 273.4453 - mae: 16.1745 - val_loss: 273.4760 - val_mae: 16.2727\n",
            "Epoch 7731/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 273.4145 - mae: 16.1735 - val_loss: 273.4443 - val_mae: 16.2718\n",
            "Epoch 7732/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 273.3837 - mae: 16.1726 - val_loss: 273.4127 - val_mae: 16.2708\n",
            "Epoch 7733/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 273.3529 - mae: 16.1716 - val_loss: 273.3810 - val_mae: 16.2698\n",
            "Epoch 7734/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 273.3221 - mae: 16.1707 - val_loss: 273.3493 - val_mae: 16.2688\n",
            "Epoch 7735/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 273.2913 - mae: 16.1698 - val_loss: 273.3176 - val_mae: 16.2679\n",
            "Epoch 7736/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 273.2605 - mae: 16.1688 - val_loss: 273.2860 - val_mae: 16.2669\n",
            "Epoch 7737/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 273.2296 - mae: 16.1679 - val_loss: 273.2543 - val_mae: 16.2659\n",
            "Epoch 7738/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 273.1989 - mae: 16.1669 - val_loss: 273.2227 - val_mae: 16.2650\n",
            "Epoch 7739/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 273.1681 - mae: 16.1660 - val_loss: 273.1910 - val_mae: 16.2640\n",
            "Epoch 7740/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 273.1373 - mae: 16.1650 - val_loss: 273.1594 - val_mae: 16.2630\n",
            "Epoch 7741/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 273.1065 - mae: 16.1641 - val_loss: 273.1277 - val_mae: 16.2620\n",
            "Epoch 7742/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 273.0757 - mae: 16.1631 - val_loss: 273.0960 - val_mae: 16.2611\n",
            "Epoch 7743/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 273.0449 - mae: 16.1622 - val_loss: 273.0644 - val_mae: 16.2601\n",
            "Epoch 7744/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 273.0142 - mae: 16.1613 - val_loss: 273.0328 - val_mae: 16.2591\n",
            "Epoch 7745/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 272.9834 - mae: 16.1603 - val_loss: 273.0011 - val_mae: 16.2582\n",
            "Epoch 7746/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 272.9526 - mae: 16.1594 - val_loss: 272.9695 - val_mae: 16.2572\n",
            "Epoch 7747/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 272.9218 - mae: 16.1584 - val_loss: 272.9378 - val_mae: 16.2562\n",
            "Epoch 7748/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 272.8910 - mae: 16.1575 - val_loss: 272.9062 - val_mae: 16.2553\n",
            "Epoch 7749/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 272.8602 - mae: 16.1565 - val_loss: 272.8746 - val_mae: 16.2543\n",
            "Epoch 7750/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 272.8294 - mae: 16.1556 - val_loss: 272.8429 - val_mae: 16.2533\n",
            "Epoch 7751/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 272.7987 - mae: 16.1546 - val_loss: 272.8113 - val_mae: 16.2523\n",
            "Epoch 7752/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 272.7679 - mae: 16.1537 - val_loss: 272.7796 - val_mae: 16.2514\n",
            "Epoch 7753/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 272.7372 - mae: 16.1528 - val_loss: 272.7480 - val_mae: 16.2504\n",
            "Epoch 7754/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 272.7064 - mae: 16.1518 - val_loss: 272.7164 - val_mae: 16.2494\n",
            "Epoch 7755/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 272.6756 - mae: 16.1509 - val_loss: 272.6848 - val_mae: 16.2485\n",
            "Epoch 7756/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 272.6449 - mae: 16.1499 - val_loss: 272.6531 - val_mae: 16.2475\n",
            "Epoch 7757/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 272.6141 - mae: 16.1490 - val_loss: 272.6215 - val_mae: 16.2465\n",
            "Epoch 7758/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 272.5833 - mae: 16.1480 - val_loss: 272.5899 - val_mae: 16.2456\n",
            "Epoch 7759/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 272.5526 - mae: 16.1471 - val_loss: 272.5583 - val_mae: 16.2446\n",
            "Epoch 7760/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 272.5219 - mae: 16.1462 - val_loss: 272.5267 - val_mae: 16.2436\n",
            "Epoch 7761/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 272.4911 - mae: 16.1452 - val_loss: 272.4951 - val_mae: 16.2426\n",
            "Epoch 7762/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 272.4604 - mae: 16.1443 - val_loss: 272.4635 - val_mae: 16.2417\n",
            "Epoch 7763/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 272.4296 - mae: 16.1433 - val_loss: 272.4319 - val_mae: 16.2407\n",
            "Epoch 7764/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 272.3989 - mae: 16.1424 - val_loss: 272.4003 - val_mae: 16.2397\n",
            "Epoch 7765/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 272.3682 - mae: 16.1414 - val_loss: 272.3687 - val_mae: 16.2388\n",
            "Epoch 7766/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 272.3374 - mae: 16.1405 - val_loss: 272.3372 - val_mae: 16.2378\n",
            "Epoch 7767/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 272.3067 - mae: 16.1395 - val_loss: 272.3056 - val_mae: 16.2368\n",
            "Epoch 7768/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 272.2760 - mae: 16.1386 - val_loss: 272.2740 - val_mae: 16.2359\n",
            "Epoch 7769/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 272.2453 - mae: 16.1377 - val_loss: 272.2424 - val_mae: 16.2349\n",
            "Epoch 7770/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 272.2145 - mae: 16.1367 - val_loss: 272.2108 - val_mae: 16.2339\n",
            "Epoch 7771/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 272.1838 - mae: 16.1358 - val_loss: 272.1793 - val_mae: 16.2329\n",
            "Epoch 7772/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 272.1531 - mae: 16.1348 - val_loss: 272.1476 - val_mae: 16.2320\n",
            "Epoch 7773/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 272.1224 - mae: 16.1339 - val_loss: 272.1161 - val_mae: 16.2310\n",
            "Epoch 7774/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 272.0917 - mae: 16.1329 - val_loss: 272.0845 - val_mae: 16.2300\n",
            "Epoch 7775/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 272.0610 - mae: 16.1320 - val_loss: 272.0529 - val_mae: 16.2291\n",
            "Epoch 7776/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 272.0303 - mae: 16.1311 - val_loss: 272.0214 - val_mae: 16.2281\n",
            "Epoch 7777/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 271.9996 - mae: 16.1301 - val_loss: 271.9898 - val_mae: 16.2271\n",
            "Epoch 7778/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 271.9688 - mae: 16.1292 - val_loss: 271.9583 - val_mae: 16.2262\n",
            "Epoch 7779/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 271.9381 - mae: 16.1282 - val_loss: 271.9267 - val_mae: 16.2252\n",
            "Epoch 7780/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 271.9074 - mae: 16.1273 - val_loss: 271.8951 - val_mae: 16.2242\n",
            "Epoch 7781/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 271.8767 - mae: 16.1263 - val_loss: 271.8636 - val_mae: 16.2233\n",
            "Epoch 7782/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 271.8460 - mae: 16.1254 - val_loss: 271.8320 - val_mae: 16.2223\n",
            "Epoch 7783/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 271.8153 - mae: 16.1244 - val_loss: 271.8005 - val_mae: 16.2213\n",
            "Epoch 7784/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 271.7846 - mae: 16.1235 - val_loss: 271.7689 - val_mae: 16.2203\n",
            "Epoch 7785/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 271.7539 - mae: 16.1226 - val_loss: 271.7374 - val_mae: 16.2194\n",
            "Epoch 7786/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 271.7232 - mae: 16.1216 - val_loss: 271.7058 - val_mae: 16.2184\n",
            "Epoch 7787/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 271.6926 - mae: 16.1207 - val_loss: 271.6743 - val_mae: 16.2174\n",
            "Epoch 7788/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 271.6619 - mae: 16.1197 - val_loss: 271.6427 - val_mae: 16.2165\n",
            "Epoch 7789/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 271.6312 - mae: 16.1188 - val_loss: 271.6112 - val_mae: 16.2155\n",
            "Epoch 7790/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 271.6005 - mae: 16.1178 - val_loss: 271.5797 - val_mae: 16.2145\n",
            "Epoch 7791/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 271.5698 - mae: 16.1169 - val_loss: 271.5481 - val_mae: 16.2136\n",
            "Epoch 7792/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 271.5391 - mae: 16.1160 - val_loss: 271.5166 - val_mae: 16.2126\n",
            "Epoch 7793/10000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 271.5085 - mae: 16.1150 - val_loss: 271.4850 - val_mae: 16.2116\n",
            "Epoch 7794/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 271.4778 - mae: 16.1141 - val_loss: 271.4535 - val_mae: 16.2106\n",
            "Epoch 7795/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 271.4471 - mae: 16.1131 - val_loss: 271.4220 - val_mae: 16.2097\n",
            "Epoch 7796/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 271.4164 - mae: 16.1122 - val_loss: 271.3904 - val_mae: 16.2087\n",
            "Epoch 7797/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 271.3858 - mae: 16.1112 - val_loss: 271.3589 - val_mae: 16.2077\n",
            "Epoch 7798/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 271.3551 - mae: 16.1103 - val_loss: 271.3274 - val_mae: 16.2068\n",
            "Epoch 7799/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 271.3245 - mae: 16.1093 - val_loss: 271.2959 - val_mae: 16.2058\n",
            "Epoch 7800/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 271.2938 - mae: 16.1084 - val_loss: 271.2643 - val_mae: 16.2048\n",
            "Epoch 7801/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 271.2631 - mae: 16.1075 - val_loss: 271.2328 - val_mae: 16.2039\n",
            "Epoch 7802/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 271.2325 - mae: 16.1065 - val_loss: 271.2013 - val_mae: 16.2029\n",
            "Epoch 7803/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 271.2018 - mae: 16.1056 - val_loss: 271.1698 - val_mae: 16.2019\n",
            "Epoch 7804/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 271.1711 - mae: 16.1046 - val_loss: 271.1383 - val_mae: 16.2009\n",
            "Epoch 7805/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 271.1405 - mae: 16.1037 - val_loss: 271.1068 - val_mae: 16.2000\n",
            "Epoch 7806/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 271.1098 - mae: 16.1027 - val_loss: 271.0753 - val_mae: 16.1990\n",
            "Epoch 7807/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 271.0792 - mae: 16.1018 - val_loss: 271.0438 - val_mae: 16.1980\n",
            "Epoch 7808/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 271.0486 - mae: 16.1009 - val_loss: 271.0123 - val_mae: 16.1971\n",
            "Epoch 7809/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 271.0179 - mae: 16.0999 - val_loss: 270.9808 - val_mae: 16.1961\n",
            "Epoch 7810/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 270.9872 - mae: 16.0990 - val_loss: 270.9493 - val_mae: 16.1951\n",
            "Epoch 7811/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 270.9566 - mae: 16.0980 - val_loss: 270.9178 - val_mae: 16.1942\n",
            "Epoch 7812/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 270.9260 - mae: 16.0971 - val_loss: 270.8863 - val_mae: 16.1932\n",
            "Epoch 7813/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 270.8953 - mae: 16.0961 - val_loss: 270.8548 - val_mae: 16.1922\n",
            "Epoch 7814/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 270.8647 - mae: 16.0952 - val_loss: 270.8233 - val_mae: 16.1912\n",
            "Epoch 7815/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 270.8340 - mae: 16.0943 - val_loss: 270.7918 - val_mae: 16.1903\n",
            "Epoch 7816/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 270.8034 - mae: 16.0933 - val_loss: 270.7603 - val_mae: 16.1893\n",
            "Epoch 7817/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 270.7728 - mae: 16.0924 - val_loss: 270.7288 - val_mae: 16.1883\n",
            "Epoch 7818/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 270.7421 - mae: 16.0914 - val_loss: 270.6973 - val_mae: 16.1874\n",
            "Epoch 7819/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 270.7115 - mae: 16.0905 - val_loss: 270.6658 - val_mae: 16.1864\n",
            "Epoch 7820/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 270.6809 - mae: 16.0895 - val_loss: 270.6344 - val_mae: 16.1854\n",
            "Epoch 7821/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 270.6503 - mae: 16.0886 - val_loss: 270.6029 - val_mae: 16.1845\n",
            "Epoch 7822/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 270.6197 - mae: 16.0876 - val_loss: 270.5714 - val_mae: 16.1835\n",
            "Epoch 7823/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 270.5890 - mae: 16.0867 - val_loss: 270.5399 - val_mae: 16.1825\n",
            "Epoch 7824/10000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 270.5584 - mae: 16.0858 - val_loss: 270.5085 - val_mae: 16.1816\n",
            "Epoch 7825/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 270.5278 - mae: 16.0848 - val_loss: 270.4770 - val_mae: 16.1806\n",
            "Epoch 7826/10000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 270.4972 - mae: 16.0839 - val_loss: 270.4455 - val_mae: 16.1796\n",
            "Epoch 7827/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 270.4666 - mae: 16.0829 - val_loss: 270.4141 - val_mae: 16.1786\n",
            "Epoch 7828/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 270.4359 - mae: 16.0820 - val_loss: 270.3826 - val_mae: 16.1777\n",
            "Epoch 7829/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 270.4054 - mae: 16.0810 - val_loss: 270.3511 - val_mae: 16.1767\n",
            "Epoch 7830/10000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 270.3747 - mae: 16.0801 - val_loss: 270.3197 - val_mae: 16.1757\n",
            "Epoch 7831/10000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 270.3441 - mae: 16.0792 - val_loss: 270.2882 - val_mae: 16.1748\n",
            "Epoch 7832/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 270.3135 - mae: 16.0782 - val_loss: 270.2567 - val_mae: 16.1738\n",
            "Epoch 7833/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 270.2829 - mae: 16.0773 - val_loss: 270.2253 - val_mae: 16.1728\n",
            "Epoch 7834/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 270.2523 - mae: 16.0763 - val_loss: 270.1938 - val_mae: 16.1719\n",
            "Epoch 7835/10000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 270.2217 - mae: 16.0754 - val_loss: 270.1624 - val_mae: 16.1709\n",
            "Epoch 7836/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 270.1911 - mae: 16.0744 - val_loss: 270.1309 - val_mae: 16.1699\n",
            "Epoch 7837/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 270.1606 - mae: 16.0735 - val_loss: 270.0995 - val_mae: 16.1689\n",
            "Epoch 7838/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 270.1299 - mae: 16.0725 - val_loss: 270.0681 - val_mae: 16.1680\n",
            "Epoch 7839/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 270.0994 - mae: 16.0716 - val_loss: 270.0366 - val_mae: 16.1670\n",
            "Epoch 7840/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 270.0687 - mae: 16.0707 - val_loss: 270.0052 - val_mae: 16.1660\n",
            "Epoch 7841/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 270.0381 - mae: 16.0697 - val_loss: 269.9737 - val_mae: 16.1651\n",
            "Epoch 7842/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 270.0076 - mae: 16.0688 - val_loss: 269.9423 - val_mae: 16.1641\n",
            "Epoch 7843/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 269.9770 - mae: 16.0678 - val_loss: 269.9108 - val_mae: 16.1631\n",
            "Epoch 7844/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 269.9464 - mae: 16.0669 - val_loss: 269.8794 - val_mae: 16.1622\n",
            "Epoch 7845/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 269.9158 - mae: 16.0659 - val_loss: 269.8480 - val_mae: 16.1612\n",
            "Epoch 7846/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 269.8853 - mae: 16.0650 - val_loss: 269.8166 - val_mae: 16.1602\n",
            "Epoch 7847/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 269.8547 - mae: 16.0641 - val_loss: 269.7852 - val_mae: 16.1593\n",
            "Epoch 7848/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 269.8241 - mae: 16.0631 - val_loss: 269.7537 - val_mae: 16.1583\n",
            "Epoch 7849/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 269.7935 - mae: 16.0622 - val_loss: 269.7223 - val_mae: 16.1573\n",
            "Epoch 7850/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 269.7630 - mae: 16.0612 - val_loss: 269.6909 - val_mae: 16.1563\n",
            "Epoch 7851/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 269.7324 - mae: 16.0603 - val_loss: 269.6594 - val_mae: 16.1554\n",
            "Epoch 7852/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 269.7018 - mae: 16.0593 - val_loss: 269.6280 - val_mae: 16.1544\n",
            "Epoch 7853/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 269.6713 - mae: 16.0584 - val_loss: 269.5966 - val_mae: 16.1534\n",
            "Epoch 7854/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 269.6407 - mae: 16.0574 - val_loss: 269.5652 - val_mae: 16.1525\n",
            "Epoch 7855/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 269.6101 - mae: 16.0565 - val_loss: 269.5338 - val_mae: 16.1515\n",
            "Epoch 7856/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 269.5796 - mae: 16.0556 - val_loss: 269.5024 - val_mae: 16.1505\n",
            "Epoch 7857/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 269.5490 - mae: 16.0546 - val_loss: 269.4710 - val_mae: 16.1496\n",
            "Epoch 7858/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 269.5185 - mae: 16.0537 - val_loss: 269.4396 - val_mae: 16.1486\n",
            "Epoch 7859/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 269.4879 - mae: 16.0527 - val_loss: 269.4081 - val_mae: 16.1476\n",
            "Epoch 7860/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 269.4573 - mae: 16.0518 - val_loss: 269.3768 - val_mae: 16.1466\n",
            "Epoch 7861/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 269.4268 - mae: 16.0508 - val_loss: 269.3454 - val_mae: 16.1457\n",
            "Epoch 7862/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 269.3962 - mae: 16.0499 - val_loss: 269.3140 - val_mae: 16.1447\n",
            "Epoch 7863/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 269.3657 - mae: 16.0490 - val_loss: 269.2826 - val_mae: 16.1437\n",
            "Epoch 7864/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 269.3352 - mae: 16.0480 - val_loss: 269.2512 - val_mae: 16.1428\n",
            "Epoch 7865/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 269.3046 - mae: 16.0471 - val_loss: 269.2198 - val_mae: 16.1418\n",
            "Epoch 7866/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 269.2741 - mae: 16.0461 - val_loss: 269.1884 - val_mae: 16.1408\n",
            "Epoch 7867/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 269.2436 - mae: 16.0452 - val_loss: 269.1570 - val_mae: 16.1399\n",
            "Epoch 7868/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 269.2130 - mae: 16.0442 - val_loss: 269.1256 - val_mae: 16.1389\n",
            "Epoch 7869/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 269.1825 - mae: 16.0433 - val_loss: 269.0942 - val_mae: 16.1379\n",
            "Epoch 7870/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 269.1519 - mae: 16.0423 - val_loss: 269.0628 - val_mae: 16.1370\n",
            "Epoch 7871/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 269.1214 - mae: 16.0414 - val_loss: 269.0315 - val_mae: 16.1360\n",
            "Epoch 7872/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 269.0909 - mae: 16.0405 - val_loss: 269.0001 - val_mae: 16.1350\n",
            "Epoch 7873/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 269.0604 - mae: 16.0395 - val_loss: 268.9687 - val_mae: 16.1340\n",
            "Epoch 7874/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 269.0298 - mae: 16.0386 - val_loss: 268.9373 - val_mae: 16.1331\n",
            "Epoch 7875/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 268.9993 - mae: 16.0376 - val_loss: 268.9059 - val_mae: 16.1321\n",
            "Epoch 7876/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 268.9688 - mae: 16.0367 - val_loss: 268.8746 - val_mae: 16.1311\n",
            "Epoch 7877/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 268.9383 - mae: 16.0357 - val_loss: 268.8432 - val_mae: 16.1302\n",
            "Epoch 7878/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 268.9077 - mae: 16.0348 - val_loss: 268.8119 - val_mae: 16.1292\n",
            "Epoch 7879/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 268.8773 - mae: 16.0339 - val_loss: 268.7805 - val_mae: 16.1282\n",
            "Epoch 7880/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 268.8467 - mae: 16.0329 - val_loss: 268.7491 - val_mae: 16.1273\n",
            "Epoch 7881/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 268.8162 - mae: 16.0320 - val_loss: 268.7178 - val_mae: 16.1263\n",
            "Epoch 7882/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 268.7857 - mae: 16.0310 - val_loss: 268.6864 - val_mae: 16.1253\n",
            "Epoch 7883/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 268.7552 - mae: 16.0301 - val_loss: 268.6551 - val_mae: 16.1243\n",
            "Epoch 7884/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 268.7247 - mae: 16.0291 - val_loss: 268.6237 - val_mae: 16.1234\n",
            "Epoch 7885/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 268.6942 - mae: 16.0282 - val_loss: 268.5923 - val_mae: 16.1224\n",
            "Epoch 7886/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 268.6637 - mae: 16.0273 - val_loss: 268.5610 - val_mae: 16.1214\n",
            "Epoch 7887/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 268.6332 - mae: 16.0263 - val_loss: 268.5296 - val_mae: 16.1205\n",
            "Epoch 7888/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 268.6027 - mae: 16.0254 - val_loss: 268.4983 - val_mae: 16.1195\n",
            "Epoch 7889/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 268.5722 - mae: 16.0244 - val_loss: 268.4670 - val_mae: 16.1185\n",
            "Epoch 7890/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 268.5417 - mae: 16.0235 - val_loss: 268.4356 - val_mae: 16.1176\n",
            "Epoch 7891/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 268.5112 - mae: 16.0225 - val_loss: 268.4043 - val_mae: 16.1166\n",
            "Epoch 7892/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 268.4807 - mae: 16.0216 - val_loss: 268.3729 - val_mae: 16.1156\n",
            "Epoch 7893/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 268.4502 - mae: 16.0206 - val_loss: 268.3416 - val_mae: 16.1147\n",
            "Epoch 7894/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 268.4197 - mae: 16.0197 - val_loss: 268.3103 - val_mae: 16.1137\n",
            "Epoch 7895/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 268.3893 - mae: 16.0188 - val_loss: 268.2790 - val_mae: 16.1127\n",
            "Epoch 7896/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 268.3588 - mae: 16.0178 - val_loss: 268.2476 - val_mae: 16.1117\n",
            "Epoch 7897/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 268.3283 - mae: 16.0169 - val_loss: 268.2162 - val_mae: 16.1108\n",
            "Epoch 7898/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 268.2978 - mae: 16.0159 - val_loss: 268.1850 - val_mae: 16.1098\n",
            "Epoch 7899/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 268.2673 - mae: 16.0150 - val_loss: 268.1536 - val_mae: 16.1088\n",
            "Epoch 7900/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 268.2368 - mae: 16.0140 - val_loss: 268.1223 - val_mae: 16.1079\n",
            "Epoch 7901/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 268.2064 - mae: 16.0131 - val_loss: 268.0910 - val_mae: 16.1069\n",
            "Epoch 7902/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 268.1759 - mae: 16.0122 - val_loss: 268.0597 - val_mae: 16.1059\n",
            "Epoch 7903/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 268.1454 - mae: 16.0112 - val_loss: 268.0284 - val_mae: 16.1050\n",
            "Epoch 7904/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 268.1150 - mae: 16.0103 - val_loss: 267.9970 - val_mae: 16.1040\n",
            "Epoch 7905/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 268.0845 - mae: 16.0093 - val_loss: 267.9657 - val_mae: 16.1030\n",
            "Epoch 7906/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 268.0540 - mae: 16.0084 - val_loss: 267.9344 - val_mae: 16.1020\n",
            "Epoch 7907/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 268.0236 - mae: 16.0074 - val_loss: 267.9031 - val_mae: 16.1011\n",
            "Epoch 7908/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 267.9931 - mae: 16.0065 - val_loss: 267.8718 - val_mae: 16.1001\n",
            "Epoch 7909/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 267.9626 - mae: 16.0055 - val_loss: 267.8405 - val_mae: 16.0991\n",
            "Epoch 7910/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 267.9322 - mae: 16.0046 - val_loss: 267.8092 - val_mae: 16.0982\n",
            "Epoch 7911/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 267.9017 - mae: 16.0037 - val_loss: 267.7779 - val_mae: 16.0972\n",
            "Epoch 7912/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 267.8713 - mae: 16.0027 - val_loss: 267.7466 - val_mae: 16.0962\n",
            "Epoch 7913/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 267.8409 - mae: 16.0018 - val_loss: 267.7153 - val_mae: 16.0953\n",
            "Epoch 7914/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 267.8104 - mae: 16.0008 - val_loss: 267.6841 - val_mae: 16.0943\n",
            "Epoch 7915/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 267.7800 - mae: 15.9999 - val_loss: 267.6528 - val_mae: 16.0933\n",
            "Epoch 7916/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 267.7496 - mae: 15.9989 - val_loss: 267.6215 - val_mae: 16.0924\n",
            "Epoch 7917/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 267.7191 - mae: 15.9980 - val_loss: 267.5903 - val_mae: 16.0914\n",
            "Epoch 7918/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 267.6887 - mae: 15.9971 - val_loss: 267.5590 - val_mae: 16.0904\n",
            "Epoch 7919/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 267.6583 - mae: 15.9961 - val_loss: 267.5277 - val_mae: 16.0894\n",
            "Epoch 7920/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 267.6278 - mae: 15.9952 - val_loss: 267.4964 - val_mae: 16.0885\n",
            "Epoch 7921/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 267.5974 - mae: 15.9942 - val_loss: 267.4652 - val_mae: 16.0875\n",
            "Epoch 7922/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 267.5670 - mae: 15.9933 - val_loss: 267.4339 - val_mae: 16.0865\n",
            "Epoch 7923/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 267.5366 - mae: 15.9923 - val_loss: 267.4026 - val_mae: 16.0856\n",
            "Epoch 7924/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 267.5062 - mae: 15.9914 - val_loss: 267.3714 - val_mae: 16.0846\n",
            "Epoch 7925/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 267.4758 - mae: 15.9905 - val_loss: 267.3401 - val_mae: 16.0836\n",
            "Epoch 7926/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 267.4453 - mae: 15.9895 - val_loss: 267.3089 - val_mae: 16.0827\n",
            "Epoch 7927/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 267.4149 - mae: 15.9886 - val_loss: 267.2776 - val_mae: 16.0817\n",
            "Epoch 7928/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 267.3845 - mae: 15.9876 - val_loss: 267.2464 - val_mae: 16.0807\n",
            "Epoch 7929/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 267.3542 - mae: 15.9867 - val_loss: 267.2151 - val_mae: 16.0798\n",
            "Epoch 7930/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 267.3237 - mae: 15.9857 - val_loss: 267.1839 - val_mae: 16.0788\n",
            "Epoch 7931/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 267.2933 - mae: 15.9848 - val_loss: 267.1526 - val_mae: 16.0778\n",
            "Epoch 7932/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 267.2629 - mae: 15.9839 - val_loss: 267.1214 - val_mae: 16.0769\n",
            "Epoch 7933/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 267.2325 - mae: 15.9829 - val_loss: 267.0901 - val_mae: 16.0759\n",
            "Epoch 7934/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 267.2021 - mae: 15.9820 - val_loss: 267.0589 - val_mae: 16.0749\n",
            "Epoch 7935/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 267.1718 - mae: 15.9810 - val_loss: 267.0277 - val_mae: 16.0739\n",
            "Epoch 7936/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 267.1413 - mae: 15.9801 - val_loss: 266.9964 - val_mae: 16.0730\n",
            "Epoch 7937/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 267.1110 - mae: 15.9791 - val_loss: 266.9652 - val_mae: 16.0720\n",
            "Epoch 7938/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 267.0806 - mae: 15.9782 - val_loss: 266.9340 - val_mae: 16.0710\n",
            "Epoch 7939/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 267.0502 - mae: 15.9773 - val_loss: 266.9027 - val_mae: 16.0701\n",
            "Epoch 7940/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 267.0198 - mae: 15.9763 - val_loss: 266.8715 - val_mae: 16.0691\n",
            "Epoch 7941/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 266.9894 - mae: 15.9754 - val_loss: 266.8403 - val_mae: 16.0681\n",
            "Epoch 7942/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 266.9590 - mae: 15.9744 - val_loss: 266.8091 - val_mae: 16.0672\n",
            "Epoch 7943/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 266.9286 - mae: 15.9735 - val_loss: 266.7778 - val_mae: 16.0662\n",
            "Epoch 7944/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 266.8983 - mae: 15.9725 - val_loss: 266.7466 - val_mae: 16.0652\n",
            "Epoch 7945/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 266.8679 - mae: 15.9716 - val_loss: 266.7154 - val_mae: 16.0643\n",
            "Epoch 7946/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 266.8375 - mae: 15.9706 - val_loss: 266.6842 - val_mae: 16.0633\n",
            "Epoch 7947/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 266.8072 - mae: 15.9697 - val_loss: 266.6530 - val_mae: 16.0623\n",
            "Epoch 7948/10000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 266.7768 - mae: 15.9688 - val_loss: 266.6217 - val_mae: 16.0613\n",
            "Epoch 7949/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 266.7464 - mae: 15.9678 - val_loss: 266.5905 - val_mae: 16.0604\n",
            "Epoch 7950/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 266.7160 - mae: 15.9669 - val_loss: 266.5593 - val_mae: 16.0594\n",
            "Epoch 7951/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 266.6857 - mae: 15.9659 - val_loss: 266.5281 - val_mae: 16.0584\n",
            "Epoch 7952/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 266.6553 - mae: 15.9650 - val_loss: 266.4969 - val_mae: 16.0575\n",
            "Epoch 7953/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 266.6249 - mae: 15.9640 - val_loss: 266.4657 - val_mae: 16.0565\n",
            "Epoch 7954/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 266.5946 - mae: 15.9631 - val_loss: 266.4345 - val_mae: 16.0555\n",
            "Epoch 7955/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 266.5642 - mae: 15.9622 - val_loss: 266.4033 - val_mae: 16.0546\n",
            "Epoch 7956/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 266.5339 - mae: 15.9612 - val_loss: 266.3721 - val_mae: 16.0536\n",
            "Epoch 7957/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 266.5035 - mae: 15.9603 - val_loss: 266.3409 - val_mae: 16.0526\n",
            "Epoch 7958/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 266.4732 - mae: 15.9593 - val_loss: 266.3097 - val_mae: 16.0517\n",
            "Epoch 7959/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 266.4428 - mae: 15.9584 - val_loss: 266.2785 - val_mae: 16.0507\n",
            "Epoch 7960/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 266.4125 - mae: 15.9574 - val_loss: 266.2474 - val_mae: 16.0497\n",
            "Epoch 7961/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 266.3821 - mae: 15.9565 - val_loss: 266.2162 - val_mae: 16.0488\n",
            "Epoch 7962/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 266.3518 - mae: 15.9556 - val_loss: 266.1850 - val_mae: 16.0478\n",
            "Epoch 7963/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 266.3214 - mae: 15.9546 - val_loss: 266.1538 - val_mae: 16.0468\n",
            "Epoch 7964/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 266.2911 - mae: 15.9537 - val_loss: 266.1226 - val_mae: 16.0458\n",
            "Epoch 7965/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 266.2608 - mae: 15.9527 - val_loss: 266.0915 - val_mae: 16.0449\n",
            "Epoch 7966/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 266.2304 - mae: 15.9518 - val_loss: 266.0603 - val_mae: 16.0439\n",
            "Epoch 7967/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 266.2001 - mae: 15.9508 - val_loss: 266.0291 - val_mae: 16.0429\n",
            "Epoch 7968/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 266.1697 - mae: 15.9499 - val_loss: 265.9979 - val_mae: 16.0420\n",
            "Epoch 7969/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 266.1394 - mae: 15.9490 - val_loss: 265.9667 - val_mae: 16.0410\n",
            "Epoch 7970/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 266.1091 - mae: 15.9480 - val_loss: 265.9356 - val_mae: 16.0400\n",
            "Epoch 7971/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 266.0788 - mae: 15.9471 - val_loss: 265.9044 - val_mae: 16.0391\n",
            "Epoch 7972/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 266.0484 - mae: 15.9461 - val_loss: 265.8732 - val_mae: 16.0381\n",
            "Epoch 7973/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 266.0181 - mae: 15.9452 - val_loss: 265.8421 - val_mae: 16.0371\n",
            "Epoch 7974/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 265.9878 - mae: 15.9442 - val_loss: 265.8109 - val_mae: 16.0362\n",
            "Epoch 7975/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 265.9575 - mae: 15.9433 - val_loss: 265.7798 - val_mae: 16.0352\n",
            "Epoch 7976/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 265.9271 - mae: 15.9424 - val_loss: 265.7486 - val_mae: 16.0342\n",
            "Epoch 7977/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 265.8969 - mae: 15.9414 - val_loss: 265.7175 - val_mae: 16.0332\n",
            "Epoch 7978/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 265.8665 - mae: 15.9405 - val_loss: 265.6863 - val_mae: 16.0323\n",
            "Epoch 7979/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 265.8362 - mae: 15.9395 - val_loss: 265.6552 - val_mae: 16.0313\n",
            "Epoch 7980/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 265.8059 - mae: 15.9386 - val_loss: 265.6240 - val_mae: 16.0303\n",
            "Epoch 7981/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 265.7756 - mae: 15.9376 - val_loss: 265.5929 - val_mae: 16.0294\n",
            "Epoch 7982/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 265.7453 - mae: 15.9367 - val_loss: 265.5617 - val_mae: 16.0284\n",
            "Epoch 7983/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 265.7150 - mae: 15.9358 - val_loss: 265.5306 - val_mae: 16.0274\n",
            "Epoch 7984/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 265.6847 - mae: 15.9348 - val_loss: 265.4994 - val_mae: 16.0265\n",
            "Epoch 7985/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 265.6544 - mae: 15.9339 - val_loss: 265.4683 - val_mae: 16.0255\n",
            "Epoch 7986/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 265.6241 - mae: 15.9329 - val_loss: 265.4372 - val_mae: 16.0245\n",
            "Epoch 7987/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 265.5938 - mae: 15.9320 - val_loss: 265.4060 - val_mae: 16.0236\n",
            "Epoch 7988/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 265.5635 - mae: 15.9310 - val_loss: 265.3749 - val_mae: 16.0226\n",
            "Epoch 7989/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 265.5332 - mae: 15.9301 - val_loss: 265.3438 - val_mae: 16.0216\n",
            "Epoch 7990/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 265.5029 - mae: 15.9291 - val_loss: 265.3127 - val_mae: 16.0207\n",
            "Epoch 7991/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 265.4726 - mae: 15.9282 - val_loss: 265.2815 - val_mae: 16.0197\n",
            "Epoch 7992/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 265.4423 - mae: 15.9273 - val_loss: 265.2504 - val_mae: 16.0187\n",
            "Epoch 7993/10000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 265.4120 - mae: 15.9263 - val_loss: 265.2192 - val_mae: 16.0177\n",
            "Epoch 7994/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 265.3817 - mae: 15.9254 - val_loss: 265.1881 - val_mae: 16.0168\n",
            "Epoch 7995/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 265.3514 - mae: 15.9244 - val_loss: 265.1570 - val_mae: 16.0158\n",
            "Epoch 7996/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 265.3212 - mae: 15.9235 - val_loss: 265.1259 - val_mae: 16.0148\n",
            "Epoch 7997/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 265.2909 - mae: 15.9225 - val_loss: 265.0948 - val_mae: 16.0139\n",
            "Epoch 7998/10000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 265.2607 - mae: 15.9216 - val_loss: 265.0637 - val_mae: 16.0129\n",
            "Epoch 7999/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 265.2303 - mae: 15.9207 - val_loss: 265.0326 - val_mae: 16.0119\n",
            "Epoch 8000/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 265.2001 - mae: 15.9197 - val_loss: 265.0014 - val_mae: 16.0110\n",
            "Epoch 8001/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 265.1698 - mae: 15.9188 - val_loss: 264.9703 - val_mae: 16.0100\n",
            "Epoch 8002/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 265.1395 - mae: 15.9178 - val_loss: 264.9392 - val_mae: 16.0090\n",
            "Epoch 8003/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 265.1093 - mae: 15.9169 - val_loss: 264.9081 - val_mae: 16.0081\n",
            "Epoch 8004/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 265.0790 - mae: 15.9159 - val_loss: 264.8770 - val_mae: 16.0071\n",
            "Epoch 8005/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 265.0487 - mae: 15.9150 - val_loss: 264.8459 - val_mae: 16.0061\n",
            "Epoch 8006/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 265.0185 - mae: 15.9141 - val_loss: 264.8148 - val_mae: 16.0052\n",
            "Epoch 8007/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 264.9882 - mae: 15.9131 - val_loss: 264.7838 - val_mae: 16.0042\n",
            "Epoch 8008/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 264.9580 - mae: 15.9122 - val_loss: 264.7526 - val_mae: 16.0032\n",
            "Epoch 8009/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 264.9277 - mae: 15.9112 - val_loss: 264.7215 - val_mae: 16.0022\n",
            "Epoch 8010/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 264.8975 - mae: 15.9103 - val_loss: 264.6905 - val_mae: 16.0013\n",
            "Epoch 8011/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 264.8672 - mae: 15.9093 - val_loss: 264.6594 - val_mae: 16.0003\n",
            "Epoch 8012/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 264.8369 - mae: 15.9084 - val_loss: 264.6283 - val_mae: 15.9993\n",
            "Epoch 8013/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 264.8067 - mae: 15.9075 - val_loss: 264.5972 - val_mae: 15.9984\n",
            "Epoch 8014/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 264.7765 - mae: 15.9065 - val_loss: 264.5661 - val_mae: 15.9974\n",
            "Epoch 8015/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 264.7462 - mae: 15.9056 - val_loss: 264.5351 - val_mae: 15.9964\n",
            "Epoch 8016/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 264.7159 - mae: 15.9046 - val_loss: 264.5040 - val_mae: 15.9955\n",
            "Epoch 8017/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 264.6857 - mae: 15.9037 - val_loss: 264.4729 - val_mae: 15.9945\n",
            "Epoch 8018/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 264.6555 - mae: 15.9027 - val_loss: 264.4418 - val_mae: 15.9935\n",
            "Epoch 8019/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 264.6253 - mae: 15.9018 - val_loss: 264.4107 - val_mae: 15.9926\n",
            "Epoch 8020/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 264.5950 - mae: 15.9009 - val_loss: 264.3797 - val_mae: 15.9916\n",
            "Epoch 8021/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 264.5648 - mae: 15.8999 - val_loss: 264.3486 - val_mae: 15.9906\n",
            "Epoch 8022/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 264.5345 - mae: 15.8990 - val_loss: 264.3175 - val_mae: 15.9896\n",
            "Epoch 8023/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 264.5043 - mae: 15.8980 - val_loss: 264.2865 - val_mae: 15.9887\n",
            "Epoch 8024/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 264.4741 - mae: 15.8971 - val_loss: 264.2554 - val_mae: 15.9877\n",
            "Epoch 8025/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 264.4439 - mae: 15.8961 - val_loss: 264.2243 - val_mae: 15.9867\n",
            "Epoch 8026/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 264.4136 - mae: 15.8952 - val_loss: 264.1933 - val_mae: 15.9858\n",
            "Epoch 8027/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 264.3834 - mae: 15.8942 - val_loss: 264.1623 - val_mae: 15.9848\n",
            "Epoch 8028/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 264.3532 - mae: 15.8933 - val_loss: 264.1312 - val_mae: 15.9838\n",
            "Epoch 8029/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 264.3230 - mae: 15.8924 - val_loss: 264.1001 - val_mae: 15.9829\n",
            "Epoch 8030/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 264.2928 - mae: 15.8914 - val_loss: 264.0691 - val_mae: 15.9819\n",
            "Epoch 8031/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 264.2625 - mae: 15.8905 - val_loss: 264.0380 - val_mae: 15.9809\n",
            "Epoch 8032/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 264.2323 - mae: 15.8895 - val_loss: 264.0070 - val_mae: 15.9800\n",
            "Epoch 8033/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 264.2021 - mae: 15.8886 - val_loss: 263.9760 - val_mae: 15.9790\n",
            "Epoch 8034/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 264.1719 - mae: 15.8876 - val_loss: 263.9449 - val_mae: 15.9780\n",
            "Epoch 8035/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 264.1417 - mae: 15.8867 - val_loss: 263.9139 - val_mae: 15.9771\n",
            "Epoch 8036/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 264.1115 - mae: 15.8858 - val_loss: 263.8828 - val_mae: 15.9761\n",
            "Epoch 8037/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 264.0813 - mae: 15.8848 - val_loss: 263.8518 - val_mae: 15.9751\n",
            "Epoch 8038/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 264.0511 - mae: 15.8839 - val_loss: 263.8207 - val_mae: 15.9741\n",
            "Epoch 8039/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 264.0209 - mae: 15.8829 - val_loss: 263.7897 - val_mae: 15.9732\n",
            "Epoch 8040/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 263.9907 - mae: 15.8820 - val_loss: 263.7587 - val_mae: 15.9722\n",
            "Epoch 8041/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 263.9605 - mae: 15.8810 - val_loss: 263.7277 - val_mae: 15.9712\n",
            "Epoch 8042/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 263.9303 - mae: 15.8801 - val_loss: 263.6967 - val_mae: 15.9703\n",
            "Epoch 8043/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 263.9001 - mae: 15.8792 - val_loss: 263.6656 - val_mae: 15.9693\n",
            "Epoch 8044/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 263.8699 - mae: 15.8782 - val_loss: 263.6346 - val_mae: 15.9683\n",
            "Epoch 8045/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 263.8397 - mae: 15.8773 - val_loss: 263.6036 - val_mae: 15.9674\n",
            "Epoch 8046/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 263.8095 - mae: 15.8763 - val_loss: 263.5726 - val_mae: 15.9664\n",
            "Epoch 8047/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 263.7794 - mae: 15.8754 - val_loss: 263.5416 - val_mae: 15.9654\n",
            "Epoch 8048/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 263.7492 - mae: 15.8744 - val_loss: 263.5106 - val_mae: 15.9645\n",
            "Epoch 8049/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 263.7190 - mae: 15.8735 - val_loss: 263.4795 - val_mae: 15.9635\n",
            "Epoch 8050/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 263.6888 - mae: 15.8726 - val_loss: 263.4485 - val_mae: 15.9625\n",
            "Epoch 8051/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 263.6586 - mae: 15.8716 - val_loss: 263.4175 - val_mae: 15.9616\n",
            "Epoch 8052/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 263.6284 - mae: 15.8707 - val_loss: 263.3865 - val_mae: 15.9606\n",
            "Epoch 8053/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 263.5983 - mae: 15.8697 - val_loss: 263.3555 - val_mae: 15.9596\n",
            "Epoch 8054/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 263.5681 - mae: 15.8688 - val_loss: 263.3245 - val_mae: 15.9586\n",
            "Epoch 8055/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 263.5379 - mae: 15.8678 - val_loss: 263.2935 - val_mae: 15.9577\n",
            "Epoch 8056/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 263.5078 - mae: 15.8669 - val_loss: 263.2625 - val_mae: 15.9567\n",
            "Epoch 8057/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 263.4776 - mae: 15.8660 - val_loss: 263.2315 - val_mae: 15.9557\n",
            "Epoch 8058/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 263.4474 - mae: 15.8650 - val_loss: 263.2005 - val_mae: 15.9548\n",
            "Epoch 8059/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 263.4173 - mae: 15.8641 - val_loss: 263.1695 - val_mae: 15.9538\n",
            "Epoch 8060/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 263.3871 - mae: 15.8631 - val_loss: 263.1386 - val_mae: 15.9528\n",
            "Epoch 8061/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 263.3570 - mae: 15.8622 - val_loss: 263.1076 - val_mae: 15.9519\n",
            "Epoch 8062/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 263.3269 - mae: 15.8612 - val_loss: 263.0766 - val_mae: 15.9509\n",
            "Epoch 8063/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 263.2967 - mae: 15.8603 - val_loss: 263.0457 - val_mae: 15.9499\n",
            "Epoch 8064/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 263.2666 - mae: 15.8594 - val_loss: 263.0147 - val_mae: 15.9490\n",
            "Epoch 8065/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 263.2365 - mae: 15.8584 - val_loss: 262.9837 - val_mae: 15.9480\n",
            "Epoch 8066/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 263.2063 - mae: 15.8575 - val_loss: 262.9528 - val_mae: 15.9470\n",
            "Epoch 8067/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 263.1762 - mae: 15.8565 - val_loss: 262.9218 - val_mae: 15.9461\n",
            "Epoch 8068/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 263.1461 - mae: 15.8556 - val_loss: 262.8908 - val_mae: 15.9451\n",
            "Epoch 8069/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 263.1159 - mae: 15.8546 - val_loss: 262.8599 - val_mae: 15.9441\n",
            "Epoch 8070/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 263.0858 - mae: 15.8537 - val_loss: 262.8289 - val_mae: 15.9432\n",
            "Epoch 8071/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 263.0557 - mae: 15.8528 - val_loss: 262.7980 - val_mae: 15.9422\n",
            "Epoch 8072/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 263.0256 - mae: 15.8518 - val_loss: 262.7670 - val_mae: 15.9412\n",
            "Epoch 8073/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 262.9954 - mae: 15.8509 - val_loss: 262.7361 - val_mae: 15.9402\n",
            "Epoch 8074/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 262.9653 - mae: 15.8499 - val_loss: 262.7051 - val_mae: 15.9393\n",
            "Epoch 8075/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 262.9352 - mae: 15.8490 - val_loss: 262.6742 - val_mae: 15.9383\n",
            "Epoch 8076/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 262.9051 - mae: 15.8480 - val_loss: 262.6432 - val_mae: 15.9373\n",
            "Epoch 8077/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 262.8749 - mae: 15.8471 - val_loss: 262.6123 - val_mae: 15.9364\n",
            "Epoch 8078/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 262.8449 - mae: 15.8462 - val_loss: 262.5814 - val_mae: 15.9354\n",
            "Epoch 8079/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 262.8148 - mae: 15.8452 - val_loss: 262.5504 - val_mae: 15.9344\n",
            "Epoch 8080/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 262.7846 - mae: 15.8443 - val_loss: 262.5195 - val_mae: 15.9335\n",
            "Epoch 8081/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 262.7545 - mae: 15.8433 - val_loss: 262.4886 - val_mae: 15.9325\n",
            "Epoch 8082/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 262.7244 - mae: 15.8424 - val_loss: 262.4576 - val_mae: 15.9315\n",
            "Epoch 8083/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 262.6943 - mae: 15.8414 - val_loss: 262.4267 - val_mae: 15.9306\n",
            "Epoch 8084/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 262.6642 - mae: 15.8405 - val_loss: 262.3958 - val_mae: 15.9296\n",
            "Epoch 8085/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 262.6341 - mae: 15.8396 - val_loss: 262.3648 - val_mae: 15.9286\n",
            "Epoch 8086/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 262.6040 - mae: 15.8386 - val_loss: 262.3339 - val_mae: 15.9277\n",
            "Epoch 8087/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 262.5739 - mae: 15.8377 - val_loss: 262.3030 - val_mae: 15.9267\n",
            "Epoch 8088/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 262.5439 - mae: 15.8367 - val_loss: 262.2721 - val_mae: 15.9257\n",
            "Epoch 8089/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 262.5138 - mae: 15.8358 - val_loss: 262.2411 - val_mae: 15.9248\n",
            "Epoch 8090/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 262.4837 - mae: 15.8348 - val_loss: 262.2102 - val_mae: 15.9238\n",
            "Epoch 8091/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 262.4536 - mae: 15.8339 - val_loss: 262.1793 - val_mae: 15.9228\n",
            "Epoch 8092/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 262.4235 - mae: 15.8330 - val_loss: 262.1484 - val_mae: 15.9219\n",
            "Epoch 8093/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 262.3934 - mae: 15.8320 - val_loss: 262.1175 - val_mae: 15.9209\n",
            "Epoch 8094/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 262.3633 - mae: 15.8311 - val_loss: 262.0866 - val_mae: 15.9199\n",
            "Epoch 8095/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 262.3333 - mae: 15.8301 - val_loss: 262.0557 - val_mae: 15.9189\n",
            "Epoch 8096/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 262.3032 - mae: 15.8292 - val_loss: 262.0248 - val_mae: 15.9180\n",
            "Epoch 8097/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 262.2731 - mae: 15.8282 - val_loss: 261.9939 - val_mae: 15.9170\n",
            "Epoch 8098/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 262.2430 - mae: 15.8273 - val_loss: 261.9630 - val_mae: 15.9160\n",
            "Epoch 8099/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 262.2130 - mae: 15.8264 - val_loss: 261.9321 - val_mae: 15.9151\n",
            "Epoch 8100/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 262.1829 - mae: 15.8254 - val_loss: 261.9012 - val_mae: 15.9141\n",
            "Epoch 8101/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 262.1528 - mae: 15.8245 - val_loss: 261.8703 - val_mae: 15.9131\n",
            "Epoch 8102/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 262.1228 - mae: 15.8235 - val_loss: 261.8394 - val_mae: 15.9122\n",
            "Epoch 8103/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 262.0927 - mae: 15.8226 - val_loss: 261.8085 - val_mae: 15.9112\n",
            "Epoch 8104/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 262.0626 - mae: 15.8216 - val_loss: 261.7776 - val_mae: 15.9102\n",
            "Epoch 8105/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 262.0326 - mae: 15.8207 - val_loss: 261.7467 - val_mae: 15.9093\n",
            "Epoch 8106/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 262.0025 - mae: 15.8198 - val_loss: 261.7158 - val_mae: 15.9083\n",
            "Epoch 8107/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 261.9725 - mae: 15.8188 - val_loss: 261.6850 - val_mae: 15.9073\n",
            "Epoch 8108/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 261.9424 - mae: 15.8179 - val_loss: 261.6541 - val_mae: 15.9064\n",
            "Epoch 8109/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 261.9123 - mae: 15.8169 - val_loss: 261.6232 - val_mae: 15.9054\n",
            "Epoch 8110/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 261.8823 - mae: 15.8160 - val_loss: 261.5923 - val_mae: 15.9044\n",
            "Epoch 8111/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 261.8522 - mae: 15.8150 - val_loss: 261.5615 - val_mae: 15.9035\n",
            "Epoch 8112/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 261.8222 - mae: 15.8141 - val_loss: 261.5306 - val_mae: 15.9025\n",
            "Epoch 8113/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 261.7921 - mae: 15.8132 - val_loss: 261.4997 - val_mae: 15.9015\n",
            "Epoch 8114/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 261.7621 - mae: 15.8122 - val_loss: 261.4689 - val_mae: 15.9006\n",
            "Epoch 8115/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 261.7321 - mae: 15.8113 - val_loss: 261.4380 - val_mae: 15.8996\n",
            "Epoch 8116/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 261.7020 - mae: 15.8103 - val_loss: 261.4071 - val_mae: 15.8986\n",
            "Epoch 8117/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 261.6720 - mae: 15.8094 - val_loss: 261.3763 - val_mae: 15.8976\n",
            "Epoch 8118/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 261.6419 - mae: 15.8084 - val_loss: 261.3454 - val_mae: 15.8967\n",
            "Epoch 8119/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 261.6119 - mae: 15.8075 - val_loss: 261.3145 - val_mae: 15.8957\n",
            "Epoch 8120/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 261.5819 - mae: 15.8066 - val_loss: 261.2837 - val_mae: 15.8947\n",
            "Epoch 8121/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 261.5518 - mae: 15.8056 - val_loss: 261.2528 - val_mae: 15.8938\n",
            "Epoch 8122/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 261.5219 - mae: 15.8047 - val_loss: 261.2220 - val_mae: 15.8928\n",
            "Epoch 8123/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 261.4918 - mae: 15.8037 - val_loss: 261.1911 - val_mae: 15.8918\n",
            "Epoch 8124/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 261.4618 - mae: 15.8028 - val_loss: 261.1603 - val_mae: 15.8909\n",
            "Epoch 8125/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 261.4317 - mae: 15.8019 - val_loss: 261.1295 - val_mae: 15.8899\n",
            "Epoch 8126/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 261.4017 - mae: 15.8009 - val_loss: 261.0986 - val_mae: 15.8889\n",
            "Epoch 8127/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 261.3717 - mae: 15.8000 - val_loss: 261.0678 - val_mae: 15.8880\n",
            "Epoch 8128/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 261.3417 - mae: 15.7990 - val_loss: 261.0369 - val_mae: 15.8870\n",
            "Epoch 8129/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 261.3117 - mae: 15.7981 - val_loss: 261.0061 - val_mae: 15.8860\n",
            "Epoch 8130/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 261.2817 - mae: 15.7971 - val_loss: 260.9753 - val_mae: 15.8851\n",
            "Epoch 8131/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 261.2516 - mae: 15.7962 - val_loss: 260.9444 - val_mae: 15.8841\n",
            "Epoch 8132/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 261.2216 - mae: 15.7953 - val_loss: 260.9136 - val_mae: 15.8831\n",
            "Epoch 8133/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 261.1917 - mae: 15.7943 - val_loss: 260.8828 - val_mae: 15.8822\n",
            "Epoch 8134/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 261.1616 - mae: 15.7934 - val_loss: 260.8520 - val_mae: 15.8812\n",
            "Epoch 8135/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 261.1316 - mae: 15.7924 - val_loss: 260.8211 - val_mae: 15.8802\n",
            "Epoch 8136/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 261.1016 - mae: 15.7915 - val_loss: 260.7903 - val_mae: 15.8793\n",
            "Epoch 8137/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 261.0716 - mae: 15.7905 - val_loss: 260.7595 - val_mae: 15.8783\n",
            "Epoch 8138/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 261.0416 - mae: 15.7896 - val_loss: 260.7286 - val_mae: 15.8773\n",
            "Epoch 8139/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 261.0116 - mae: 15.7887 - val_loss: 260.6978 - val_mae: 15.8763\n",
            "Epoch 8140/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 260.9816 - mae: 15.7877 - val_loss: 260.6670 - val_mae: 15.8754\n",
            "Epoch 8141/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 260.9516 - mae: 15.7868 - val_loss: 260.6362 - val_mae: 15.8744\n",
            "Epoch 8142/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 260.9216 - mae: 15.7858 - val_loss: 260.6054 - val_mae: 15.8734\n",
            "Epoch 8143/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 260.8916 - mae: 15.7849 - val_loss: 260.5746 - val_mae: 15.8725\n",
            "Epoch 8144/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 260.8617 - mae: 15.7839 - val_loss: 260.5438 - val_mae: 15.8715\n",
            "Epoch 8145/10000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 260.8317 - mae: 15.7830 - val_loss: 260.5129 - val_mae: 15.8705\n",
            "Epoch 8146/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 260.8017 - mae: 15.7821 - val_loss: 260.4821 - val_mae: 15.8696\n",
            "Epoch 8147/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 260.7717 - mae: 15.7811 - val_loss: 260.4513 - val_mae: 15.8686\n",
            "Epoch 8148/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 260.7418 - mae: 15.7802 - val_loss: 260.4205 - val_mae: 15.8676\n",
            "Epoch 8149/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 260.7118 - mae: 15.7792 - val_loss: 260.3897 - val_mae: 15.8667\n",
            "Epoch 8150/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 260.6818 - mae: 15.7783 - val_loss: 260.3589 - val_mae: 15.8657\n",
            "Epoch 8151/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 260.6518 - mae: 15.7773 - val_loss: 260.3282 - val_mae: 15.8647\n",
            "Epoch 8152/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 260.6218 - mae: 15.7764 - val_loss: 260.2974 - val_mae: 15.8638\n",
            "Epoch 8153/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 260.5919 - mae: 15.7755 - val_loss: 260.2666 - val_mae: 15.8628\n",
            "Epoch 8154/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 260.5619 - mae: 15.7745 - val_loss: 260.2358 - val_mae: 15.8618\n",
            "Epoch 8155/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 260.5320 - mae: 15.7736 - val_loss: 260.2050 - val_mae: 15.8609\n",
            "Epoch 8156/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 260.5020 - mae: 15.7726 - val_loss: 260.1742 - val_mae: 15.8599\n",
            "Epoch 8157/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 260.4720 - mae: 15.7717 - val_loss: 260.1434 - val_mae: 15.8589\n",
            "Epoch 8158/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 260.4420 - mae: 15.7707 - val_loss: 260.1126 - val_mae: 15.8580\n",
            "Epoch 8159/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 260.4120 - mae: 15.7698 - val_loss: 260.0818 - val_mae: 15.8570\n",
            "Epoch 8160/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 260.3821 - mae: 15.7689 - val_loss: 260.0511 - val_mae: 15.8560\n",
            "Epoch 8161/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 260.3521 - mae: 15.7679 - val_loss: 260.0203 - val_mae: 15.8551\n",
            "Epoch 8162/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 260.3222 - mae: 15.7670 - val_loss: 259.9895 - val_mae: 15.8541\n",
            "Epoch 8163/10000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 260.2923 - mae: 15.7660 - val_loss: 259.9588 - val_mae: 15.8531\n",
            "Epoch 8164/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 260.2623 - mae: 15.7651 - val_loss: 259.9280 - val_mae: 15.8521\n",
            "Epoch 8165/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 260.2324 - mae: 15.7641 - val_loss: 259.8972 - val_mae: 15.8512\n",
            "Epoch 8166/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 260.2024 - mae: 15.7632 - val_loss: 259.8665 - val_mae: 15.8502\n",
            "Epoch 8167/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 260.1725 - mae: 15.7623 - val_loss: 259.8357 - val_mae: 15.8492\n",
            "Epoch 8168/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 260.1425 - mae: 15.7613 - val_loss: 259.8049 - val_mae: 15.8483\n",
            "Epoch 8169/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 260.1126 - mae: 15.7604 - val_loss: 259.7742 - val_mae: 15.8473\n",
            "Epoch 8170/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 260.0826 - mae: 15.7594 - val_loss: 259.7434 - val_mae: 15.8463\n",
            "Epoch 8171/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 260.0527 - mae: 15.7585 - val_loss: 259.7127 - val_mae: 15.8454\n",
            "Epoch 8172/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 260.0228 - mae: 15.7575 - val_loss: 259.6819 - val_mae: 15.8444\n",
            "Epoch 8173/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 259.9928 - mae: 15.7566 - val_loss: 259.6512 - val_mae: 15.8434\n",
            "Epoch 8174/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 259.9629 - mae: 15.7557 - val_loss: 259.6204 - val_mae: 15.8425\n",
            "Epoch 8175/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 259.9330 - mae: 15.7547 - val_loss: 259.5897 - val_mae: 15.8415\n",
            "Epoch 8176/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 259.9030 - mae: 15.7538 - val_loss: 259.5589 - val_mae: 15.8405\n",
            "Epoch 8177/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 259.8731 - mae: 15.7528 - val_loss: 259.5282 - val_mae: 15.8396\n",
            "Epoch 8178/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 259.8432 - mae: 15.7519 - val_loss: 259.4975 - val_mae: 15.8386\n",
            "Epoch 8179/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 259.8133 - mae: 15.7509 - val_loss: 259.4667 - val_mae: 15.8376\n",
            "Epoch 8180/10000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 259.7834 - mae: 15.7500 - val_loss: 259.4360 - val_mae: 15.8367\n",
            "Epoch 8181/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 259.7534 - mae: 15.7491 - val_loss: 259.4052 - val_mae: 15.8357\n",
            "Epoch 8182/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 259.7235 - mae: 15.7481 - val_loss: 259.3745 - val_mae: 15.8347\n",
            "Epoch 8183/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 259.6936 - mae: 15.7472 - val_loss: 259.3438 - val_mae: 15.8338\n",
            "Epoch 8184/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 259.6637 - mae: 15.7462 - val_loss: 259.3130 - val_mae: 15.8328\n",
            "Epoch 8185/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 259.6338 - mae: 15.7453 - val_loss: 259.2823 - val_mae: 15.8318\n",
            "Epoch 8186/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 259.6039 - mae: 15.7443 - val_loss: 259.2516 - val_mae: 15.8309\n",
            "Epoch 8187/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 259.5740 - mae: 15.7434 - val_loss: 259.2209 - val_mae: 15.8299\n",
            "Epoch 8188/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 259.5440 - mae: 15.7425 - val_loss: 259.1901 - val_mae: 15.8289\n",
            "Epoch 8189/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 259.5142 - mae: 15.7415 - val_loss: 259.1594 - val_mae: 15.8279\n",
            "Epoch 8190/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 259.4843 - mae: 15.7406 - val_loss: 259.1287 - val_mae: 15.8270\n",
            "Epoch 8191/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 259.4544 - mae: 15.7396 - val_loss: 259.0980 - val_mae: 15.8260\n",
            "Epoch 8192/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 259.4245 - mae: 15.7387 - val_loss: 259.0673 - val_mae: 15.8250\n",
            "Epoch 8193/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 259.3946 - mae: 15.7377 - val_loss: 259.0366 - val_mae: 15.8241\n",
            "Epoch 8194/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 259.3647 - mae: 15.7368 - val_loss: 259.0059 - val_mae: 15.8231\n",
            "Epoch 8195/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 259.3348 - mae: 15.7359 - val_loss: 258.9752 - val_mae: 15.8221\n",
            "Epoch 8196/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 259.3049 - mae: 15.7349 - val_loss: 258.9445 - val_mae: 15.8212\n",
            "Epoch 8197/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 259.2750 - mae: 15.7340 - val_loss: 258.9138 - val_mae: 15.8202\n",
            "Epoch 8198/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 259.2451 - mae: 15.7330 - val_loss: 258.8831 - val_mae: 15.8192\n",
            "Epoch 8199/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 259.2152 - mae: 15.7321 - val_loss: 258.8524 - val_mae: 15.8183\n",
            "Epoch 8200/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 259.1854 - mae: 15.7311 - val_loss: 258.8217 - val_mae: 15.8173\n",
            "Epoch 8201/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 259.1555 - mae: 15.7302 - val_loss: 258.7910 - val_mae: 15.8163\n",
            "Epoch 8202/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 259.1256 - mae: 15.7293 - val_loss: 258.7603 - val_mae: 15.8154\n",
            "Epoch 8203/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 259.0957 - mae: 15.7283 - val_loss: 258.7296 - val_mae: 15.8144\n",
            "Epoch 8204/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 259.0658 - mae: 15.7274 - val_loss: 258.6989 - val_mae: 15.8134\n",
            "Epoch 8205/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 259.0360 - mae: 15.7264 - val_loss: 258.6682 - val_mae: 15.8125\n",
            "Epoch 8206/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 259.0061 - mae: 15.7255 - val_loss: 258.6375 - val_mae: 15.8115\n",
            "Epoch 8207/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 258.9763 - mae: 15.7245 - val_loss: 258.6069 - val_mae: 15.8105\n",
            "Epoch 8208/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 258.9464 - mae: 15.7236 - val_loss: 258.5762 - val_mae: 15.8096\n",
            "Epoch 8209/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 258.9165 - mae: 15.7227 - val_loss: 258.5456 - val_mae: 15.8086\n",
            "Epoch 8210/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 258.8867 - mae: 15.7217 - val_loss: 258.5149 - val_mae: 15.8076\n",
            "Epoch 8211/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 258.8569 - mae: 15.7208 - val_loss: 258.4842 - val_mae: 15.8067\n",
            "Epoch 8212/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 258.8270 - mae: 15.7198 - val_loss: 258.4536 - val_mae: 15.8057\n",
            "Epoch 8213/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 258.7971 - mae: 15.7189 - val_loss: 258.4229 - val_mae: 15.8047\n",
            "Epoch 8214/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 258.7673 - mae: 15.7180 - val_loss: 258.3923 - val_mae: 15.8038\n",
            "Epoch 8215/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 258.7375 - mae: 15.7170 - val_loss: 258.3616 - val_mae: 15.8028\n",
            "Epoch 8216/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 258.7076 - mae: 15.7161 - val_loss: 258.3310 - val_mae: 15.8018\n",
            "Epoch 8217/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 258.6778 - mae: 15.7151 - val_loss: 258.3003 - val_mae: 15.8009\n",
            "Epoch 8218/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 258.6480 - mae: 15.7142 - val_loss: 258.2697 - val_mae: 15.7999\n",
            "Epoch 8219/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 258.6181 - mae: 15.7132 - val_loss: 258.2390 - val_mae: 15.7989\n",
            "Epoch 8220/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 258.5883 - mae: 15.7123 - val_loss: 258.2084 - val_mae: 15.7980\n",
            "Epoch 8221/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 258.5585 - mae: 15.7114 - val_loss: 258.1777 - val_mae: 15.7970\n",
            "Epoch 8222/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 258.5287 - mae: 15.7104 - val_loss: 258.1471 - val_mae: 15.7960\n",
            "Epoch 8223/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 258.4988 - mae: 15.7095 - val_loss: 258.1165 - val_mae: 15.7950\n",
            "Epoch 8224/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 258.4690 - mae: 15.7085 - val_loss: 258.0858 - val_mae: 15.7941\n",
            "Epoch 8225/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 258.4392 - mae: 15.7076 - val_loss: 258.0552 - val_mae: 15.7931\n",
            "Epoch 8226/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 258.4094 - mae: 15.7066 - val_loss: 258.0246 - val_mae: 15.7921\n",
            "Epoch 8227/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 258.3796 - mae: 15.7057 - val_loss: 257.9940 - val_mae: 15.7912\n",
            "Epoch 8228/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 258.3497 - mae: 15.7048 - val_loss: 257.9633 - val_mae: 15.7902\n",
            "Epoch 8229/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 258.3200 - mae: 15.7038 - val_loss: 257.9327 - val_mae: 15.7892\n",
            "Epoch 8230/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 258.2901 - mae: 15.7029 - val_loss: 257.9021 - val_mae: 15.7883\n",
            "Epoch 8231/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 258.2603 - mae: 15.7019 - val_loss: 257.8715 - val_mae: 15.7873\n",
            "Epoch 8232/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 258.2305 - mae: 15.7010 - val_loss: 257.8409 - val_mae: 15.7863\n",
            "Epoch 8233/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 258.2007 - mae: 15.7001 - val_loss: 257.8102 - val_mae: 15.7854\n",
            "Epoch 8234/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 258.1709 - mae: 15.6991 - val_loss: 257.7796 - val_mae: 15.7844\n",
            "Epoch 8235/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 258.1411 - mae: 15.6982 - val_loss: 257.7490 - val_mae: 15.7834\n",
            "Epoch 8236/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 258.1113 - mae: 15.6972 - val_loss: 257.7184 - val_mae: 15.7825\n",
            "Epoch 8237/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 258.0815 - mae: 15.6963 - val_loss: 257.6878 - val_mae: 15.7815\n",
            "Epoch 8238/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 258.0517 - mae: 15.6953 - val_loss: 257.6572 - val_mae: 15.7805\n",
            "Epoch 8239/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 258.0219 - mae: 15.6944 - val_loss: 257.6266 - val_mae: 15.7796\n",
            "Epoch 8240/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 257.9921 - mae: 15.6935 - val_loss: 257.5959 - val_mae: 15.7786\n",
            "Epoch 8241/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 257.9623 - mae: 15.6925 - val_loss: 257.5654 - val_mae: 15.7776\n",
            "Epoch 8242/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 257.9325 - mae: 15.6916 - val_loss: 257.5348 - val_mae: 15.7767\n",
            "Epoch 8243/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 257.9027 - mae: 15.6906 - val_loss: 257.5042 - val_mae: 15.7757\n",
            "Epoch 8244/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 257.8730 - mae: 15.6897 - val_loss: 257.4736 - val_mae: 15.7747\n",
            "Epoch 8245/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 257.8432 - mae: 15.6887 - val_loss: 257.4430 - val_mae: 15.7738\n",
            "Epoch 8246/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 257.8134 - mae: 15.6878 - val_loss: 257.4124 - val_mae: 15.7728\n",
            "Epoch 8247/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 257.7836 - mae: 15.6869 - val_loss: 257.3818 - val_mae: 15.7718\n",
            "Epoch 8248/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 257.7538 - mae: 15.6859 - val_loss: 257.3512 - val_mae: 15.7709\n",
            "Epoch 8249/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 257.7241 - mae: 15.6850 - val_loss: 257.3206 - val_mae: 15.7699\n",
            "Epoch 8250/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 257.6943 - mae: 15.6840 - val_loss: 257.2900 - val_mae: 15.7689\n",
            "Epoch 8251/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 257.6645 - mae: 15.6831 - val_loss: 257.2595 - val_mae: 15.7680\n",
            "Epoch 8252/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 257.6348 - mae: 15.6821 - val_loss: 257.2289 - val_mae: 15.7670\n",
            "Epoch 8253/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 257.6050 - mae: 15.6812 - val_loss: 257.1983 - val_mae: 15.7660\n",
            "Epoch 8254/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 257.5752 - mae: 15.6803 - val_loss: 257.1677 - val_mae: 15.7651\n",
            "Epoch 8255/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 257.5455 - mae: 15.6793 - val_loss: 257.1372 - val_mae: 15.7641\n",
            "Epoch 8256/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 257.5157 - mae: 15.6784 - val_loss: 257.1066 - val_mae: 15.7631\n",
            "Epoch 8257/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 257.4859 - mae: 15.6774 - val_loss: 257.0760 - val_mae: 15.7622\n",
            "Epoch 8258/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 257.4562 - mae: 15.6765 - val_loss: 257.0455 - val_mae: 15.7612\n",
            "Epoch 8259/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 257.4264 - mae: 15.6756 - val_loss: 257.0149 - val_mae: 15.7602\n",
            "Epoch 8260/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 257.3967 - mae: 15.6746 - val_loss: 256.9843 - val_mae: 15.7593\n",
            "Epoch 8261/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 257.3669 - mae: 15.6737 - val_loss: 256.9538 - val_mae: 15.7583\n",
            "Epoch 8262/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 257.3372 - mae: 15.6727 - val_loss: 256.9232 - val_mae: 15.7573\n",
            "Epoch 8263/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 257.3074 - mae: 15.6718 - val_loss: 256.8927 - val_mae: 15.7564\n",
            "Epoch 8264/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 257.2777 - mae: 15.6708 - val_loss: 256.8621 - val_mae: 15.7554\n",
            "Epoch 8265/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 257.2479 - mae: 15.6699 - val_loss: 256.8316 - val_mae: 15.7544\n",
            "Epoch 8266/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 257.2182 - mae: 15.6690 - val_loss: 256.8010 - val_mae: 15.7535\n",
            "Epoch 8267/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 257.1884 - mae: 15.6680 - val_loss: 256.7704 - val_mae: 15.7525\n",
            "Epoch 8268/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 257.1587 - mae: 15.6671 - val_loss: 256.7399 - val_mae: 15.7515\n",
            "Epoch 8269/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 257.1289 - mae: 15.6661 - val_loss: 256.7094 - val_mae: 15.7506\n",
            "Epoch 8270/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 257.0992 - mae: 15.6652 - val_loss: 256.6788 - val_mae: 15.7496\n",
            "Epoch 8271/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 257.0695 - mae: 15.6642 - val_loss: 256.6483 - val_mae: 15.7486\n",
            "Epoch 8272/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 257.0398 - mae: 15.6633 - val_loss: 256.6177 - val_mae: 15.7476\n",
            "Epoch 8273/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 257.0100 - mae: 15.6624 - val_loss: 256.5872 - val_mae: 15.7467\n",
            "Epoch 8274/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 256.9803 - mae: 15.6614 - val_loss: 256.5567 - val_mae: 15.7457\n",
            "Epoch 8275/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 256.9505 - mae: 15.6605 - val_loss: 256.5261 - val_mae: 15.7447\n",
            "Epoch 8276/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 256.9208 - mae: 15.6595 - val_loss: 256.4956 - val_mae: 15.7438\n",
            "Epoch 8277/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 256.8911 - mae: 15.6586 - val_loss: 256.4651 - val_mae: 15.7428\n",
            "Epoch 8278/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 256.8614 - mae: 15.6577 - val_loss: 256.4346 - val_mae: 15.7418\n",
            "Epoch 8279/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 256.8317 - mae: 15.6567 - val_loss: 256.4041 - val_mae: 15.7409\n",
            "Epoch 8280/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 256.8019 - mae: 15.6558 - val_loss: 256.3735 - val_mae: 15.7399\n",
            "Epoch 8281/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 256.7722 - mae: 15.6548 - val_loss: 256.3430 - val_mae: 15.7389\n",
            "Epoch 8282/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 256.7425 - mae: 15.6539 - val_loss: 256.3124 - val_mae: 15.7380\n",
            "Epoch 8283/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 256.7128 - mae: 15.6529 - val_loss: 256.2819 - val_mae: 15.7370\n",
            "Epoch 8284/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 256.6831 - mae: 15.6520 - val_loss: 256.2514 - val_mae: 15.7360\n",
            "Epoch 8285/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 256.6534 - mae: 15.6511 - val_loss: 256.2209 - val_mae: 15.7351\n",
            "Epoch 8286/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 256.6237 - mae: 15.6501 - val_loss: 256.1904 - val_mae: 15.7341\n",
            "Epoch 8287/10000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 256.5940 - mae: 15.6492 - val_loss: 256.1599 - val_mae: 15.7331\n",
            "Epoch 8288/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 256.5643 - mae: 15.6482 - val_loss: 256.1294 - val_mae: 15.7322\n",
            "Epoch 8289/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 256.5346 - mae: 15.6473 - val_loss: 256.0989 - val_mae: 15.7312\n",
            "Epoch 8290/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 256.5049 - mae: 15.6463 - val_loss: 256.0684 - val_mae: 15.7302\n",
            "Epoch 8291/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 256.4752 - mae: 15.6454 - val_loss: 256.0379 - val_mae: 15.7293\n",
            "Epoch 8292/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 256.4455 - mae: 15.6445 - val_loss: 256.0074 - val_mae: 15.7283\n",
            "Epoch 8293/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 256.4158 - mae: 15.6435 - val_loss: 255.9769 - val_mae: 15.7273\n",
            "Epoch 8294/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 256.3861 - mae: 15.6426 - val_loss: 255.9464 - val_mae: 15.7264\n",
            "Epoch 8295/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 256.3564 - mae: 15.6416 - val_loss: 255.9159 - val_mae: 15.7254\n",
            "Epoch 8296/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 256.3267 - mae: 15.6407 - val_loss: 255.8854 - val_mae: 15.7244\n",
            "Epoch 8297/10000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 256.2971 - mae: 15.6397 - val_loss: 255.8549 - val_mae: 15.7235\n",
            "Epoch 8298/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 256.2673 - mae: 15.6388 - val_loss: 255.8244 - val_mae: 15.7225\n",
            "Epoch 8299/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 256.2376 - mae: 15.6379 - val_loss: 255.7939 - val_mae: 15.7215\n",
            "Epoch 8300/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 256.2080 - mae: 15.6369 - val_loss: 255.7635 - val_mae: 15.7206\n",
            "Epoch 8301/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 256.1783 - mae: 15.6360 - val_loss: 255.7330 - val_mae: 15.7196\n",
            "Epoch 8302/10000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 256.1486 - mae: 15.6350 - val_loss: 255.7025 - val_mae: 15.7186\n",
            "Epoch 8303/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 256.1190 - mae: 15.6341 - val_loss: 255.6720 - val_mae: 15.7177\n",
            "Epoch 8304/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 256.0893 - mae: 15.6332 - val_loss: 255.6416 - val_mae: 15.7167\n",
            "Epoch 8305/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 256.0596 - mae: 15.6322 - val_loss: 255.6111 - val_mae: 15.7157\n",
            "Epoch 8306/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 256.0299 - mae: 15.6313 - val_loss: 255.5806 - val_mae: 15.7148\n",
            "Epoch 8307/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 256.0003 - mae: 15.6303 - val_loss: 255.5501 - val_mae: 15.7138\n",
            "Epoch 8308/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 255.9706 - mae: 15.6294 - val_loss: 255.5197 - val_mae: 15.7128\n",
            "Epoch 8309/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 255.9410 - mae: 15.6284 - val_loss: 255.4892 - val_mae: 15.7119\n",
            "Epoch 8310/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 255.9113 - mae: 15.6275 - val_loss: 255.4587 - val_mae: 15.7109\n",
            "Epoch 8311/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 255.8817 - mae: 15.6266 - val_loss: 255.4283 - val_mae: 15.7099\n",
            "Epoch 8312/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 255.8520 - mae: 15.6256 - val_loss: 255.3979 - val_mae: 15.7090\n",
            "Epoch 8313/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 255.8224 - mae: 15.6247 - val_loss: 255.3674 - val_mae: 15.7080\n",
            "Epoch 8314/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 255.7927 - mae: 15.6237 - val_loss: 255.3369 - val_mae: 15.7070\n",
            "Epoch 8315/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 255.7630 - mae: 15.6228 - val_loss: 255.3064 - val_mae: 15.7061\n",
            "Epoch 8316/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 255.7333 - mae: 15.6218 - val_loss: 255.2760 - val_mae: 15.7051\n",
            "Epoch 8317/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 255.7037 - mae: 15.6209 - val_loss: 255.2456 - val_mae: 15.7041\n",
            "Epoch 8318/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 255.6741 - mae: 15.6200 - val_loss: 255.2151 - val_mae: 15.7032\n",
            "Epoch 8319/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 255.6444 - mae: 15.6190 - val_loss: 255.1847 - val_mae: 15.7022\n",
            "Epoch 8320/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 255.6148 - mae: 15.6181 - val_loss: 255.1542 - val_mae: 15.7012\n",
            "Epoch 8321/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 255.5851 - mae: 15.6171 - val_loss: 255.1238 - val_mae: 15.7003\n",
            "Epoch 8322/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 255.5555 - mae: 15.6162 - val_loss: 255.0934 - val_mae: 15.6993\n",
            "Epoch 8323/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 255.5258 - mae: 15.6152 - val_loss: 255.0629 - val_mae: 15.6983\n",
            "Epoch 8324/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 255.4962 - mae: 15.6143 - val_loss: 255.0325 - val_mae: 15.6974\n",
            "Epoch 8325/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 255.4666 - mae: 15.6134 - val_loss: 255.0020 - val_mae: 15.6964\n",
            "Epoch 8326/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 255.4370 - mae: 15.6124 - val_loss: 254.9716 - val_mae: 15.6954\n",
            "Epoch 8327/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 255.4073 - mae: 15.6115 - val_loss: 254.9412 - val_mae: 15.6945\n",
            "Epoch 8328/10000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 255.3777 - mae: 15.6105 - val_loss: 254.9108 - val_mae: 15.6935\n",
            "Epoch 8329/10000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 255.3481 - mae: 15.6096 - val_loss: 254.8803 - val_mae: 15.6925\n",
            "Epoch 8330/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 255.3185 - mae: 15.6087 - val_loss: 254.8499 - val_mae: 15.6916\n",
            "Epoch 8331/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 255.2888 - mae: 15.6077 - val_loss: 254.8195 - val_mae: 15.6906\n",
            "Epoch 8332/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 255.2592 - mae: 15.6068 - val_loss: 254.7891 - val_mae: 15.6896\n",
            "Epoch 8333/10000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 255.2296 - mae: 15.6058 - val_loss: 254.7587 - val_mae: 15.6887\n",
            "Epoch 8334/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 255.2000 - mae: 15.6049 - val_loss: 254.7282 - val_mae: 15.6877\n",
            "Epoch 8335/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 255.1704 - mae: 15.6039 - val_loss: 254.6978 - val_mae: 15.6867\n",
            "Epoch 8336/10000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 255.1407 - mae: 15.6030 - val_loss: 254.6674 - val_mae: 15.6857\n",
            "Epoch 8337/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 255.1111 - mae: 15.6021 - val_loss: 254.6370 - val_mae: 15.6848\n",
            "Epoch 8338/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 255.0815 - mae: 15.6011 - val_loss: 254.6066 - val_mae: 15.6838\n",
            "Epoch 8339/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 255.0519 - mae: 15.6002 - val_loss: 254.5762 - val_mae: 15.6828\n",
            "Epoch 8340/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 255.0224 - mae: 15.5992 - val_loss: 254.5458 - val_mae: 15.6819\n",
            "Epoch 8341/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 254.9927 - mae: 15.5983 - val_loss: 254.5154 - val_mae: 15.6809\n",
            "Epoch 8342/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 254.9631 - mae: 15.5973 - val_loss: 254.4850 - val_mae: 15.6799\n",
            "Epoch 8343/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 254.9335 - mae: 15.5964 - val_loss: 254.4546 - val_mae: 15.6790\n",
            "Epoch 8344/10000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 254.9039 - mae: 15.5955 - val_loss: 254.4242 - val_mae: 15.6780\n",
            "Epoch 8345/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 254.8743 - mae: 15.5945 - val_loss: 254.3938 - val_mae: 15.6770\n",
            "Epoch 8346/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 254.8447 - mae: 15.5936 - val_loss: 254.3634 - val_mae: 15.6761\n",
            "Epoch 8347/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 254.8152 - mae: 15.5926 - val_loss: 254.3330 - val_mae: 15.6751\n",
            "Epoch 8348/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 254.7856 - mae: 15.5917 - val_loss: 254.3026 - val_mae: 15.6741\n",
            "Epoch 8349/10000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 254.7560 - mae: 15.5908 - val_loss: 254.2723 - val_mae: 15.6732\n",
            "Epoch 8350/10000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 254.7264 - mae: 15.5898 - val_loss: 254.2419 - val_mae: 15.6722\n",
            "Epoch 8351/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 254.6968 - mae: 15.5889 - val_loss: 254.2115 - val_mae: 15.6712\n",
            "Epoch 8352/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 254.6672 - mae: 15.5879 - val_loss: 254.1811 - val_mae: 15.6703\n",
            "Epoch 8353/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 254.6376 - mae: 15.5870 - val_loss: 254.1507 - val_mae: 15.6693\n",
            "Epoch 8354/10000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 254.6080 - mae: 15.5860 - val_loss: 254.1204 - val_mae: 15.6683\n",
            "Epoch 8355/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 254.5784 - mae: 15.5851 - val_loss: 254.0900 - val_mae: 15.6674\n",
            "Epoch 8356/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 254.5489 - mae: 15.5842 - val_loss: 254.0596 - val_mae: 15.6664\n",
            "Epoch 8357/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 254.5193 - mae: 15.5832 - val_loss: 254.0293 - val_mae: 15.6654\n",
            "Epoch 8358/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 254.4898 - mae: 15.5823 - val_loss: 253.9989 - val_mae: 15.6645\n",
            "Epoch 8359/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 254.4602 - mae: 15.5813 - val_loss: 253.9685 - val_mae: 15.6635\n",
            "Epoch 8360/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 254.4306 - mae: 15.5804 - val_loss: 253.9382 - val_mae: 15.6625\n",
            "Epoch 8361/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 254.4010 - mae: 15.5794 - val_loss: 253.9078 - val_mae: 15.6616\n",
            "Epoch 8362/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 254.3715 - mae: 15.5785 - val_loss: 253.8774 - val_mae: 15.6606\n",
            "Epoch 8363/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 254.3419 - mae: 15.5776 - val_loss: 253.8471 - val_mae: 15.6596\n",
            "Epoch 8364/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 254.3123 - mae: 15.5766 - val_loss: 253.8167 - val_mae: 15.6587\n",
            "Epoch 8365/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 254.2828 - mae: 15.5757 - val_loss: 253.7863 - val_mae: 15.6577\n",
            "Epoch 8366/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 254.2533 - mae: 15.5747 - val_loss: 253.7560 - val_mae: 15.6567\n",
            "Epoch 8367/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 254.2237 - mae: 15.5738 - val_loss: 253.7257 - val_mae: 15.6558\n",
            "Epoch 8368/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 254.1941 - mae: 15.5729 - val_loss: 253.6953 - val_mae: 15.6548\n",
            "Epoch 8369/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 254.1646 - mae: 15.5719 - val_loss: 253.6650 - val_mae: 15.6538\n",
            "Epoch 8370/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 254.1350 - mae: 15.5710 - val_loss: 253.6346 - val_mae: 15.6529\n",
            "Epoch 8371/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 254.1055 - mae: 15.5700 - val_loss: 253.6043 - val_mae: 15.6519\n",
            "Epoch 8372/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 254.0759 - mae: 15.5691 - val_loss: 253.5739 - val_mae: 15.6509\n",
            "Epoch 8373/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 254.0464 - mae: 15.5681 - val_loss: 253.5437 - val_mae: 15.6500\n",
            "Epoch 8374/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 254.0169 - mae: 15.5672 - val_loss: 253.5133 - val_mae: 15.6490\n",
            "Epoch 8375/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 253.9873 - mae: 15.5663 - val_loss: 253.4829 - val_mae: 15.6480\n",
            "Epoch 8376/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 253.9578 - mae: 15.5653 - val_loss: 253.4526 - val_mae: 15.6471\n",
            "Epoch 8377/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 253.9282 - mae: 15.5644 - val_loss: 253.4223 - val_mae: 15.6461\n",
            "Epoch 8378/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 253.8987 - mae: 15.5634 - val_loss: 253.3919 - val_mae: 15.6451\n",
            "Epoch 8379/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 253.8692 - mae: 15.5625 - val_loss: 253.3616 - val_mae: 15.6442\n",
            "Epoch 8380/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 253.8396 - mae: 15.5615 - val_loss: 253.3313 - val_mae: 15.6432\n",
            "Epoch 8381/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 253.8101 - mae: 15.5606 - val_loss: 253.3010 - val_mae: 15.6422\n",
            "Epoch 8382/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 253.7806 - mae: 15.5597 - val_loss: 253.2707 - val_mae: 15.6413\n",
            "Epoch 8383/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 253.7511 - mae: 15.5587 - val_loss: 253.2404 - val_mae: 15.6403\n",
            "Epoch 8384/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 253.7216 - mae: 15.5578 - val_loss: 253.2101 - val_mae: 15.6393\n",
            "Epoch 8385/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 253.6920 - mae: 15.5568 - val_loss: 253.1797 - val_mae: 15.6384\n",
            "Epoch 8386/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 253.6625 - mae: 15.5559 - val_loss: 253.1494 - val_mae: 15.6374\n",
            "Epoch 8387/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 253.6330 - mae: 15.5549 - val_loss: 253.1191 - val_mae: 15.6364\n",
            "Epoch 8388/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 253.6035 - mae: 15.5540 - val_loss: 253.0888 - val_mae: 15.6355\n",
            "Epoch 8389/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 253.5739 - mae: 15.5531 - val_loss: 253.0585 - val_mae: 15.6345\n",
            "Epoch 8390/10000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 253.5445 - mae: 15.5521 - val_loss: 253.0282 - val_mae: 15.6335\n",
            "Epoch 8391/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 253.5149 - mae: 15.5512 - val_loss: 252.9979 - val_mae: 15.6326\n",
            "Epoch 8392/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 253.4854 - mae: 15.5502 - val_loss: 252.9676 - val_mae: 15.6316\n",
            "Epoch 8393/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 253.4559 - mae: 15.5493 - val_loss: 252.9373 - val_mae: 15.6306\n",
            "Epoch 8394/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 253.4264 - mae: 15.5484 - val_loss: 252.9070 - val_mae: 15.6297\n",
            "Epoch 8395/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 253.3969 - mae: 15.5474 - val_loss: 252.8767 - val_mae: 15.6287\n",
            "Epoch 8396/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 253.3674 - mae: 15.5465 - val_loss: 252.8464 - val_mae: 15.6277\n",
            "Epoch 8397/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 253.3379 - mae: 15.5455 - val_loss: 252.8161 - val_mae: 15.6268\n",
            "Epoch 8398/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 253.3084 - mae: 15.5446 - val_loss: 252.7858 - val_mae: 15.6258\n",
            "Epoch 8399/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 253.2789 - mae: 15.5436 - val_loss: 252.7555 - val_mae: 15.6248\n",
            "Epoch 8400/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 253.2494 - mae: 15.5427 - val_loss: 252.7253 - val_mae: 15.6239\n",
            "Epoch 8401/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 253.2199 - mae: 15.5418 - val_loss: 252.6950 - val_mae: 15.6229\n",
            "Epoch 8402/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 253.1904 - mae: 15.5408 - val_loss: 252.6647 - val_mae: 15.6219\n",
            "Epoch 8403/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 253.1610 - mae: 15.5399 - val_loss: 252.6344 - val_mae: 15.6210\n",
            "Epoch 8404/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 253.1315 - mae: 15.5389 - val_loss: 252.6042 - val_mae: 15.6200\n",
            "Epoch 8405/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 253.1020 - mae: 15.5380 - val_loss: 252.5739 - val_mae: 15.6190\n",
            "Epoch 8406/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 253.0725 - mae: 15.5370 - val_loss: 252.5436 - val_mae: 15.6181\n",
            "Epoch 8407/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 253.0430 - mae: 15.5361 - val_loss: 252.5133 - val_mae: 15.6171\n",
            "Epoch 8408/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 253.0136 - mae: 15.5352 - val_loss: 252.4831 - val_mae: 15.6161\n",
            "Epoch 8409/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 252.9841 - mae: 15.5342 - val_loss: 252.4528 - val_mae: 15.6152\n",
            "Epoch 8410/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 252.9546 - mae: 15.5333 - val_loss: 252.4226 - val_mae: 15.6142\n",
            "Epoch 8411/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 252.9251 - mae: 15.5323 - val_loss: 252.3923 - val_mae: 15.6132\n",
            "Epoch 8412/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 252.8957 - mae: 15.5314 - val_loss: 252.3620 - val_mae: 15.6123\n",
            "Epoch 8413/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 252.8662 - mae: 15.5305 - val_loss: 252.3317 - val_mae: 15.6113\n",
            "Epoch 8414/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 252.8367 - mae: 15.5295 - val_loss: 252.3015 - val_mae: 15.6103\n",
            "Epoch 8415/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 252.8073 - mae: 15.5286 - val_loss: 252.2712 - val_mae: 15.6094\n",
            "Epoch 8416/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 252.7778 - mae: 15.5276 - val_loss: 252.2410 - val_mae: 15.6084\n",
            "Epoch 8417/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 252.7483 - mae: 15.5267 - val_loss: 252.2107 - val_mae: 15.6074\n",
            "Epoch 8418/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 252.7189 - mae: 15.5257 - val_loss: 252.1805 - val_mae: 15.6065\n",
            "Epoch 8419/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 252.6894 - mae: 15.5248 - val_loss: 252.1502 - val_mae: 15.6055\n",
            "Epoch 8420/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 252.6599 - mae: 15.5239 - val_loss: 252.1200 - val_mae: 15.6045\n",
            "Epoch 8421/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 252.6305 - mae: 15.5229 - val_loss: 252.0898 - val_mae: 15.6036\n",
            "Epoch 8422/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 252.6011 - mae: 15.5220 - val_loss: 252.0596 - val_mae: 15.6026\n",
            "Epoch 8423/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 252.5717 - mae: 15.5210 - val_loss: 252.0294 - val_mae: 15.6016\n",
            "Epoch 8424/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 252.5422 - mae: 15.5201 - val_loss: 251.9992 - val_mae: 15.6007\n",
            "Epoch 8425/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 252.5128 - mae: 15.5191 - val_loss: 251.9690 - val_mae: 15.5997\n",
            "Epoch 8426/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 252.4834 - mae: 15.5182 - val_loss: 251.9388 - val_mae: 15.5987\n",
            "Epoch 8427/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 252.4540 - mae: 15.5173 - val_loss: 251.9086 - val_mae: 15.5978\n",
            "Epoch 8428/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 252.4246 - mae: 15.5163 - val_loss: 251.8784 - val_mae: 15.5968\n",
            "Epoch 8429/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 252.3952 - mae: 15.5154 - val_loss: 251.8482 - val_mae: 15.5958\n",
            "Epoch 8430/10000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 252.3658 - mae: 15.5144 - val_loss: 251.8180 - val_mae: 15.5949\n",
            "Epoch 8431/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 252.3363 - mae: 15.5135 - val_loss: 251.7878 - val_mae: 15.5939\n",
            "Epoch 8432/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 252.3070 - mae: 15.5126 - val_loss: 251.7576 - val_mae: 15.5929\n",
            "Epoch 8433/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 252.2775 - mae: 15.5116 - val_loss: 251.7274 - val_mae: 15.5920\n",
            "Epoch 8434/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 252.2482 - mae: 15.5107 - val_loss: 251.6972 - val_mae: 15.5910\n",
            "Epoch 8435/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 252.2188 - mae: 15.5097 - val_loss: 251.6670 - val_mae: 15.5900\n",
            "Epoch 8436/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 252.1893 - mae: 15.5088 - val_loss: 251.6369 - val_mae: 15.5891\n",
            "Epoch 8437/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 252.1600 - mae: 15.5079 - val_loss: 251.6067 - val_mae: 15.5881\n",
            "Epoch 8438/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 252.1306 - mae: 15.5069 - val_loss: 251.5765 - val_mae: 15.5871\n",
            "Epoch 8439/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 252.1012 - mae: 15.5060 - val_loss: 251.5463 - val_mae: 15.5862\n",
            "Epoch 8440/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 252.0718 - mae: 15.5050 - val_loss: 251.5162 - val_mae: 15.5852\n",
            "Epoch 8441/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 252.0424 - mae: 15.5041 - val_loss: 251.4860 - val_mae: 15.5842\n",
            "Epoch 8442/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 252.0130 - mae: 15.5031 - val_loss: 251.4558 - val_mae: 15.5833\n",
            "Epoch 8443/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 251.9836 - mae: 15.5022 - val_loss: 251.4257 - val_mae: 15.5823\n",
            "Epoch 8444/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 251.9543 - mae: 15.5013 - val_loss: 251.3955 - val_mae: 15.5813\n",
            "Epoch 8445/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 251.9249 - mae: 15.5003 - val_loss: 251.3653 - val_mae: 15.5804\n",
            "Epoch 8446/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 251.8955 - mae: 15.4994 - val_loss: 251.3352 - val_mae: 15.5794\n",
            "Epoch 8447/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 251.8661 - mae: 15.4984 - val_loss: 251.3050 - val_mae: 15.5784\n",
            "Epoch 8448/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 251.8368 - mae: 15.4975 - val_loss: 251.2748 - val_mae: 15.5775\n",
            "Epoch 8449/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 251.8074 - mae: 15.4966 - val_loss: 251.2447 - val_mae: 15.5765\n",
            "Epoch 8450/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 251.7780 - mae: 15.4956 - val_loss: 251.2145 - val_mae: 15.5755\n",
            "Epoch 8451/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 251.7486 - mae: 15.4947 - val_loss: 251.1844 - val_mae: 15.5746\n",
            "Epoch 8452/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 251.7193 - mae: 15.4937 - val_loss: 251.1542 - val_mae: 15.5736\n",
            "Epoch 8453/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 251.6899 - mae: 15.4928 - val_loss: 251.1241 - val_mae: 15.5727\n",
            "Epoch 8454/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 251.6605 - mae: 15.4919 - val_loss: 251.0939 - val_mae: 15.5717\n",
            "Epoch 8455/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 251.6312 - mae: 15.4909 - val_loss: 251.0638 - val_mae: 15.5707\n",
            "Epoch 8456/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 251.6019 - mae: 15.4900 - val_loss: 251.0336 - val_mae: 15.5698\n",
            "Epoch 8457/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 251.5725 - mae: 15.4890 - val_loss: 251.0035 - val_mae: 15.5688\n",
            "Epoch 8458/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 251.5431 - mae: 15.4881 - val_loss: 250.9734 - val_mae: 15.5678\n",
            "Epoch 8459/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 251.5138 - mae: 15.4871 - val_loss: 250.9432 - val_mae: 15.5669\n",
            "Epoch 8460/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 251.4844 - mae: 15.4862 - val_loss: 250.9131 - val_mae: 15.5659\n",
            "Epoch 8461/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 251.4551 - mae: 15.4853 - val_loss: 250.8830 - val_mae: 15.5649\n",
            "Epoch 8462/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 251.4257 - mae: 15.4843 - val_loss: 250.8528 - val_mae: 15.5640\n",
            "Epoch 8463/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 251.3964 - mae: 15.4834 - val_loss: 250.8227 - val_mae: 15.5630\n",
            "Epoch 8464/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 251.3670 - mae: 15.4824 - val_loss: 250.7926 - val_mae: 15.5620\n",
            "Epoch 8465/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 251.3377 - mae: 15.4815 - val_loss: 250.7625 - val_mae: 15.5611\n",
            "Epoch 8466/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 251.3083 - mae: 15.4806 - val_loss: 250.7323 - val_mae: 15.5601\n",
            "Epoch 8467/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 251.2790 - mae: 15.4796 - val_loss: 250.7022 - val_mae: 15.5591\n",
            "Epoch 8468/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 251.2497 - mae: 15.4787 - val_loss: 250.6721 - val_mae: 15.5582\n",
            "Epoch 8469/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 251.2204 - mae: 15.4777 - val_loss: 250.6420 - val_mae: 15.5572\n",
            "Epoch 8470/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 251.1910 - mae: 15.4768 - val_loss: 250.6119 - val_mae: 15.5562\n",
            "Epoch 8471/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 251.1617 - mae: 15.4759 - val_loss: 250.5817 - val_mae: 15.5553\n",
            "Epoch 8472/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 251.1323 - mae: 15.4749 - val_loss: 250.5517 - val_mae: 15.5543\n",
            "Epoch 8473/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 251.1030 - mae: 15.4740 - val_loss: 250.5215 - val_mae: 15.5533\n",
            "Epoch 8474/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 251.0737 - mae: 15.4730 - val_loss: 250.4914 - val_mae: 15.5524\n",
            "Epoch 8475/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 251.0444 - mae: 15.4721 - val_loss: 250.4613 - val_mae: 15.5514\n",
            "Epoch 8476/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 251.0150 - mae: 15.4711 - val_loss: 250.4312 - val_mae: 15.5504\n",
            "Epoch 8477/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 250.9857 - mae: 15.4702 - val_loss: 250.4011 - val_mae: 15.5495\n",
            "Epoch 8478/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 250.9564 - mae: 15.4693 - val_loss: 250.3710 - val_mae: 15.5485\n",
            "Epoch 8479/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 250.9271 - mae: 15.4683 - val_loss: 250.3409 - val_mae: 15.5475\n",
            "Epoch 8480/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 250.8978 - mae: 15.4674 - val_loss: 250.3108 - val_mae: 15.5466\n",
            "Epoch 8481/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 250.8685 - mae: 15.4664 - val_loss: 250.2808 - val_mae: 15.5456\n",
            "Epoch 8482/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 250.8392 - mae: 15.4655 - val_loss: 250.2506 - val_mae: 15.5446\n",
            "Epoch 8483/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 250.8098 - mae: 15.4646 - val_loss: 250.2206 - val_mae: 15.5437\n",
            "Epoch 8484/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 250.7806 - mae: 15.4636 - val_loss: 250.1905 - val_mae: 15.5427\n",
            "Epoch 8485/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 250.7513 - mae: 15.4627 - val_loss: 250.1604 - val_mae: 15.5417\n",
            "Epoch 8486/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 250.7219 - mae: 15.4617 - val_loss: 250.1303 - val_mae: 15.5408\n",
            "Epoch 8487/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 250.6926 - mae: 15.4608 - val_loss: 250.1003 - val_mae: 15.5398\n",
            "Epoch 8488/10000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 250.6633 - mae: 15.4598 - val_loss: 250.0702 - val_mae: 15.5389\n",
            "Epoch 8489/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 250.6341 - mae: 15.4589 - val_loss: 250.0401 - val_mae: 15.5379\n",
            "Epoch 8490/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 250.6047 - mae: 15.4580 - val_loss: 250.0100 - val_mae: 15.5369\n",
            "Epoch 8491/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 250.5755 - mae: 15.4570 - val_loss: 249.9799 - val_mae: 15.5360\n",
            "Epoch 8492/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 250.5461 - mae: 15.4561 - val_loss: 249.9499 - val_mae: 15.5350\n",
            "Epoch 8493/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 250.5169 - mae: 15.4551 - val_loss: 249.9198 - val_mae: 15.5340\n",
            "Epoch 8494/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 250.4876 - mae: 15.4542 - val_loss: 249.8897 - val_mae: 15.5331\n",
            "Epoch 8495/10000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 250.4583 - mae: 15.4533 - val_loss: 249.8597 - val_mae: 15.5321\n",
            "Epoch 8496/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 250.4290 - mae: 15.4523 - val_loss: 249.8296 - val_mae: 15.5311\n",
            "Epoch 8497/10000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 250.3997 - mae: 15.4514 - val_loss: 249.7995 - val_mae: 15.5302\n",
            "Epoch 8498/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 250.3705 - mae: 15.4504 - val_loss: 249.7695 - val_mae: 15.5292\n",
            "Epoch 8499/10000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 250.3412 - mae: 15.4495 - val_loss: 249.7395 - val_mae: 15.5282\n",
            "Epoch 8500/10000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 250.3119 - mae: 15.4486 - val_loss: 249.7094 - val_mae: 15.5273\n",
            "Epoch 8501/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 250.2826 - mae: 15.4476 - val_loss: 249.6793 - val_mae: 15.5263\n",
            "Epoch 8502/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 250.2533 - mae: 15.4467 - val_loss: 249.6493 - val_mae: 15.5253\n",
            "Epoch 8503/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 250.2241 - mae: 15.4457 - val_loss: 249.6192 - val_mae: 15.5244\n",
            "Epoch 8504/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 250.1948 - mae: 15.4448 - val_loss: 249.5892 - val_mae: 15.5234\n",
            "Epoch 8505/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 250.1655 - mae: 15.4438 - val_loss: 249.5591 - val_mae: 15.5224\n",
            "Epoch 8506/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 250.1362 - mae: 15.4429 - val_loss: 249.5291 - val_mae: 15.5215\n",
            "Epoch 8507/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 250.1070 - mae: 15.4420 - val_loss: 249.4991 - val_mae: 15.5205\n",
            "Epoch 8508/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 250.0777 - mae: 15.4410 - val_loss: 249.4690 - val_mae: 15.5195\n",
            "Epoch 8509/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 250.0485 - mae: 15.4401 - val_loss: 249.4390 - val_mae: 15.5186\n",
            "Epoch 8510/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 250.0192 - mae: 15.4391 - val_loss: 249.4090 - val_mae: 15.5176\n",
            "Epoch 8511/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 249.9900 - mae: 15.4382 - val_loss: 249.3789 - val_mae: 15.5166\n",
            "Epoch 8512/10000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 249.9607 - mae: 15.4373 - val_loss: 249.3489 - val_mae: 15.5157\n",
            "Epoch 8513/10000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 249.9315 - mae: 15.4363 - val_loss: 249.3188 - val_mae: 15.5147\n",
            "Epoch 8514/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 249.9022 - mae: 15.4354 - val_loss: 249.2888 - val_mae: 15.5137\n",
            "Epoch 8515/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 249.8730 - mae: 15.4344 - val_loss: 249.2588 - val_mae: 15.5128\n",
            "Epoch 8516/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 249.8437 - mae: 15.4335 - val_loss: 249.2288 - val_mae: 15.5118\n",
            "Epoch 8517/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 249.8145 - mae: 15.4325 - val_loss: 249.1988 - val_mae: 15.5108\n",
            "Epoch 8518/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 249.7852 - mae: 15.4316 - val_loss: 249.1687 - val_mae: 15.5099\n",
            "Epoch 8519/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 249.7560 - mae: 15.4307 - val_loss: 249.1387 - val_mae: 15.5089\n",
            "Epoch 8520/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 249.7268 - mae: 15.4297 - val_loss: 249.1087 - val_mae: 15.5079\n",
            "Epoch 8521/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 249.6975 - mae: 15.4288 - val_loss: 249.0787 - val_mae: 15.5070\n",
            "Epoch 8522/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 249.6683 - mae: 15.4278 - val_loss: 249.0487 - val_mae: 15.5060\n",
            "Epoch 8523/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 249.6391 - mae: 15.4269 - val_loss: 249.0187 - val_mae: 15.5051\n",
            "Epoch 8524/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 249.6098 - mae: 15.4260 - val_loss: 248.9887 - val_mae: 15.5041\n",
            "Epoch 8525/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 249.5806 - mae: 15.4250 - val_loss: 248.9586 - val_mae: 15.5031\n",
            "Epoch 8526/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 249.5513 - mae: 15.4241 - val_loss: 248.9287 - val_mae: 15.5022\n",
            "Epoch 8527/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 249.5221 - mae: 15.4231 - val_loss: 248.8987 - val_mae: 15.5012\n",
            "Epoch 8528/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 249.4929 - mae: 15.4222 - val_loss: 248.8687 - val_mae: 15.5002\n",
            "Epoch 8529/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 249.4637 - mae: 15.4213 - val_loss: 248.8387 - val_mae: 15.4993\n",
            "Epoch 8530/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 249.4345 - mae: 15.4203 - val_loss: 248.8087 - val_mae: 15.4983\n",
            "Epoch 8531/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 249.4052 - mae: 15.4194 - val_loss: 248.7787 - val_mae: 15.4973\n",
            "Epoch 8532/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 249.3760 - mae: 15.4184 - val_loss: 248.7487 - val_mae: 15.4964\n",
            "Epoch 8533/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 249.3468 - mae: 15.4175 - val_loss: 248.7187 - val_mae: 15.4954\n",
            "Epoch 8534/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 249.3176 - mae: 15.4165 - val_loss: 248.6887 - val_mae: 15.4944\n",
            "Epoch 8535/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 249.2884 - mae: 15.4156 - val_loss: 248.6587 - val_mae: 15.4935\n",
            "Epoch 8536/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 249.2592 - mae: 15.4147 - val_loss: 248.6288 - val_mae: 15.4925\n",
            "Epoch 8537/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 249.2299 - mae: 15.4137 - val_loss: 248.5988 - val_mae: 15.4915\n",
            "Epoch 8538/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 249.2008 - mae: 15.4128 - val_loss: 248.5688 - val_mae: 15.4906\n",
            "Epoch 8539/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 249.1716 - mae: 15.4118 - val_loss: 248.5388 - val_mae: 15.4896\n",
            "Epoch 8540/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 249.1423 - mae: 15.4109 - val_loss: 248.5088 - val_mae: 15.4886\n",
            "Epoch 8541/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 249.1132 - mae: 15.4100 - val_loss: 248.4789 - val_mae: 15.4877\n",
            "Epoch 8542/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 249.0840 - mae: 15.4090 - val_loss: 248.4489 - val_mae: 15.4867\n",
            "Epoch 8543/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 249.0548 - mae: 15.4081 - val_loss: 248.4189 - val_mae: 15.4857\n",
            "Epoch 8544/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 249.0255 - mae: 15.4071 - val_loss: 248.3890 - val_mae: 15.4848\n",
            "Epoch 8545/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 248.9964 - mae: 15.4062 - val_loss: 248.3590 - val_mae: 15.4838\n",
            "Epoch 8546/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 248.9671 - mae: 15.4053 - val_loss: 248.3291 - val_mae: 15.4828\n",
            "Epoch 8547/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 248.9380 - mae: 15.4043 - val_loss: 248.2991 - val_mae: 15.4819\n",
            "Epoch 8548/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 248.9088 - mae: 15.4034 - val_loss: 248.2691 - val_mae: 15.4809\n",
            "Epoch 8549/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 248.8796 - mae: 15.4024 - val_loss: 248.2392 - val_mae: 15.4800\n",
            "Epoch 8550/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 248.8505 - mae: 15.4015 - val_loss: 248.2092 - val_mae: 15.4790\n",
            "Epoch 8551/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 248.8212 - mae: 15.4005 - val_loss: 248.1792 - val_mae: 15.4780\n",
            "Epoch 8552/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 248.7921 - mae: 15.3996 - val_loss: 248.1493 - val_mae: 15.4771\n",
            "Epoch 8553/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 248.7629 - mae: 15.3987 - val_loss: 248.1193 - val_mae: 15.4761\n",
            "Epoch 8554/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 248.7337 - mae: 15.3977 - val_loss: 248.0894 - val_mae: 15.4751\n",
            "Epoch 8555/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 248.7045 - mae: 15.3968 - val_loss: 248.0595 - val_mae: 15.4742\n",
            "Epoch 8556/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 248.6754 - mae: 15.3958 - val_loss: 248.0295 - val_mae: 15.4732\n",
            "Epoch 8557/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 248.6462 - mae: 15.3949 - val_loss: 247.9996 - val_mae: 15.4722\n",
            "Epoch 8558/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 248.6170 - mae: 15.3940 - val_loss: 247.9697 - val_mae: 15.4713\n",
            "Epoch 8559/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 248.5879 - mae: 15.3930 - val_loss: 247.9397 - val_mae: 15.4703\n",
            "Epoch 8560/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 248.5587 - mae: 15.3921 - val_loss: 247.9098 - val_mae: 15.4693\n",
            "Epoch 8561/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 248.5295 - mae: 15.3911 - val_loss: 247.8798 - val_mae: 15.4684\n",
            "Epoch 8562/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 248.5004 - mae: 15.3902 - val_loss: 247.8499 - val_mae: 15.4674\n",
            "Epoch 8563/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 248.4712 - mae: 15.3893 - val_loss: 247.8200 - val_mae: 15.4664\n",
            "Epoch 8564/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 248.4420 - mae: 15.3883 - val_loss: 247.7900 - val_mae: 15.4655\n",
            "Epoch 8565/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 248.4129 - mae: 15.3874 - val_loss: 247.7602 - val_mae: 15.4645\n",
            "Epoch 8566/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 248.3837 - mae: 15.3864 - val_loss: 247.7302 - val_mae: 15.4635\n",
            "Epoch 8567/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 248.3546 - mae: 15.3855 - val_loss: 247.7003 - val_mae: 15.4626\n",
            "Epoch 8568/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 248.3255 - mae: 15.3845 - val_loss: 247.6704 - val_mae: 15.4616\n",
            "Epoch 8569/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 248.2963 - mae: 15.3836 - val_loss: 247.6404 - val_mae: 15.4606\n",
            "Epoch 8570/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 248.2672 - mae: 15.3827 - val_loss: 247.6105 - val_mae: 15.4597\n",
            "Epoch 8571/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 248.2380 - mae: 15.3817 - val_loss: 247.5806 - val_mae: 15.4587\n",
            "Epoch 8572/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 248.2088 - mae: 15.3808 - val_loss: 247.5507 - val_mae: 15.4577\n",
            "Epoch 8573/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 248.1797 - mae: 15.3798 - val_loss: 247.5208 - val_mae: 15.4568\n",
            "Epoch 8574/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 248.1506 - mae: 15.3789 - val_loss: 247.4909 - val_mae: 15.4558\n",
            "Epoch 8575/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 248.1215 - mae: 15.3780 - val_loss: 247.4610 - val_mae: 15.4549\n",
            "Epoch 8576/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 248.0923 - mae: 15.3770 - val_loss: 247.4311 - val_mae: 15.4539\n",
            "Epoch 8577/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 248.0632 - mae: 15.3761 - val_loss: 247.4012 - val_mae: 15.4529\n",
            "Epoch 8578/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 248.0341 - mae: 15.3751 - val_loss: 247.3713 - val_mae: 15.4520\n",
            "Epoch 8579/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 248.0049 - mae: 15.3742 - val_loss: 247.3414 - val_mae: 15.4510\n",
            "Epoch 8580/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 247.9758 - mae: 15.3733 - val_loss: 247.3115 - val_mae: 15.4500\n",
            "Epoch 8581/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 247.9467 - mae: 15.3723 - val_loss: 247.2816 - val_mae: 15.4491\n",
            "Epoch 8582/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 247.9176 - mae: 15.3714 - val_loss: 247.2517 - val_mae: 15.4481\n",
            "Epoch 8583/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 247.8884 - mae: 15.3704 - val_loss: 247.2218 - val_mae: 15.4471\n",
            "Epoch 8584/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 247.8593 - mae: 15.3695 - val_loss: 247.1919 - val_mae: 15.4462\n",
            "Epoch 8585/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 247.8302 - mae: 15.3685 - val_loss: 247.1621 - val_mae: 15.4452\n",
            "Epoch 8586/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 247.8011 - mae: 15.3676 - val_loss: 247.1322 - val_mae: 15.4442\n",
            "Epoch 8587/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 247.7720 - mae: 15.3667 - val_loss: 247.1023 - val_mae: 15.4433\n",
            "Epoch 8588/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 247.7428 - mae: 15.3657 - val_loss: 247.0724 - val_mae: 15.4423\n",
            "Epoch 8589/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 247.7137 - mae: 15.3648 - val_loss: 247.0425 - val_mae: 15.4413\n",
            "Epoch 8590/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 247.6846 - mae: 15.3638 - val_loss: 247.0126 - val_mae: 15.4404\n",
            "Epoch 8591/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 247.6555 - mae: 15.3629 - val_loss: 246.9828 - val_mae: 15.4394\n",
            "Epoch 8592/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 247.6264 - mae: 15.3620 - val_loss: 246.9529 - val_mae: 15.4384\n",
            "Epoch 8593/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 247.5973 - mae: 15.3610 - val_loss: 246.9230 - val_mae: 15.4375\n",
            "Epoch 8594/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 247.5682 - mae: 15.3601 - val_loss: 246.8932 - val_mae: 15.4365\n",
            "Epoch 8595/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 247.5391 - mae: 15.3591 - val_loss: 246.8633 - val_mae: 15.4355\n",
            "Epoch 8596/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 247.5100 - mae: 15.3582 - val_loss: 246.8335 - val_mae: 15.4346\n",
            "Epoch 8597/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 247.4809 - mae: 15.3572 - val_loss: 246.8036 - val_mae: 15.4336\n",
            "Epoch 8598/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 247.4518 - mae: 15.3563 - val_loss: 246.7737 - val_mae: 15.4326\n",
            "Epoch 8599/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 247.4227 - mae: 15.3554 - val_loss: 246.7439 - val_mae: 15.4317\n",
            "Epoch 8600/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 247.3936 - mae: 15.3544 - val_loss: 246.7140 - val_mae: 15.4307\n",
            "Epoch 8601/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 247.3645 - mae: 15.3535 - val_loss: 246.6842 - val_mae: 15.4298\n",
            "Epoch 8602/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 247.3355 - mae: 15.3525 - val_loss: 246.6543 - val_mae: 15.4288\n",
            "Epoch 8603/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 247.3064 - mae: 15.3516 - val_loss: 246.6245 - val_mae: 15.4278\n",
            "Epoch 8604/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 247.2773 - mae: 15.3507 - val_loss: 246.5946 - val_mae: 15.4269\n",
            "Epoch 8605/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 247.2482 - mae: 15.3497 - val_loss: 246.5648 - val_mae: 15.4259\n",
            "Epoch 8606/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 247.2191 - mae: 15.3488 - val_loss: 246.5350 - val_mae: 15.4249\n",
            "Epoch 8607/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 247.1900 - mae: 15.3478 - val_loss: 246.5051 - val_mae: 15.4240\n",
            "Epoch 8608/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 247.1610 - mae: 15.3469 - val_loss: 246.4753 - val_mae: 15.4230\n",
            "Epoch 8609/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 247.1319 - mae: 15.3460 - val_loss: 246.4454 - val_mae: 15.4220\n",
            "Epoch 8610/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 247.1028 - mae: 15.3450 - val_loss: 246.4156 - val_mae: 15.4211\n",
            "Epoch 8611/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 247.0738 - mae: 15.3441 - val_loss: 246.3858 - val_mae: 15.4201\n",
            "Epoch 8612/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 247.0447 - mae: 15.3431 - val_loss: 246.3560 - val_mae: 15.4191\n",
            "Epoch 8613/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 247.0157 - mae: 15.3422 - val_loss: 246.3261 - val_mae: 15.4182\n",
            "Epoch 8614/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 246.9866 - mae: 15.3412 - val_loss: 246.2963 - val_mae: 15.4172\n",
            "Epoch 8615/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 246.9575 - mae: 15.3403 - val_loss: 246.2664 - val_mae: 15.4162\n",
            "Epoch 8616/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 246.9285 - mae: 15.3394 - val_loss: 246.2366 - val_mae: 15.4153\n",
            "Epoch 8617/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 246.8994 - mae: 15.3384 - val_loss: 246.2068 - val_mae: 15.4143\n",
            "Epoch 8618/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 246.8703 - mae: 15.3375 - val_loss: 246.1770 - val_mae: 15.4133\n",
            "Epoch 8619/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 246.8413 - mae: 15.3365 - val_loss: 246.1472 - val_mae: 15.4124\n",
            "Epoch 8620/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 246.8122 - mae: 15.3356 - val_loss: 246.1174 - val_mae: 15.4114\n",
            "Epoch 8621/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 246.7832 - mae: 15.3347 - val_loss: 246.0876 - val_mae: 15.4104\n",
            "Epoch 8622/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 246.7541 - mae: 15.3337 - val_loss: 246.0578 - val_mae: 15.4095\n",
            "Epoch 8623/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 246.7251 - mae: 15.3328 - val_loss: 246.0279 - val_mae: 15.4085\n",
            "Epoch 8624/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 246.6960 - mae: 15.3318 - val_loss: 245.9981 - val_mae: 15.4076\n",
            "Epoch 8625/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 246.6670 - mae: 15.3309 - val_loss: 245.9683 - val_mae: 15.4066\n",
            "Epoch 8626/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 246.6379 - mae: 15.3300 - val_loss: 245.9385 - val_mae: 15.4056\n",
            "Epoch 8627/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 246.6089 - mae: 15.3290 - val_loss: 245.9087 - val_mae: 15.4047\n",
            "Epoch 8628/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 246.5799 - mae: 15.3281 - val_loss: 245.8789 - val_mae: 15.4037\n",
            "Epoch 8629/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 246.5508 - mae: 15.3271 - val_loss: 245.8491 - val_mae: 15.4027\n",
            "Epoch 8630/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 246.5218 - mae: 15.3262 - val_loss: 245.8193 - val_mae: 15.4018\n",
            "Epoch 8631/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 246.4928 - mae: 15.3252 - val_loss: 245.7896 - val_mae: 15.4008\n",
            "Epoch 8632/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 246.4637 - mae: 15.3243 - val_loss: 245.7597 - val_mae: 15.3998\n",
            "Epoch 8633/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 246.4347 - mae: 15.3234 - val_loss: 245.7300 - val_mae: 15.3989\n",
            "Epoch 8634/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 246.4057 - mae: 15.3224 - val_loss: 245.7002 - val_mae: 15.3979\n",
            "Epoch 8635/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 246.3766 - mae: 15.3215 - val_loss: 245.6704 - val_mae: 15.3969\n",
            "Epoch 8636/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 246.3476 - mae: 15.3205 - val_loss: 245.6406 - val_mae: 15.3960\n",
            "Epoch 8637/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 246.3186 - mae: 15.3196 - val_loss: 245.6108 - val_mae: 15.3950\n",
            "Epoch 8638/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 246.2896 - mae: 15.3187 - val_loss: 245.5811 - val_mae: 15.3940\n",
            "Epoch 8639/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 246.2606 - mae: 15.3177 - val_loss: 245.5513 - val_mae: 15.3931\n",
            "Epoch 8640/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 246.2316 - mae: 15.3168 - val_loss: 245.5215 - val_mae: 15.3921\n",
            "Epoch 8641/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 246.2026 - mae: 15.3158 - val_loss: 245.4917 - val_mae: 15.3911\n",
            "Epoch 8642/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 246.1735 - mae: 15.3149 - val_loss: 245.4620 - val_mae: 15.3902\n",
            "Epoch 8643/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 246.1445 - mae: 15.3139 - val_loss: 245.4322 - val_mae: 15.3892\n",
            "Epoch 8644/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 246.1155 - mae: 15.3130 - val_loss: 245.4024 - val_mae: 15.3883\n",
            "Epoch 8645/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 246.0865 - mae: 15.3121 - val_loss: 245.3727 - val_mae: 15.3873\n",
            "Epoch 8646/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 246.0575 - mae: 15.3111 - val_loss: 245.3429 - val_mae: 15.3863\n",
            "Epoch 8647/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 246.0285 - mae: 15.3102 - val_loss: 245.3131 - val_mae: 15.3854\n",
            "Epoch 8648/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 245.9995 - mae: 15.3092 - val_loss: 245.2834 - val_mae: 15.3844\n",
            "Epoch 8649/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 245.9705 - mae: 15.3083 - val_loss: 245.2536 - val_mae: 15.3834\n",
            "Epoch 8650/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 245.9415 - mae: 15.3074 - val_loss: 245.2239 - val_mae: 15.3825\n",
            "Epoch 8651/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 245.9125 - mae: 15.3064 - val_loss: 245.1941 - val_mae: 15.3815\n",
            "Epoch 8652/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 245.8835 - mae: 15.3055 - val_loss: 245.1644 - val_mae: 15.3805\n",
            "Epoch 8653/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 245.8545 - mae: 15.3045 - val_loss: 245.1346 - val_mae: 15.3796\n",
            "Epoch 8654/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 245.8255 - mae: 15.3036 - val_loss: 245.1049 - val_mae: 15.3786\n",
            "Epoch 8655/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 245.7966 - mae: 15.3027 - val_loss: 245.0751 - val_mae: 15.3776\n",
            "Epoch 8656/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 245.7676 - mae: 15.3017 - val_loss: 245.0454 - val_mae: 15.3767\n",
            "Epoch 8657/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 245.7386 - mae: 15.3008 - val_loss: 245.0157 - val_mae: 15.3757\n",
            "Epoch 8658/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 245.7096 - mae: 15.2998 - val_loss: 244.9859 - val_mae: 15.3747\n",
            "Epoch 8659/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 245.6806 - mae: 15.2989 - val_loss: 244.9561 - val_mae: 15.3738\n",
            "Epoch 8660/10000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 245.6516 - mae: 15.2979 - val_loss: 244.9264 - val_mae: 15.3728\n",
            "Epoch 8661/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 245.6226 - mae: 15.2970 - val_loss: 244.8967 - val_mae: 15.3718\n",
            "Epoch 8662/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 245.5937 - mae: 15.2961 - val_loss: 244.8670 - val_mae: 15.3709\n",
            "Epoch 8663/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 245.5647 - mae: 15.2951 - val_loss: 244.8372 - val_mae: 15.3699\n",
            "Epoch 8664/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 245.5357 - mae: 15.2942 - val_loss: 244.8075 - val_mae: 15.3689\n",
            "Epoch 8665/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 245.5068 - mae: 15.2932 - val_loss: 244.7778 - val_mae: 15.3680\n",
            "Epoch 8666/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 245.4778 - mae: 15.2923 - val_loss: 244.7480 - val_mae: 15.3670\n",
            "Epoch 8667/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 245.4489 - mae: 15.2914 - val_loss: 244.7183 - val_mae: 15.3661\n",
            "Epoch 8668/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 245.4199 - mae: 15.2904 - val_loss: 244.6886 - val_mae: 15.3651\n",
            "Epoch 8669/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 245.3909 - mae: 15.2895 - val_loss: 244.6589 - val_mae: 15.3641\n",
            "Epoch 8670/10000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 245.3620 - mae: 15.2885 - val_loss: 244.6292 - val_mae: 15.3632\n",
            "Epoch 8671/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 245.3330 - mae: 15.2876 - val_loss: 244.5995 - val_mae: 15.3622\n",
            "Epoch 8672/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 245.3040 - mae: 15.2867 - val_loss: 244.5698 - val_mae: 15.3612\n",
            "Epoch 8673/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 245.2751 - mae: 15.2857 - val_loss: 244.5401 - val_mae: 15.3603\n",
            "Epoch 8674/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 245.2461 - mae: 15.2848 - val_loss: 244.5103 - val_mae: 15.3593\n",
            "Epoch 8675/10000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 245.2172 - mae: 15.2838 - val_loss: 244.4806 - val_mae: 15.3583\n",
            "Epoch 8676/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 245.1882 - mae: 15.2829 - val_loss: 244.4510 - val_mae: 15.3574\n",
            "Epoch 8677/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 245.1593 - mae: 15.2819 - val_loss: 244.4212 - val_mae: 15.3564\n",
            "Epoch 8678/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 245.1304 - mae: 15.2810 - val_loss: 244.3916 - val_mae: 15.3554\n",
            "Epoch 8679/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 245.1014 - mae: 15.2801 - val_loss: 244.3619 - val_mae: 15.3545\n",
            "Epoch 8680/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 245.0724 - mae: 15.2791 - val_loss: 244.3322 - val_mae: 15.3535\n",
            "Epoch 8681/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 245.0435 - mae: 15.2782 - val_loss: 244.3025 - val_mae: 15.3525\n",
            "Epoch 8682/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 245.0146 - mae: 15.2772 - val_loss: 244.2728 - val_mae: 15.3516\n",
            "Epoch 8683/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 244.9857 - mae: 15.2763 - val_loss: 244.2431 - val_mae: 15.3506\n",
            "Epoch 8684/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 244.9567 - mae: 15.2754 - val_loss: 244.2134 - val_mae: 15.3496\n",
            "Epoch 8685/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 244.9278 - mae: 15.2744 - val_loss: 244.1837 - val_mae: 15.3487\n",
            "Epoch 8686/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 244.8988 - mae: 15.2735 - val_loss: 244.1540 - val_mae: 15.3477\n",
            "Epoch 8687/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 244.8699 - mae: 15.2725 - val_loss: 244.1244 - val_mae: 15.3468\n",
            "Epoch 8688/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 244.8410 - mae: 15.2716 - val_loss: 244.0947 - val_mae: 15.3458\n",
            "Epoch 8689/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 244.8121 - mae: 15.2707 - val_loss: 244.0650 - val_mae: 15.3448\n",
            "Epoch 8690/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 244.7832 - mae: 15.2697 - val_loss: 244.0353 - val_mae: 15.3439\n",
            "Epoch 8691/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 244.7543 - mae: 15.2688 - val_loss: 244.0056 - val_mae: 15.3429\n",
            "Epoch 8692/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 244.7253 - mae: 15.2678 - val_loss: 243.9760 - val_mae: 15.3419\n",
            "Epoch 8693/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 244.6964 - mae: 15.2669 - val_loss: 243.9463 - val_mae: 15.3410\n",
            "Epoch 8694/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 244.6675 - mae: 15.2659 - val_loss: 243.9167 - val_mae: 15.3400\n",
            "Epoch 8695/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 244.6385 - mae: 15.2650 - val_loss: 243.8870 - val_mae: 15.3390\n",
            "Epoch 8696/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 244.6096 - mae: 15.2641 - val_loss: 243.8573 - val_mae: 15.3381\n",
            "Epoch 8697/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 244.5807 - mae: 15.2631 - val_loss: 243.8277 - val_mae: 15.3371\n",
            "Epoch 8698/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 244.5518 - mae: 15.2622 - val_loss: 243.7980 - val_mae: 15.3361\n",
            "Epoch 8699/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 244.5229 - mae: 15.2612 - val_loss: 243.7684 - val_mae: 15.3352\n",
            "Epoch 8700/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 244.4940 - mae: 15.2603 - val_loss: 243.7387 - val_mae: 15.3342\n",
            "Epoch 8701/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 244.4651 - mae: 15.2594 - val_loss: 243.7090 - val_mae: 15.3332\n",
            "Epoch 8702/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 244.4362 - mae: 15.2584 - val_loss: 243.6794 - val_mae: 15.3323\n",
            "Epoch 8703/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 244.4073 - mae: 15.2575 - val_loss: 243.6497 - val_mae: 15.3313\n",
            "Epoch 8704/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 244.3784 - mae: 15.2565 - val_loss: 243.6201 - val_mae: 15.3304\n",
            "Epoch 8705/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 244.3495 - mae: 15.2556 - val_loss: 243.5905 - val_mae: 15.3294\n",
            "Epoch 8706/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 244.3207 - mae: 15.2547 - val_loss: 243.5609 - val_mae: 15.3284\n",
            "Epoch 8707/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 244.2918 - mae: 15.2537 - val_loss: 243.5313 - val_mae: 15.3275\n",
            "Epoch 8708/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 244.2630 - mae: 15.2528 - val_loss: 243.5017 - val_mae: 15.3265\n",
            "Epoch 8709/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 244.2341 - mae: 15.2518 - val_loss: 243.4721 - val_mae: 15.3255\n",
            "Epoch 8710/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 244.2053 - mae: 15.2509 - val_loss: 243.4425 - val_mae: 15.3246\n",
            "Epoch 8711/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 244.1764 - mae: 15.2499 - val_loss: 243.4128 - val_mae: 15.3236\n",
            "Epoch 8712/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 244.1476 - mae: 15.2490 - val_loss: 243.3833 - val_mae: 15.3226\n",
            "Epoch 8713/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 244.1187 - mae: 15.2481 - val_loss: 243.3537 - val_mae: 15.3217\n",
            "Epoch 8714/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 244.0898 - mae: 15.2471 - val_loss: 243.3241 - val_mae: 15.3207\n",
            "Epoch 8715/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 244.0610 - mae: 15.2462 - val_loss: 243.2945 - val_mae: 15.3197\n",
            "Epoch 8716/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 244.0322 - mae: 15.2452 - val_loss: 243.2649 - val_mae: 15.3188\n",
            "Epoch 8717/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 244.0033 - mae: 15.2443 - val_loss: 243.2353 - val_mae: 15.3178\n",
            "Epoch 8718/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 243.9745 - mae: 15.2434 - val_loss: 243.2057 - val_mae: 15.3169\n",
            "Epoch 8719/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 243.9457 - mae: 15.2424 - val_loss: 243.1761 - val_mae: 15.3159\n",
            "Epoch 8720/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 243.9168 - mae: 15.2415 - val_loss: 243.1465 - val_mae: 15.3149\n",
            "Epoch 8721/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 243.8880 - mae: 15.2405 - val_loss: 243.1169 - val_mae: 15.3140\n",
            "Epoch 8722/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 243.8591 - mae: 15.2396 - val_loss: 243.0874 - val_mae: 15.3130\n",
            "Epoch 8723/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 243.8303 - mae: 15.2387 - val_loss: 243.0578 - val_mae: 15.3120\n",
            "Epoch 8724/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 243.8014 - mae: 15.2377 - val_loss: 243.0282 - val_mae: 15.3111\n",
            "Epoch 8725/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 243.7726 - mae: 15.2368 - val_loss: 242.9986 - val_mae: 15.3101\n",
            "Epoch 8726/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 243.7438 - mae: 15.2358 - val_loss: 242.9690 - val_mae: 15.3091\n",
            "Epoch 8727/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 243.7150 - mae: 15.2349 - val_loss: 242.9395 - val_mae: 15.3082\n",
            "Epoch 8728/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 243.6861 - mae: 15.2340 - val_loss: 242.9099 - val_mae: 15.3072\n",
            "Epoch 8729/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 243.6573 - mae: 15.2330 - val_loss: 242.8803 - val_mae: 15.3063\n",
            "Epoch 8730/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 243.6285 - mae: 15.2321 - val_loss: 242.8508 - val_mae: 15.3053\n",
            "Epoch 8731/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 243.5997 - mae: 15.2311 - val_loss: 242.8212 - val_mae: 15.3043\n",
            "Epoch 8732/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 243.5709 - mae: 15.2302 - val_loss: 242.7916 - val_mae: 15.3034\n",
            "Epoch 8733/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 243.5421 - mae: 15.2293 - val_loss: 242.7621 - val_mae: 15.3024\n",
            "Epoch 8734/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 243.5133 - mae: 15.2283 - val_loss: 242.7325 - val_mae: 15.3014\n",
            "Epoch 8735/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 243.4845 - mae: 15.2274 - val_loss: 242.7030 - val_mae: 15.3005\n",
            "Epoch 8736/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 243.4557 - mae: 15.2264 - val_loss: 242.6734 - val_mae: 15.2995\n",
            "Epoch 8737/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 243.4268 - mae: 15.2255 - val_loss: 242.6438 - val_mae: 15.2985\n",
            "Epoch 8738/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 243.3980 - mae: 15.2246 - val_loss: 242.6143 - val_mae: 15.2976\n",
            "Epoch 8739/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 243.3692 - mae: 15.2236 - val_loss: 242.5848 - val_mae: 15.2966\n",
            "Epoch 8740/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 243.3405 - mae: 15.2227 - val_loss: 242.5553 - val_mae: 15.2957\n",
            "Epoch 8741/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 243.3116 - mae: 15.2217 - val_loss: 242.5257 - val_mae: 15.2947\n",
            "Epoch 8742/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 243.2829 - mae: 15.2208 - val_loss: 242.4961 - val_mae: 15.2937\n",
            "Epoch 8743/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 243.2541 - mae: 15.2199 - val_loss: 242.4666 - val_mae: 15.2928\n",
            "Epoch 8744/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 243.2252 - mae: 15.2189 - val_loss: 242.4371 - val_mae: 15.2918\n",
            "Epoch 8745/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 243.1965 - mae: 15.2180 - val_loss: 242.4075 - val_mae: 15.2908\n",
            "Epoch 8746/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 243.1677 - mae: 15.2170 - val_loss: 242.3780 - val_mae: 15.2899\n",
            "Epoch 8747/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 243.1389 - mae: 15.2161 - val_loss: 242.3485 - val_mae: 15.2889\n",
            "Epoch 8748/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 243.1101 - mae: 15.2152 - val_loss: 242.3189 - val_mae: 15.2879\n",
            "Epoch 8749/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 243.0813 - mae: 15.2142 - val_loss: 242.2894 - val_mae: 15.2870\n",
            "Epoch 8750/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 243.0525 - mae: 15.2133 - val_loss: 242.2599 - val_mae: 15.2860\n",
            "Epoch 8751/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 243.0238 - mae: 15.2123 - val_loss: 242.2304 - val_mae: 15.2851\n",
            "Epoch 8752/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 242.9950 - mae: 15.2114 - val_loss: 242.2009 - val_mae: 15.2841\n",
            "Epoch 8753/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 242.9662 - mae: 15.2105 - val_loss: 242.1713 - val_mae: 15.2831\n",
            "Epoch 8754/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 242.9374 - mae: 15.2095 - val_loss: 242.1418 - val_mae: 15.2822\n",
            "Epoch 8755/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 242.9087 - mae: 15.2086 - val_loss: 242.1123 - val_mae: 15.2812\n",
            "Epoch 8756/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 242.8799 - mae: 15.2076 - val_loss: 242.0828 - val_mae: 15.2802\n",
            "Epoch 8757/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 242.8511 - mae: 15.2067 - val_loss: 242.0533 - val_mae: 15.2793\n",
            "Epoch 8758/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 242.8223 - mae: 15.2058 - val_loss: 242.0238 - val_mae: 15.2783\n",
            "Epoch 8759/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 242.7936 - mae: 15.2048 - val_loss: 241.9942 - val_mae: 15.2773\n",
            "Epoch 8760/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 242.7648 - mae: 15.2039 - val_loss: 241.9648 - val_mae: 15.2764\n",
            "Epoch 8761/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 242.7360 - mae: 15.2029 - val_loss: 241.9353 - val_mae: 15.2754\n",
            "Epoch 8762/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 242.7073 - mae: 15.2020 - val_loss: 241.9058 - val_mae: 15.2745\n",
            "Epoch 8763/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 242.6786 - mae: 15.2011 - val_loss: 241.8762 - val_mae: 15.2735\n",
            "Epoch 8764/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 242.6498 - mae: 15.2001 - val_loss: 241.8467 - val_mae: 15.2725\n",
            "Epoch 8765/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 242.6210 - mae: 15.1992 - val_loss: 241.8173 - val_mae: 15.2716\n",
            "Epoch 8766/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 242.5923 - mae: 15.1982 - val_loss: 241.7878 - val_mae: 15.2706\n",
            "Epoch 8767/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 242.5635 - mae: 15.1973 - val_loss: 241.7583 - val_mae: 15.2696\n",
            "Epoch 8768/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 242.5348 - mae: 15.1963 - val_loss: 241.7288 - val_mae: 15.2687\n",
            "Epoch 8769/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 242.5060 - mae: 15.1954 - val_loss: 241.6993 - val_mae: 15.2677\n",
            "Epoch 8770/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 242.4773 - mae: 15.1945 - val_loss: 241.6698 - val_mae: 15.2667\n",
            "Epoch 8771/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 242.4485 - mae: 15.1935 - val_loss: 241.6403 - val_mae: 15.2658\n",
            "Epoch 8772/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 242.4198 - mae: 15.1926 - val_loss: 241.6108 - val_mae: 15.2648\n",
            "Epoch 8773/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 242.3911 - mae: 15.1917 - val_loss: 241.5813 - val_mae: 15.2639\n",
            "Epoch 8774/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 242.3623 - mae: 15.1907 - val_loss: 241.5519 - val_mae: 15.2629\n",
            "Epoch 8775/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 242.3336 - mae: 15.1898 - val_loss: 241.5224 - val_mae: 15.2619\n",
            "Epoch 8776/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 242.3049 - mae: 15.1888 - val_loss: 241.4929 - val_mae: 15.2610\n",
            "Epoch 8777/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 242.2761 - mae: 15.1879 - val_loss: 241.4635 - val_mae: 15.2600\n",
            "Epoch 8778/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 242.2474 - mae: 15.1869 - val_loss: 241.4340 - val_mae: 15.2590\n",
            "Epoch 8779/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 242.2187 - mae: 15.1860 - val_loss: 241.4045 - val_mae: 15.2581\n",
            "Epoch 8780/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 242.1899 - mae: 15.1851 - val_loss: 241.3750 - val_mae: 15.2571\n",
            "Epoch 8781/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 242.1612 - mae: 15.1841 - val_loss: 241.3456 - val_mae: 15.2561\n",
            "Epoch 8782/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 242.1325 - mae: 15.1832 - val_loss: 241.3161 - val_mae: 15.2552\n",
            "Epoch 8783/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 242.1038 - mae: 15.1822 - val_loss: 241.2867 - val_mae: 15.2542\n",
            "Epoch 8784/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 242.0751 - mae: 15.1813 - val_loss: 241.2572 - val_mae: 15.2533\n",
            "Epoch 8785/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 242.0463 - mae: 15.1804 - val_loss: 241.2278 - val_mae: 15.2523\n",
            "Epoch 8786/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 242.0176 - mae: 15.1794 - val_loss: 241.1983 - val_mae: 15.2513\n",
            "Epoch 8787/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 241.9889 - mae: 15.1785 - val_loss: 241.1689 - val_mae: 15.2504\n",
            "Epoch 8788/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 241.9602 - mae: 15.1775 - val_loss: 241.1394 - val_mae: 15.2494\n",
            "Epoch 8789/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 241.9315 - mae: 15.1766 - val_loss: 241.1100 - val_mae: 15.2484\n",
            "Epoch 8790/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 241.9028 - mae: 15.1757 - val_loss: 241.0805 - val_mae: 15.2475\n",
            "Epoch 8791/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 241.8741 - mae: 15.1747 - val_loss: 241.0511 - val_mae: 15.2465\n",
            "Epoch 8792/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 241.8454 - mae: 15.1738 - val_loss: 241.0216 - val_mae: 15.2455\n",
            "Epoch 8793/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 241.8167 - mae: 15.1728 - val_loss: 240.9922 - val_mae: 15.2446\n",
            "Epoch 8794/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 241.7880 - mae: 15.1719 - val_loss: 240.9628 - val_mae: 15.2436\n",
            "Epoch 8795/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 241.7593 - mae: 15.1710 - val_loss: 240.9333 - val_mae: 15.2427\n",
            "Epoch 8796/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 241.7306 - mae: 15.1700 - val_loss: 240.9039 - val_mae: 15.2417\n",
            "Epoch 8797/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 241.7019 - mae: 15.1691 - val_loss: 240.8744 - val_mae: 15.2407\n",
            "Epoch 8798/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 241.6732 - mae: 15.1681 - val_loss: 240.8450 - val_mae: 15.2398\n",
            "Epoch 8799/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 241.6445 - mae: 15.1672 - val_loss: 240.8156 - val_mae: 15.2388\n",
            "Epoch 8800/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 241.6158 - mae: 15.1663 - val_loss: 240.7862 - val_mae: 15.2378\n",
            "Epoch 8801/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 241.5871 - mae: 15.1653 - val_loss: 240.7568 - val_mae: 15.2369\n",
            "Epoch 8802/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 241.5584 - mae: 15.1644 - val_loss: 240.7273 - val_mae: 15.2359\n",
            "Epoch 8803/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 241.5297 - mae: 15.1634 - val_loss: 240.6979 - val_mae: 15.2349\n",
            "Epoch 8804/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 241.5011 - mae: 15.1625 - val_loss: 240.6685 - val_mae: 15.2340\n",
            "Epoch 8805/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 241.4724 - mae: 15.1616 - val_loss: 240.6391 - val_mae: 15.2330\n",
            "Epoch 8806/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 241.4437 - mae: 15.1606 - val_loss: 240.6097 - val_mae: 15.2321\n",
            "Epoch 8807/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 241.4150 - mae: 15.1597 - val_loss: 240.5802 - val_mae: 15.2311\n",
            "Epoch 8808/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 241.3864 - mae: 15.1587 - val_loss: 240.5508 - val_mae: 15.2301\n",
            "Epoch 8809/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 241.3577 - mae: 15.1578 - val_loss: 240.5214 - val_mae: 15.2292\n",
            "Epoch 8810/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 241.3290 - mae: 15.1569 - val_loss: 240.4920 - val_mae: 15.2282\n",
            "Epoch 8811/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 241.3004 - mae: 15.1559 - val_loss: 240.4626 - val_mae: 15.2272\n",
            "Epoch 8812/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 241.2717 - mae: 15.1550 - val_loss: 240.4333 - val_mae: 15.2263\n",
            "Epoch 8813/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 241.2430 - mae: 15.1540 - val_loss: 240.4038 - val_mae: 15.2253\n",
            "Epoch 8814/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 241.2143 - mae: 15.1531 - val_loss: 240.3745 - val_mae: 15.2243\n",
            "Epoch 8815/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 241.1857 - mae: 15.1522 - val_loss: 240.3450 - val_mae: 15.2234\n",
            "Epoch 8816/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 241.1570 - mae: 15.1512 - val_loss: 240.3156 - val_mae: 15.2224\n",
            "Epoch 8817/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 241.1284 - mae: 15.1503 - val_loss: 240.2862 - val_mae: 15.2215\n",
            "Epoch 8818/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 241.0997 - mae: 15.1493 - val_loss: 240.2568 - val_mae: 15.2205\n",
            "Epoch 8819/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 241.0711 - mae: 15.1484 - val_loss: 240.2275 - val_mae: 15.2195\n",
            "Epoch 8820/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 241.0424 - mae: 15.1475 - val_loss: 240.1981 - val_mae: 15.2186\n",
            "Epoch 8821/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 241.0138 - mae: 15.1465 - val_loss: 240.1687 - val_mae: 15.2176\n",
            "Epoch 8822/10000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 240.9851 - mae: 15.1456 - val_loss: 240.1393 - val_mae: 15.2166\n",
            "Epoch 8823/10000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 240.9565 - mae: 15.1446 - val_loss: 240.1099 - val_mae: 15.2157\n",
            "Epoch 8824/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 240.9278 - mae: 15.1437 - val_loss: 240.0806 - val_mae: 15.2147\n",
            "Epoch 8825/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 240.8992 - mae: 15.1428 - val_loss: 240.0512 - val_mae: 15.2137\n",
            "Epoch 8826/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 240.8705 - mae: 15.1418 - val_loss: 240.0218 - val_mae: 15.2128\n",
            "Epoch 8827/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 240.8419 - mae: 15.1409 - val_loss: 239.9925 - val_mae: 15.2118\n",
            "Epoch 8828/10000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 240.8133 - mae: 15.1399 - val_loss: 239.9631 - val_mae: 15.2109\n",
            "Epoch 8829/10000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 240.7846 - mae: 15.1390 - val_loss: 239.9337 - val_mae: 15.2099\n",
            "Epoch 8830/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 240.7560 - mae: 15.1381 - val_loss: 239.9043 - val_mae: 15.2089\n",
            "Epoch 8831/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 240.7274 - mae: 15.1371 - val_loss: 239.8750 - val_mae: 15.2080\n",
            "Epoch 8832/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 240.6987 - mae: 15.1362 - val_loss: 239.8456 - val_mae: 15.2070\n",
            "Epoch 8833/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 240.6701 - mae: 15.1352 - val_loss: 239.8163 - val_mae: 15.2060\n",
            "Epoch 8834/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 240.6415 - mae: 15.1343 - val_loss: 239.7869 - val_mae: 15.2051\n",
            "Epoch 8835/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 240.6128 - mae: 15.1334 - val_loss: 239.7575 - val_mae: 15.2041\n",
            "Epoch 8836/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 240.5842 - mae: 15.1324 - val_loss: 239.7282 - val_mae: 15.2031\n",
            "Epoch 8837/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 240.5556 - mae: 15.1315 - val_loss: 239.6988 - val_mae: 15.2022\n",
            "Epoch 8838/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 240.5270 - mae: 15.1305 - val_loss: 239.6695 - val_mae: 15.2012\n",
            "Epoch 8839/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 240.4984 - mae: 15.1296 - val_loss: 239.6401 - val_mae: 15.2003\n",
            "Epoch 8840/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 240.4698 - mae: 15.1286 - val_loss: 239.6108 - val_mae: 15.1993\n",
            "Epoch 8841/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 240.4411 - mae: 15.1277 - val_loss: 239.5815 - val_mae: 15.1983\n",
            "Epoch 8842/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 240.4125 - mae: 15.1268 - val_loss: 239.5521 - val_mae: 15.1974\n",
            "Epoch 8843/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 240.3839 - mae: 15.1258 - val_loss: 239.5228 - val_mae: 15.1964\n",
            "Epoch 8844/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 240.3553 - mae: 15.1249 - val_loss: 239.4935 - val_mae: 15.1954\n",
            "Epoch 8845/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 240.3267 - mae: 15.1239 - val_loss: 239.4641 - val_mae: 15.1945\n",
            "Epoch 8846/10000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 240.2981 - mae: 15.1230 - val_loss: 239.4348 - val_mae: 15.1935\n",
            "Epoch 8847/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 240.2695 - mae: 15.1221 - val_loss: 239.4054 - val_mae: 15.1926\n",
            "Epoch 8848/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 240.2409 - mae: 15.1211 - val_loss: 239.3761 - val_mae: 15.1916\n",
            "Epoch 8849/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 240.2123 - mae: 15.1202 - val_loss: 239.3468 - val_mae: 15.1906\n",
            "Epoch 8850/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 240.1837 - mae: 15.1192 - val_loss: 239.3175 - val_mae: 15.1897\n",
            "Epoch 8851/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 240.1551 - mae: 15.1183 - val_loss: 239.2881 - val_mae: 15.1887\n",
            "Epoch 8852/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 240.1265 - mae: 15.1174 - val_loss: 239.2588 - val_mae: 15.1877\n",
            "Epoch 8853/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 240.0979 - mae: 15.1164 - val_loss: 239.2295 - val_mae: 15.1868\n",
            "Epoch 8854/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 240.0694 - mae: 15.1155 - val_loss: 239.2002 - val_mae: 15.1858\n",
            "Epoch 8855/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 240.0408 - mae: 15.1145 - val_loss: 239.1709 - val_mae: 15.1848\n",
            "Epoch 8856/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 240.0122 - mae: 15.1136 - val_loss: 239.1416 - val_mae: 15.1839\n",
            "Epoch 8857/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 239.9836 - mae: 15.1127 - val_loss: 239.1123 - val_mae: 15.1829\n",
            "Epoch 8858/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 239.9550 - mae: 15.1117 - val_loss: 239.0830 - val_mae: 15.1820\n",
            "Epoch 8859/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 239.9264 - mae: 15.1108 - val_loss: 239.0536 - val_mae: 15.1810\n",
            "Epoch 8860/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 239.8978 - mae: 15.1098 - val_loss: 239.0243 - val_mae: 15.1800\n",
            "Epoch 8861/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 239.8693 - mae: 15.1089 - val_loss: 238.9950 - val_mae: 15.1791\n",
            "Epoch 8862/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 239.8407 - mae: 15.1080 - val_loss: 238.9657 - val_mae: 15.1781\n",
            "Epoch 8863/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 239.8121 - mae: 15.1070 - val_loss: 238.9364 - val_mae: 15.1771\n",
            "Epoch 8864/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 239.7836 - mae: 15.1061 - val_loss: 238.9071 - val_mae: 15.1762\n",
            "Epoch 8865/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 239.7550 - mae: 15.1051 - val_loss: 238.8778 - val_mae: 15.1752\n",
            "Epoch 8866/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 239.7264 - mae: 15.1042 - val_loss: 238.8485 - val_mae: 15.1743\n",
            "Epoch 8867/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 239.6978 - mae: 15.1033 - val_loss: 238.8192 - val_mae: 15.1733\n",
            "Epoch 8868/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 239.6693 - mae: 15.1023 - val_loss: 238.7900 - val_mae: 15.1723\n",
            "Epoch 8869/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 239.6407 - mae: 15.1014 - val_loss: 238.7607 - val_mae: 15.1714\n",
            "Epoch 8870/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 239.6122 - mae: 15.1004 - val_loss: 238.7314 - val_mae: 15.1704\n",
            "Epoch 8871/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 239.5836 - mae: 15.0995 - val_loss: 238.7021 - val_mae: 15.1694\n",
            "Epoch 8872/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 239.5551 - mae: 15.0986 - val_loss: 238.6728 - val_mae: 15.1685\n",
            "Epoch 8873/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 239.5265 - mae: 15.0976 - val_loss: 238.6435 - val_mae: 15.1675\n",
            "Epoch 8874/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 239.4980 - mae: 15.0967 - val_loss: 238.6143 - val_mae: 15.1665\n",
            "Epoch 8875/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 239.4694 - mae: 15.0957 - val_loss: 238.5850 - val_mae: 15.1656\n",
            "Epoch 8876/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 239.4408 - mae: 15.0948 - val_loss: 238.5557 - val_mae: 15.1646\n",
            "Epoch 8877/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 239.4123 - mae: 15.0939 - val_loss: 238.5264 - val_mae: 15.1637\n",
            "Epoch 8878/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 239.3838 - mae: 15.0929 - val_loss: 238.4972 - val_mae: 15.1627\n",
            "Epoch 8879/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 239.3552 - mae: 15.0920 - val_loss: 238.4679 - val_mae: 15.1617\n",
            "Epoch 8880/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 239.3267 - mae: 15.0910 - val_loss: 238.4386 - val_mae: 15.1608\n",
            "Epoch 8881/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 239.2982 - mae: 15.0901 - val_loss: 238.4094 - val_mae: 15.1598\n",
            "Epoch 8882/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 239.2696 - mae: 15.0892 - val_loss: 238.3801 - val_mae: 15.1588\n",
            "Epoch 8883/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 239.2411 - mae: 15.0882 - val_loss: 238.3509 - val_mae: 15.1579\n",
            "Epoch 8884/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 239.2125 - mae: 15.0873 - val_loss: 238.3216 - val_mae: 15.1569\n",
            "Epoch 8885/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 239.1840 - mae: 15.0863 - val_loss: 238.2923 - val_mae: 15.1560\n",
            "Epoch 8886/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 239.1554 - mae: 15.0854 - val_loss: 238.2631 - val_mae: 15.1550\n",
            "Epoch 8887/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 239.1270 - mae: 15.0845 - val_loss: 238.2338 - val_mae: 15.1540\n",
            "Epoch 8888/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 239.0984 - mae: 15.0835 - val_loss: 238.2046 - val_mae: 15.1531\n",
            "Epoch 8889/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 239.0699 - mae: 15.0826 - val_loss: 238.1753 - val_mae: 15.1521\n",
            "Epoch 8890/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 239.0414 - mae: 15.0816 - val_loss: 238.1461 - val_mae: 15.1511\n",
            "Epoch 8891/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 239.0128 - mae: 15.0807 - val_loss: 238.1169 - val_mae: 15.1502\n",
            "Epoch 8892/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 238.9843 - mae: 15.0797 - val_loss: 238.0876 - val_mae: 15.1492\n",
            "Epoch 8893/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 238.9558 - mae: 15.0788 - val_loss: 238.0584 - val_mae: 15.1482\n",
            "Epoch 8894/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 238.9273 - mae: 15.0779 - val_loss: 238.0291 - val_mae: 15.1473\n",
            "Epoch 8895/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 238.8988 - mae: 15.0769 - val_loss: 237.9999 - val_mae: 15.1463\n",
            "Epoch 8896/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 238.8703 - mae: 15.0760 - val_loss: 237.9707 - val_mae: 15.1454\n",
            "Epoch 8897/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 238.8418 - mae: 15.0750 - val_loss: 237.9415 - val_mae: 15.1444\n",
            "Epoch 8898/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 238.8133 - mae: 15.0741 - val_loss: 237.9122 - val_mae: 15.1434\n",
            "Epoch 8899/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 238.7848 - mae: 15.0732 - val_loss: 237.8830 - val_mae: 15.1425\n",
            "Epoch 8900/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 238.7563 - mae: 15.0722 - val_loss: 237.8538 - val_mae: 15.1415\n",
            "Epoch 8901/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 238.7277 - mae: 15.0713 - val_loss: 237.8245 - val_mae: 15.1405\n",
            "Epoch 8902/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 238.6993 - mae: 15.0703 - val_loss: 237.7953 - val_mae: 15.1396\n",
            "Epoch 8903/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 238.6707 - mae: 15.0694 - val_loss: 237.7661 - val_mae: 15.1386\n",
            "Epoch 8904/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 238.6423 - mae: 15.0685 - val_loss: 237.7369 - val_mae: 15.1377\n",
            "Epoch 8905/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 238.6138 - mae: 15.0675 - val_loss: 237.7077 - val_mae: 15.1367\n",
            "Epoch 8906/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 238.5853 - mae: 15.0666 - val_loss: 237.6785 - val_mae: 15.1357\n",
            "Epoch 8907/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 238.5568 - mae: 15.0656 - val_loss: 237.6492 - val_mae: 15.1348\n",
            "Epoch 8908/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 238.5283 - mae: 15.0647 - val_loss: 237.6200 - val_mae: 15.1338\n",
            "Epoch 8909/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 238.4998 - mae: 15.0638 - val_loss: 237.5908 - val_mae: 15.1328\n",
            "Epoch 8910/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 238.4713 - mae: 15.0628 - val_loss: 237.5616 - val_mae: 15.1319\n",
            "Epoch 8911/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 238.4429 - mae: 15.0619 - val_loss: 237.5324 - val_mae: 15.1309\n",
            "Epoch 8912/10000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 238.4144 - mae: 15.0609 - val_loss: 237.5032 - val_mae: 15.1299\n",
            "Epoch 8913/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 238.3859 - mae: 15.0600 - val_loss: 237.4740 - val_mae: 15.1290\n",
            "Epoch 8914/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 238.3574 - mae: 15.0591 - val_loss: 237.4448 - val_mae: 15.1280\n",
            "Epoch 8915/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 238.3289 - mae: 15.0581 - val_loss: 237.4156 - val_mae: 15.1271\n",
            "Epoch 8916/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 238.3004 - mae: 15.0572 - val_loss: 237.3864 - val_mae: 15.1261\n",
            "Epoch 8917/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 238.2720 - mae: 15.0562 - val_loss: 237.3572 - val_mae: 15.1251\n",
            "Epoch 8918/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 238.2435 - mae: 15.0553 - val_loss: 237.3280 - val_mae: 15.1242\n",
            "Epoch 8919/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 238.2151 - mae: 15.0544 - val_loss: 237.2989 - val_mae: 15.1232\n",
            "Epoch 8920/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 238.1866 - mae: 15.0534 - val_loss: 237.2697 - val_mae: 15.1222\n",
            "Epoch 8921/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 238.1581 - mae: 15.0525 - val_loss: 237.2405 - val_mae: 15.1213\n",
            "Epoch 8922/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 238.1296 - mae: 15.0515 - val_loss: 237.2113 - val_mae: 15.1203\n",
            "Epoch 8923/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 238.1012 - mae: 15.0506 - val_loss: 237.1821 - val_mae: 15.1194\n",
            "Epoch 8924/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 238.0727 - mae: 15.0497 - val_loss: 237.1530 - val_mae: 15.1184\n",
            "Epoch 8925/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 238.0443 - mae: 15.0487 - val_loss: 237.1238 - val_mae: 15.1174\n",
            "Epoch 8926/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 238.0158 - mae: 15.0478 - val_loss: 237.0946 - val_mae: 15.1165\n",
            "Epoch 8927/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 237.9874 - mae: 15.0468 - val_loss: 237.0654 - val_mae: 15.1155\n",
            "Epoch 8928/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 237.9589 - mae: 15.0459 - val_loss: 237.0363 - val_mae: 15.1145\n",
            "Epoch 8929/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 237.9305 - mae: 15.0450 - val_loss: 237.0071 - val_mae: 15.1136\n",
            "Epoch 8930/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 237.9020 - mae: 15.0440 - val_loss: 236.9779 - val_mae: 15.1126\n",
            "Epoch 8931/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 237.8736 - mae: 15.0431 - val_loss: 236.9488 - val_mae: 15.1117\n",
            "Epoch 8932/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 237.8451 - mae: 15.0421 - val_loss: 236.9196 - val_mae: 15.1107\n",
            "Epoch 8933/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 237.8167 - mae: 15.0412 - val_loss: 236.8904 - val_mae: 15.1097\n",
            "Epoch 8934/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 237.7882 - mae: 15.0403 - val_loss: 236.8613 - val_mae: 15.1088\n",
            "Epoch 8935/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 237.7598 - mae: 15.0393 - val_loss: 236.8321 - val_mae: 15.1078\n",
            "Epoch 8936/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 237.7314 - mae: 15.0384 - val_loss: 236.8030 - val_mae: 15.1068\n",
            "Epoch 8937/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 237.7029 - mae: 15.0374 - val_loss: 236.7738 - val_mae: 15.1059\n",
            "Epoch 8938/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 237.6745 - mae: 15.0365 - val_loss: 236.7447 - val_mae: 15.1049\n",
            "Epoch 8939/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 237.6461 - mae: 15.0356 - val_loss: 236.7155 - val_mae: 15.1039\n",
            "Epoch 8940/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 237.6176 - mae: 15.0346 - val_loss: 236.6864 - val_mae: 15.1030\n",
            "Epoch 8941/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 237.5892 - mae: 15.0337 - val_loss: 236.6573 - val_mae: 15.1020\n",
            "Epoch 8942/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 237.5608 - mae: 15.0327 - val_loss: 236.6281 - val_mae: 15.1011\n",
            "Epoch 8943/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 237.5323 - mae: 15.0318 - val_loss: 236.5990 - val_mae: 15.1001\n",
            "Epoch 8944/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 237.5039 - mae: 15.0309 - val_loss: 236.5698 - val_mae: 15.0991\n",
            "Epoch 8945/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 237.4755 - mae: 15.0299 - val_loss: 236.5407 - val_mae: 15.0982\n",
            "Epoch 8946/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 237.4471 - mae: 15.0290 - val_loss: 236.5116 - val_mae: 15.0972\n",
            "Epoch 8947/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 237.4187 - mae: 15.0280 - val_loss: 236.4824 - val_mae: 15.0962\n",
            "Epoch 8948/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 237.3902 - mae: 15.0271 - val_loss: 236.4533 - val_mae: 15.0953\n",
            "Epoch 8949/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 237.3618 - mae: 15.0262 - val_loss: 236.4242 - val_mae: 15.0943\n",
            "Epoch 8950/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 237.3334 - mae: 15.0252 - val_loss: 236.3951 - val_mae: 15.0934\n",
            "Epoch 8951/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 237.3050 - mae: 15.0243 - val_loss: 236.3659 - val_mae: 15.0924\n",
            "Epoch 8952/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 237.2766 - mae: 15.0233 - val_loss: 236.3368 - val_mae: 15.0914\n",
            "Epoch 8953/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 237.2482 - mae: 15.0224 - val_loss: 236.3077 - val_mae: 15.0905\n",
            "Epoch 8954/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 237.2198 - mae: 15.0215 - val_loss: 236.2786 - val_mae: 15.0895\n",
            "Epoch 8955/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 237.1914 - mae: 15.0205 - val_loss: 236.2495 - val_mae: 15.0885\n",
            "Epoch 8956/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 237.1630 - mae: 15.0196 - val_loss: 236.2204 - val_mae: 15.0876\n",
            "Epoch 8957/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 237.1346 - mae: 15.0186 - val_loss: 236.1912 - val_mae: 15.0866\n",
            "Epoch 8958/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 237.1062 - mae: 15.0177 - val_loss: 236.1622 - val_mae: 15.0857\n",
            "Epoch 8959/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 237.0778 - mae: 15.0167 - val_loss: 236.1330 - val_mae: 15.0847\n",
            "Epoch 8960/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 237.0494 - mae: 15.0158 - val_loss: 236.1039 - val_mae: 15.0837\n",
            "Epoch 8961/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 237.0210 - mae: 15.0149 - val_loss: 236.0748 - val_mae: 15.0828\n",
            "Epoch 8962/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 236.9927 - mae: 15.0139 - val_loss: 236.0457 - val_mae: 15.0818\n",
            "Epoch 8963/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 236.9642 - mae: 15.0130 - val_loss: 236.0166 - val_mae: 15.0808\n",
            "Epoch 8964/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 236.9359 - mae: 15.0120 - val_loss: 235.9875 - val_mae: 15.0799\n",
            "Epoch 8965/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 236.9075 - mae: 15.0111 - val_loss: 235.9584 - val_mae: 15.0789\n",
            "Epoch 8966/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 236.8791 - mae: 15.0102 - val_loss: 235.9294 - val_mae: 15.0779\n",
            "Epoch 8967/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 236.8507 - mae: 15.0092 - val_loss: 235.9002 - val_mae: 15.0770\n",
            "Epoch 8968/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 236.8224 - mae: 15.0083 - val_loss: 235.8711 - val_mae: 15.0760\n",
            "Epoch 8969/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 236.7940 - mae: 15.0073 - val_loss: 235.8421 - val_mae: 15.0751\n",
            "Epoch 8970/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 236.7656 - mae: 15.0064 - val_loss: 235.8130 - val_mae: 15.0741\n",
            "Epoch 8971/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 236.7372 - mae: 15.0055 - val_loss: 235.7839 - val_mae: 15.0731\n",
            "Epoch 8972/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 236.7088 - mae: 15.0045 - val_loss: 235.7548 - val_mae: 15.0722\n",
            "Epoch 8973/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 236.6805 - mae: 15.0036 - val_loss: 235.7257 - val_mae: 15.0712\n",
            "Epoch 8974/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 236.6521 - mae: 15.0026 - val_loss: 235.6967 - val_mae: 15.0702\n",
            "Epoch 8975/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 236.6237 - mae: 15.0017 - val_loss: 235.6676 - val_mae: 15.0693\n",
            "Epoch 8976/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 236.5954 - mae: 15.0008 - val_loss: 235.6385 - val_mae: 15.0683\n",
            "Epoch 8977/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 236.5670 - mae: 14.9998 - val_loss: 235.6095 - val_mae: 15.0674\n",
            "Epoch 8978/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 236.5387 - mae: 14.9989 - val_loss: 235.5804 - val_mae: 15.0664\n",
            "Epoch 8979/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 236.5103 - mae: 14.9979 - val_loss: 235.5513 - val_mae: 15.0654\n",
            "Epoch 8980/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 236.4819 - mae: 14.9970 - val_loss: 235.5223 - val_mae: 15.0645\n",
            "Epoch 8981/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 236.4536 - mae: 14.9961 - val_loss: 235.4932 - val_mae: 15.0635\n",
            "Epoch 8982/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 236.4253 - mae: 14.9951 - val_loss: 235.4642 - val_mae: 15.0625\n",
            "Epoch 8983/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 236.3970 - mae: 14.9942 - val_loss: 235.4352 - val_mae: 15.0616\n",
            "Epoch 8984/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 236.3687 - mae: 14.9932 - val_loss: 235.4062 - val_mae: 15.0606\n",
            "Epoch 8985/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 236.3404 - mae: 14.9923 - val_loss: 235.3771 - val_mae: 15.0597\n",
            "Epoch 8986/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 236.3120 - mae: 14.9914 - val_loss: 235.3481 - val_mae: 15.0587\n",
            "Epoch 8987/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 236.2837 - mae: 14.9904 - val_loss: 235.3191 - val_mae: 15.0577\n",
            "Epoch 8988/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 236.2554 - mae: 14.9895 - val_loss: 235.2900 - val_mae: 15.0568\n",
            "Epoch 8989/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 236.2271 - mae: 14.9885 - val_loss: 235.2610 - val_mae: 15.0558\n",
            "Epoch 8990/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 236.1988 - mae: 14.9876 - val_loss: 235.2320 - val_mae: 15.0549\n",
            "Epoch 8991/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 236.1705 - mae: 14.9867 - val_loss: 235.2030 - val_mae: 15.0539\n",
            "Epoch 8992/10000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 236.1422 - mae: 14.9857 - val_loss: 235.1740 - val_mae: 15.0529\n",
            "Epoch 8993/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 236.1139 - mae: 14.9848 - val_loss: 235.1450 - val_mae: 15.0520\n",
            "Epoch 8994/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 236.0856 - mae: 14.9839 - val_loss: 235.1160 - val_mae: 15.0510\n",
            "Epoch 8995/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 236.0573 - mae: 14.9829 - val_loss: 235.0870 - val_mae: 15.0500\n",
            "Epoch 8996/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 236.0290 - mae: 14.9820 - val_loss: 235.0580 - val_mae: 15.0491\n",
            "Epoch 8997/10000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 236.0007 - mae: 14.9810 - val_loss: 235.0290 - val_mae: 15.0481\n",
            "Epoch 8998/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 235.9724 - mae: 14.9801 - val_loss: 235.0000 - val_mae: 15.0472\n",
            "Epoch 8999/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 235.9441 - mae: 14.9792 - val_loss: 234.9709 - val_mae: 15.0462\n",
            "Epoch 9000/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 235.9158 - mae: 14.9782 - val_loss: 234.9420 - val_mae: 15.0452\n",
            "Epoch 9001/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 235.8875 - mae: 14.9773 - val_loss: 234.9130 - val_mae: 15.0443\n",
            "Epoch 9002/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 235.8592 - mae: 14.9763 - val_loss: 234.8840 - val_mae: 15.0433\n",
            "Epoch 9003/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 235.8309 - mae: 14.9754 - val_loss: 234.8550 - val_mae: 15.0424\n",
            "Epoch 9004/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 235.8027 - mae: 14.9745 - val_loss: 234.8260 - val_mae: 15.0414\n",
            "Epoch 9005/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 235.7744 - mae: 14.9735 - val_loss: 234.7970 - val_mae: 15.0404\n",
            "Epoch 9006/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 235.7461 - mae: 14.9726 - val_loss: 234.7680 - val_mae: 15.0395\n",
            "Epoch 9007/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 235.7178 - mae: 14.9716 - val_loss: 234.7391 - val_mae: 15.0385\n",
            "Epoch 9008/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 235.6895 - mae: 14.9707 - val_loss: 234.7101 - val_mae: 15.0375\n",
            "Epoch 9009/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 235.6613 - mae: 14.9698 - val_loss: 234.6811 - val_mae: 15.0366\n",
            "Epoch 9010/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 235.6330 - mae: 14.9688 - val_loss: 234.6521 - val_mae: 15.0356\n",
            "Epoch 9011/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 235.6047 - mae: 14.9679 - val_loss: 234.6231 - val_mae: 15.0347\n",
            "Epoch 9012/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 235.5765 - mae: 14.9669 - val_loss: 234.5942 - val_mae: 15.0337\n",
            "Epoch 9013/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 235.5482 - mae: 14.9660 - val_loss: 234.5652 - val_mae: 15.0327\n",
            "Epoch 9014/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 235.5199 - mae: 14.9651 - val_loss: 234.5362 - val_mae: 15.0318\n",
            "Epoch 9015/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 235.4917 - mae: 14.9641 - val_loss: 234.5073 - val_mae: 15.0308\n",
            "Epoch 9016/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 235.4634 - mae: 14.9632 - val_loss: 234.4783 - val_mae: 15.0299\n",
            "Epoch 9017/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 235.4352 - mae: 14.9622 - val_loss: 234.4493 - val_mae: 15.0289\n",
            "Epoch 9018/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 235.4069 - mae: 14.9613 - val_loss: 234.4204 - val_mae: 15.0279\n",
            "Epoch 9019/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 235.3787 - mae: 14.9604 - val_loss: 234.3914 - val_mae: 15.0270\n",
            "Epoch 9020/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 235.3504 - mae: 14.9594 - val_loss: 234.3625 - val_mae: 15.0260\n",
            "Epoch 9021/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 235.3221 - mae: 14.9585 - val_loss: 234.3335 - val_mae: 15.0250\n",
            "Epoch 9022/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 235.2939 - mae: 14.9575 - val_loss: 234.3046 - val_mae: 15.0241\n",
            "Epoch 9023/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 235.2656 - mae: 14.9566 - val_loss: 234.2756 - val_mae: 15.0231\n",
            "Epoch 9024/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 235.2374 - mae: 14.9557 - val_loss: 234.2467 - val_mae: 15.0222\n",
            "Epoch 9025/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 235.2092 - mae: 14.9547 - val_loss: 234.2177 - val_mae: 15.0212\n",
            "Epoch 9026/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 235.1809 - mae: 14.9538 - val_loss: 234.1888 - val_mae: 15.0202\n",
            "Epoch 9027/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 235.1527 - mae: 14.9529 - val_loss: 234.1598 - val_mae: 15.0193\n",
            "Epoch 9028/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 235.1244 - mae: 14.9519 - val_loss: 234.1309 - val_mae: 15.0183\n",
            "Epoch 9029/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 235.0962 - mae: 14.9510 - val_loss: 234.1019 - val_mae: 15.0173\n",
            "Epoch 9030/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 235.0680 - mae: 14.9500 - val_loss: 234.0730 - val_mae: 15.0164\n",
            "Epoch 9031/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 235.0397 - mae: 14.9491 - val_loss: 234.0441 - val_mae: 15.0154\n",
            "Epoch 9032/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 235.0115 - mae: 14.9482 - val_loss: 234.0152 - val_mae: 15.0145\n",
            "Epoch 9033/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 234.9833 - mae: 14.9472 - val_loss: 233.9862 - val_mae: 15.0135\n",
            "Epoch 9034/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 234.9551 - mae: 14.9463 - val_loss: 233.9573 - val_mae: 15.0125\n",
            "Epoch 9035/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 234.9268 - mae: 14.9453 - val_loss: 233.9284 - val_mae: 15.0116\n",
            "Epoch 9036/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 234.8986 - mae: 14.9444 - val_loss: 233.8995 - val_mae: 15.0106\n",
            "Epoch 9037/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 234.8704 - mae: 14.9435 - val_loss: 233.8705 - val_mae: 15.0097\n",
            "Epoch 9038/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 234.8421 - mae: 14.9425 - val_loss: 233.8416 - val_mae: 15.0087\n",
            "Epoch 9039/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 234.8139 - mae: 14.9416 - val_loss: 233.8127 - val_mae: 15.0077\n",
            "Epoch 9040/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 234.7857 - mae: 14.9406 - val_loss: 233.7838 - val_mae: 15.0068\n",
            "Epoch 9041/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 234.7575 - mae: 14.9397 - val_loss: 233.7549 - val_mae: 15.0058\n",
            "Epoch 9042/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 234.7293 - mae: 14.9388 - val_loss: 233.7259 - val_mae: 15.0049\n",
            "Epoch 9043/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 234.7011 - mae: 14.9378 - val_loss: 233.6970 - val_mae: 15.0039\n",
            "Epoch 9044/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 234.6729 - mae: 14.9369 - val_loss: 233.6681 - val_mae: 15.0029\n",
            "Epoch 9045/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 234.6447 - mae: 14.9359 - val_loss: 233.6392 - val_mae: 15.0020\n",
            "Epoch 9046/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 234.6165 - mae: 14.9350 - val_loss: 233.6103 - val_mae: 15.0010\n",
            "Epoch 9047/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 234.5883 - mae: 14.9341 - val_loss: 233.5814 - val_mae: 15.0000\n",
            "Epoch 9048/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 234.5601 - mae: 14.9331 - val_loss: 233.5525 - val_mae: 14.9991\n",
            "Epoch 9049/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 234.5318 - mae: 14.9322 - val_loss: 233.5236 - val_mae: 14.9981\n",
            "Epoch 9050/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 234.5037 - mae: 14.9312 - val_loss: 233.4947 - val_mae: 14.9972\n",
            "Epoch 9051/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 234.4755 - mae: 14.9303 - val_loss: 233.4658 - val_mae: 14.9962\n",
            "Epoch 9052/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 234.4473 - mae: 14.9294 - val_loss: 233.4369 - val_mae: 14.9952\n",
            "Epoch 9053/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 234.4191 - mae: 14.9284 - val_loss: 233.4080 - val_mae: 14.9943\n",
            "Epoch 9054/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 234.3909 - mae: 14.9275 - val_loss: 233.3792 - val_mae: 14.9933\n",
            "Epoch 9055/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 234.3627 - mae: 14.9266 - val_loss: 233.3503 - val_mae: 14.9924\n",
            "Epoch 9056/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 234.3345 - mae: 14.9256 - val_loss: 233.3214 - val_mae: 14.9914\n",
            "Epoch 9057/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 234.3063 - mae: 14.9247 - val_loss: 233.2925 - val_mae: 14.9904\n",
            "Epoch 9058/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 234.2782 - mae: 14.9237 - val_loss: 233.2636 - val_mae: 14.9895\n",
            "Epoch 9059/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 234.2500 - mae: 14.9228 - val_loss: 233.2347 - val_mae: 14.9885\n",
            "Epoch 9060/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 234.2218 - mae: 14.9219 - val_loss: 233.2059 - val_mae: 14.9875\n",
            "Epoch 9061/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 234.1936 - mae: 14.9209 - val_loss: 233.1770 - val_mae: 14.9866\n",
            "Epoch 9062/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 234.1654 - mae: 14.9200 - val_loss: 233.1481 - val_mae: 14.9856\n",
            "Epoch 9063/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 234.1373 - mae: 14.9190 - val_loss: 233.1192 - val_mae: 14.9847\n",
            "Epoch 9064/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 234.1091 - mae: 14.9181 - val_loss: 233.0904 - val_mae: 14.9837\n",
            "Epoch 9065/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 234.0809 - mae: 14.9172 - val_loss: 233.0615 - val_mae: 14.9827\n",
            "Epoch 9066/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 234.0527 - mae: 14.9162 - val_loss: 233.0327 - val_mae: 14.9818\n",
            "Epoch 9067/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 234.0246 - mae: 14.9153 - val_loss: 233.0038 - val_mae: 14.9808\n",
            "Epoch 9068/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 233.9964 - mae: 14.9143 - val_loss: 232.9749 - val_mae: 14.9799\n",
            "Epoch 9069/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 233.9683 - mae: 14.9134 - val_loss: 232.9461 - val_mae: 14.9789\n",
            "Epoch 9070/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 233.9401 - mae: 14.9125 - val_loss: 232.9172 - val_mae: 14.9779\n",
            "Epoch 9071/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 233.9120 - mae: 14.9115 - val_loss: 232.8884 - val_mae: 14.9770\n",
            "Epoch 9072/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 233.8838 - mae: 14.9106 - val_loss: 232.8595 - val_mae: 14.9760\n",
            "Epoch 9073/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 233.8556 - mae: 14.9096 - val_loss: 232.8307 - val_mae: 14.9750\n",
            "Epoch 9074/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 233.8275 - mae: 14.9087 - val_loss: 232.8018 - val_mae: 14.9741\n",
            "Epoch 9075/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 233.7993 - mae: 14.9078 - val_loss: 232.7730 - val_mae: 14.9731\n",
            "Epoch 9076/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 233.7712 - mae: 14.9068 - val_loss: 232.7441 - val_mae: 14.9722\n",
            "Epoch 9077/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 233.7430 - mae: 14.9059 - val_loss: 232.7153 - val_mae: 14.9712\n",
            "Epoch 9078/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 233.7149 - mae: 14.9049 - val_loss: 232.6864 - val_mae: 14.9702\n",
            "Epoch 9079/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 233.6867 - mae: 14.9040 - val_loss: 232.6576 - val_mae: 14.9693\n",
            "Epoch 9080/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 233.6586 - mae: 14.9031 - val_loss: 232.6288 - val_mae: 14.9683\n",
            "Epoch 9081/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 233.6304 - mae: 14.9021 - val_loss: 232.5999 - val_mae: 14.9674\n",
            "Epoch 9082/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 233.6023 - mae: 14.9012 - val_loss: 232.5711 - val_mae: 14.9664\n",
            "Epoch 9083/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 233.5742 - mae: 14.9002 - val_loss: 232.5423 - val_mae: 14.9654\n",
            "Epoch 9084/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 233.5460 - mae: 14.8993 - val_loss: 232.5134 - val_mae: 14.9645\n",
            "Epoch 9085/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 233.5179 - mae: 14.8984 - val_loss: 232.4846 - val_mae: 14.9635\n",
            "Epoch 9086/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 233.4898 - mae: 14.8974 - val_loss: 232.4558 - val_mae: 14.9626\n",
            "Epoch 9087/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 233.4617 - mae: 14.8965 - val_loss: 232.4270 - val_mae: 14.9616\n",
            "Epoch 9088/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 233.4335 - mae: 14.8955 - val_loss: 232.3981 - val_mae: 14.9606\n",
            "Epoch 9089/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 233.4054 - mae: 14.8946 - val_loss: 232.3693 - val_mae: 14.9597\n",
            "Epoch 9090/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 233.3773 - mae: 14.8937 - val_loss: 232.3405 - val_mae: 14.9587\n",
            "Epoch 9091/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 233.3492 - mae: 14.8927 - val_loss: 232.3117 - val_mae: 14.9577\n",
            "Epoch 9092/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 233.3210 - mae: 14.8918 - val_loss: 232.2829 - val_mae: 14.9568\n",
            "Epoch 9093/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 233.2929 - mae: 14.8909 - val_loss: 232.2541 - val_mae: 14.9558\n",
            "Epoch 9094/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 233.2648 - mae: 14.8899 - val_loss: 232.2253 - val_mae: 14.9549\n",
            "Epoch 9095/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 233.2367 - mae: 14.8890 - val_loss: 232.1965 - val_mae: 14.9539\n",
            "Epoch 9096/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 233.2086 - mae: 14.8880 - val_loss: 232.1677 - val_mae: 14.9529\n",
            "Epoch 9097/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 233.1805 - mae: 14.8871 - val_loss: 232.1389 - val_mae: 14.9520\n",
            "Epoch 9098/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 233.1523 - mae: 14.8862 - val_loss: 232.1101 - val_mae: 14.9510\n",
            "Epoch 9099/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 233.1243 - mae: 14.8852 - val_loss: 232.0813 - val_mae: 14.9501\n",
            "Epoch 9100/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 233.0961 - mae: 14.8843 - val_loss: 232.0525 - val_mae: 14.9491\n",
            "Epoch 9101/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 233.0681 - mae: 14.8833 - val_loss: 232.0237 - val_mae: 14.9481\n",
            "Epoch 9102/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 233.0399 - mae: 14.8824 - val_loss: 231.9949 - val_mae: 14.9472\n",
            "Epoch 9103/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 233.0118 - mae: 14.8815 - val_loss: 231.9661 - val_mae: 14.9462\n",
            "Epoch 9104/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 232.9837 - mae: 14.8805 - val_loss: 231.9373 - val_mae: 14.9452\n",
            "Epoch 9105/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 232.9556 - mae: 14.8796 - val_loss: 231.9085 - val_mae: 14.9443\n",
            "Epoch 9106/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 232.9276 - mae: 14.8786 - val_loss: 231.8797 - val_mae: 14.9433\n",
            "Epoch 9107/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 232.8994 - mae: 14.8777 - val_loss: 231.8510 - val_mae: 14.9424\n",
            "Epoch 9108/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 232.8714 - mae: 14.8768 - val_loss: 231.8222 - val_mae: 14.9414\n",
            "Epoch 9109/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 232.8433 - mae: 14.8758 - val_loss: 231.7934 - val_mae: 14.9404\n",
            "Epoch 9110/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 232.8152 - mae: 14.8749 - val_loss: 231.7646 - val_mae: 14.9395\n",
            "Epoch 9111/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 232.7871 - mae: 14.8739 - val_loss: 231.7358 - val_mae: 14.9385\n",
            "Epoch 9112/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 232.7590 - mae: 14.8730 - val_loss: 231.7071 - val_mae: 14.9376\n",
            "Epoch 9113/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 232.7309 - mae: 14.8721 - val_loss: 231.6783 - val_mae: 14.9366\n",
            "Epoch 9114/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 232.7029 - mae: 14.8711 - val_loss: 231.6495 - val_mae: 14.9356\n",
            "Epoch 9115/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 232.6748 - mae: 14.8702 - val_loss: 231.6208 - val_mae: 14.9347\n",
            "Epoch 9116/10000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 232.6467 - mae: 14.8692 - val_loss: 231.5920 - val_mae: 14.9337\n",
            "Epoch 9117/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 232.6186 - mae: 14.8683 - val_loss: 231.5632 - val_mae: 14.9328\n",
            "Epoch 9118/10000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 232.5906 - mae: 14.8674 - val_loss: 231.5345 - val_mae: 14.9318\n",
            "Epoch 9119/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 232.5625 - mae: 14.8664 - val_loss: 231.5057 - val_mae: 14.9308\n",
            "Epoch 9120/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 232.5344 - mae: 14.8655 - val_loss: 231.4770 - val_mae: 14.9299\n",
            "Epoch 9121/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 232.5064 - mae: 14.8646 - val_loss: 231.4482 - val_mae: 14.9289\n",
            "Epoch 9122/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 232.4783 - mae: 14.8636 - val_loss: 231.4195 - val_mae: 14.9279\n",
            "Epoch 9123/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 232.4502 - mae: 14.8627 - val_loss: 231.3907 - val_mae: 14.9270\n",
            "Epoch 9124/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 232.4222 - mae: 14.8617 - val_loss: 231.3620 - val_mae: 14.9260\n",
            "Epoch 9125/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 232.3941 - mae: 14.8608 - val_loss: 231.3333 - val_mae: 14.9251\n",
            "Epoch 9126/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 232.3660 - mae: 14.8599 - val_loss: 231.3045 - val_mae: 14.9241\n",
            "Epoch 9127/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 232.3380 - mae: 14.8589 - val_loss: 231.2757 - val_mae: 14.9231\n",
            "Epoch 9128/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 232.3100 - mae: 14.8580 - val_loss: 231.2470 - val_mae: 14.9222\n",
            "Epoch 9129/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 232.2819 - mae: 14.8570 - val_loss: 231.2183 - val_mae: 14.9212\n",
            "Epoch 9130/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 232.2538 - mae: 14.8561 - val_loss: 231.1895 - val_mae: 14.9203\n",
            "Epoch 9131/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 232.2258 - mae: 14.8552 - val_loss: 231.1608 - val_mae: 14.9193\n",
            "Epoch 9132/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 232.1977 - mae: 14.8542 - val_loss: 231.1320 - val_mae: 14.9183\n",
            "Epoch 9133/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 232.1697 - mae: 14.8533 - val_loss: 231.1033 - val_mae: 14.9174\n",
            "Epoch 9134/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 232.1417 - mae: 14.8523 - val_loss: 231.0746 - val_mae: 14.9164\n",
            "Epoch 9135/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 232.1136 - mae: 14.8514 - val_loss: 231.0459 - val_mae: 14.9155\n",
            "Epoch 9136/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 232.0856 - mae: 14.8505 - val_loss: 231.0172 - val_mae: 14.9145\n",
            "Epoch 9137/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 232.0575 - mae: 14.8495 - val_loss: 230.9884 - val_mae: 14.9135\n",
            "Epoch 9138/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 232.0295 - mae: 14.8486 - val_loss: 230.9597 - val_mae: 14.9126\n",
            "Epoch 9139/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 232.0015 - mae: 14.8476 - val_loss: 230.9310 - val_mae: 14.9116\n",
            "Epoch 9140/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 231.9734 - mae: 14.8467 - val_loss: 230.9023 - val_mae: 14.9106\n",
            "Epoch 9141/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 231.9454 - mae: 14.8458 - val_loss: 230.8736 - val_mae: 14.9097\n",
            "Epoch 9142/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 231.9174 - mae: 14.8448 - val_loss: 230.8448 - val_mae: 14.9087\n",
            "Epoch 9143/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 231.8894 - mae: 14.8439 - val_loss: 230.8162 - val_mae: 14.9078\n",
            "Epoch 9144/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 231.8613 - mae: 14.8429 - val_loss: 230.7874 - val_mae: 14.9068\n",
            "Epoch 9145/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 231.8333 - mae: 14.8420 - val_loss: 230.7587 - val_mae: 14.9058\n",
            "Epoch 9146/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 231.8053 - mae: 14.8411 - val_loss: 230.7300 - val_mae: 14.9049\n",
            "Epoch 9147/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 231.7773 - mae: 14.8401 - val_loss: 230.7013 - val_mae: 14.9039\n",
            "Epoch 9148/10000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 231.7493 - mae: 14.8392 - val_loss: 230.6726 - val_mae: 14.9030\n",
            "Epoch 9149/10000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 231.7213 - mae: 14.8383 - val_loss: 230.6439 - val_mae: 14.9020\n",
            "Epoch 9150/10000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 231.6932 - mae: 14.8373 - val_loss: 230.6152 - val_mae: 14.9010\n",
            "Epoch 9151/10000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 231.6652 - mae: 14.8364 - val_loss: 230.5865 - val_mae: 14.9001\n",
            "Epoch 9152/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 231.6372 - mae: 14.8354 - val_loss: 230.5578 - val_mae: 14.8991\n",
            "Epoch 9153/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 231.6092 - mae: 14.8345 - val_loss: 230.5291 - val_mae: 14.8982\n",
            "Epoch 9154/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 231.5812 - mae: 14.8336 - val_loss: 230.5005 - val_mae: 14.8972\n",
            "Epoch 9155/10000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 231.5532 - mae: 14.8326 - val_loss: 230.4718 - val_mae: 14.8962\n",
            "Epoch 9156/10000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 231.5252 - mae: 14.8317 - val_loss: 230.4431 - val_mae: 14.8953\n",
            "Epoch 9157/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 231.4972 - mae: 14.8307 - val_loss: 230.4144 - val_mae: 14.8943\n",
            "Epoch 9158/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 231.4692 - mae: 14.8298 - val_loss: 230.3857 - val_mae: 14.8934\n",
            "Epoch 9159/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 231.4412 - mae: 14.8289 - val_loss: 230.3570 - val_mae: 14.8924\n",
            "Epoch 9160/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 231.4132 - mae: 14.8279 - val_loss: 230.3284 - val_mae: 14.8914\n",
            "Epoch 9161/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 231.3852 - mae: 14.8270 - val_loss: 230.2997 - val_mae: 14.8905\n",
            "Epoch 9162/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 231.3572 - mae: 14.8260 - val_loss: 230.2710 - val_mae: 14.8895\n",
            "Epoch 9163/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 231.3292 - mae: 14.8251 - val_loss: 230.2424 - val_mae: 14.8885\n",
            "Epoch 9164/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 231.3012 - mae: 14.8242 - val_loss: 230.2137 - val_mae: 14.8876\n",
            "Epoch 9165/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 231.2733 - mae: 14.8232 - val_loss: 230.1850 - val_mae: 14.8866\n",
            "Epoch 9166/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 231.2453 - mae: 14.8223 - val_loss: 230.1563 - val_mae: 14.8857\n",
            "Epoch 9167/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 231.2173 - mae: 14.8213 - val_loss: 230.1277 - val_mae: 14.8847\n",
            "Epoch 9168/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 231.1893 - mae: 14.8204 - val_loss: 230.0990 - val_mae: 14.8837\n",
            "Epoch 9169/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 231.1613 - mae: 14.8195 - val_loss: 230.0704 - val_mae: 14.8828\n",
            "Epoch 9170/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 231.1333 - mae: 14.8185 - val_loss: 230.0417 - val_mae: 14.8818\n",
            "Epoch 9171/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 231.1054 - mae: 14.8176 - val_loss: 230.0131 - val_mae: 14.8809\n",
            "Epoch 9172/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 231.0774 - mae: 14.8166 - val_loss: 229.9844 - val_mae: 14.8799\n",
            "Epoch 9173/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 231.0495 - mae: 14.8157 - val_loss: 229.9558 - val_mae: 14.8789\n",
            "Epoch 9174/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 231.0215 - mae: 14.8148 - val_loss: 229.9271 - val_mae: 14.8780\n",
            "Epoch 9175/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 230.9935 - mae: 14.8138 - val_loss: 229.8985 - val_mae: 14.8770\n",
            "Epoch 9176/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 230.9655 - mae: 14.8129 - val_loss: 229.8698 - val_mae: 14.8761\n",
            "Epoch 9177/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 230.9376 - mae: 14.8119 - val_loss: 229.8412 - val_mae: 14.8751\n",
            "Epoch 9178/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 230.9096 - mae: 14.8110 - val_loss: 229.8125 - val_mae: 14.8741\n",
            "Epoch 9179/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 230.8816 - mae: 14.8101 - val_loss: 229.7839 - val_mae: 14.8732\n",
            "Epoch 9180/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 230.8537 - mae: 14.8091 - val_loss: 229.7553 - val_mae: 14.8722\n",
            "Epoch 9181/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 230.8258 - mae: 14.8082 - val_loss: 229.7267 - val_mae: 14.8713\n",
            "Epoch 9182/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 230.7978 - mae: 14.8073 - val_loss: 229.6980 - val_mae: 14.8703\n",
            "Epoch 9183/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 230.7698 - mae: 14.8063 - val_loss: 229.6694 - val_mae: 14.8693\n",
            "Epoch 9184/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 230.7419 - mae: 14.8054 - val_loss: 229.6408 - val_mae: 14.8684\n",
            "Epoch 9185/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 230.7139 - mae: 14.8044 - val_loss: 229.6121 - val_mae: 14.8674\n",
            "Epoch 9186/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 230.6860 - mae: 14.8035 - val_loss: 229.5835 - val_mae: 14.8664\n",
            "Epoch 9187/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 230.6581 - mae: 14.8026 - val_loss: 229.5549 - val_mae: 14.8655\n",
            "Epoch 9188/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 230.6301 - mae: 14.8016 - val_loss: 229.5263 - val_mae: 14.8645\n",
            "Epoch 9189/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 230.6022 - mae: 14.8007 - val_loss: 229.4977 - val_mae: 14.8636\n",
            "Epoch 9190/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 230.5742 - mae: 14.7997 - val_loss: 229.4690 - val_mae: 14.8626\n",
            "Epoch 9191/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 230.5463 - mae: 14.7988 - val_loss: 229.4404 - val_mae: 14.8616\n",
            "Epoch 9192/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 230.5183 - mae: 14.7979 - val_loss: 229.4118 - val_mae: 14.8607\n",
            "Epoch 9193/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 230.4904 - mae: 14.7969 - val_loss: 229.3832 - val_mae: 14.8597\n",
            "Epoch 9194/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 230.4625 - mae: 14.7960 - val_loss: 229.3546 - val_mae: 14.8588\n",
            "Epoch 9195/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 230.4346 - mae: 14.7950 - val_loss: 229.3260 - val_mae: 14.8578\n",
            "Epoch 9196/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 230.4066 - mae: 14.7941 - val_loss: 229.2974 - val_mae: 14.8568\n",
            "Epoch 9197/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 230.3787 - mae: 14.7932 - val_loss: 229.2688 - val_mae: 14.8559\n",
            "Epoch 9198/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 230.3508 - mae: 14.7922 - val_loss: 229.2402 - val_mae: 14.8549\n",
            "Epoch 9199/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 230.3228 - mae: 14.7913 - val_loss: 229.2116 - val_mae: 14.8540\n",
            "Epoch 9200/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 230.2949 - mae: 14.7903 - val_loss: 229.1830 - val_mae: 14.8530\n",
            "Epoch 9201/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 230.2670 - mae: 14.7894 - val_loss: 229.1544 - val_mae: 14.8520\n",
            "Epoch 9202/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 230.2391 - mae: 14.7885 - val_loss: 229.1258 - val_mae: 14.8511\n",
            "Epoch 9203/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 230.2112 - mae: 14.7875 - val_loss: 229.0972 - val_mae: 14.8501\n",
            "Epoch 9204/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 230.1833 - mae: 14.7866 - val_loss: 229.0686 - val_mae: 14.8492\n",
            "Epoch 9205/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 230.1554 - mae: 14.7856 - val_loss: 229.0401 - val_mae: 14.8482\n",
            "Epoch 9206/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 230.1275 - mae: 14.7847 - val_loss: 229.0114 - val_mae: 14.8472\n",
            "Epoch 9207/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 230.0995 - mae: 14.7838 - val_loss: 228.9829 - val_mae: 14.8463\n",
            "Epoch 9208/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 230.0716 - mae: 14.7828 - val_loss: 228.9543 - val_mae: 14.8453\n",
            "Epoch 9209/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 230.0437 - mae: 14.7819 - val_loss: 228.9257 - val_mae: 14.8444\n",
            "Epoch 9210/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 230.0158 - mae: 14.7809 - val_loss: 228.8972 - val_mae: 14.8434\n",
            "Epoch 9211/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 229.9879 - mae: 14.7800 - val_loss: 228.8686 - val_mae: 14.8424\n",
            "Epoch 9212/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 229.9601 - mae: 14.7791 - val_loss: 228.8400 - val_mae: 14.8415\n",
            "Epoch 9213/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 229.9321 - mae: 14.7781 - val_loss: 228.8114 - val_mae: 14.8405\n",
            "Epoch 9214/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 229.9042 - mae: 14.7772 - val_loss: 228.7829 - val_mae: 14.8395\n",
            "Epoch 9215/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 229.8764 - mae: 14.7762 - val_loss: 228.7543 - val_mae: 14.8386\n",
            "Epoch 9216/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 229.8484 - mae: 14.7753 - val_loss: 228.7257 - val_mae: 14.8376\n",
            "Epoch 9217/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 229.8206 - mae: 14.7744 - val_loss: 228.6972 - val_mae: 14.8367\n",
            "Epoch 9218/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 229.7927 - mae: 14.7734 - val_loss: 228.6686 - val_mae: 14.8357\n",
            "Epoch 9219/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 229.7648 - mae: 14.7725 - val_loss: 228.6401 - val_mae: 14.8347\n",
            "Epoch 9220/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 229.7369 - mae: 14.7716 - val_loss: 228.6115 - val_mae: 14.8338\n",
            "Epoch 9221/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 229.7090 - mae: 14.7706 - val_loss: 228.5830 - val_mae: 14.8328\n",
            "Epoch 9222/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 229.6811 - mae: 14.7697 - val_loss: 228.5544 - val_mae: 14.8319\n",
            "Epoch 9223/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 229.6533 - mae: 14.7687 - val_loss: 228.5258 - val_mae: 14.8309\n",
            "Epoch 9224/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 229.6254 - mae: 14.7678 - val_loss: 228.4973 - val_mae: 14.8299\n",
            "Epoch 9225/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 229.5975 - mae: 14.7669 - val_loss: 228.4688 - val_mae: 14.8290\n",
            "Epoch 9226/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 229.5696 - mae: 14.7659 - val_loss: 228.4402 - val_mae: 14.8280\n",
            "Epoch 9227/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 229.5418 - mae: 14.7650 - val_loss: 228.4117 - val_mae: 14.8271\n",
            "Epoch 9228/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 229.5139 - mae: 14.7640 - val_loss: 228.3831 - val_mae: 14.8261\n",
            "Epoch 9229/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 229.4860 - mae: 14.7631 - val_loss: 228.3546 - val_mae: 14.8251\n",
            "Epoch 9230/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 229.4582 - mae: 14.7622 - val_loss: 228.3260 - val_mae: 14.8242\n",
            "Epoch 9231/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 229.4303 - mae: 14.7612 - val_loss: 228.2975 - val_mae: 14.8232\n",
            "Epoch 9232/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 229.4024 - mae: 14.7603 - val_loss: 228.2690 - val_mae: 14.8223\n",
            "Epoch 9233/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 229.3746 - mae: 14.7593 - val_loss: 228.2405 - val_mae: 14.8213\n",
            "Epoch 9234/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 229.3467 - mae: 14.7584 - val_loss: 228.2119 - val_mae: 14.8203\n",
            "Epoch 9235/10000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 229.3189 - mae: 14.7575 - val_loss: 228.1834 - val_mae: 14.8194\n",
            "Epoch 9236/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 229.2910 - mae: 14.7565 - val_loss: 228.1549 - val_mae: 14.8184\n",
            "Epoch 9237/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 229.2631 - mae: 14.7556 - val_loss: 228.1264 - val_mae: 14.8175\n",
            "Epoch 9238/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 229.2353 - mae: 14.7546 - val_loss: 228.0979 - val_mae: 14.8165\n",
            "Epoch 9239/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 229.2074 - mae: 14.7537 - val_loss: 228.0693 - val_mae: 14.8155\n",
            "Epoch 9240/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 229.1796 - mae: 14.7528 - val_loss: 228.0408 - val_mae: 14.8146\n",
            "Epoch 9241/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 229.1517 - mae: 14.7518 - val_loss: 228.0123 - val_mae: 14.8136\n",
            "Epoch 9242/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 229.1239 - mae: 14.7509 - val_loss: 227.9838 - val_mae: 14.8127\n",
            "Epoch 9243/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 229.0961 - mae: 14.7499 - val_loss: 227.9553 - val_mae: 14.8117\n",
            "Epoch 9244/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 229.0682 - mae: 14.7490 - val_loss: 227.9268 - val_mae: 14.8107\n",
            "Epoch 9245/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 229.0404 - mae: 14.7481 - val_loss: 227.8983 - val_mae: 14.8098\n",
            "Epoch 9246/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 229.0126 - mae: 14.7471 - val_loss: 227.8698 - val_mae: 14.8088\n",
            "Epoch 9247/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 228.9847 - mae: 14.7462 - val_loss: 227.8413 - val_mae: 14.8079\n",
            "Epoch 9248/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 228.9569 - mae: 14.7453 - val_loss: 227.8128 - val_mae: 14.8069\n",
            "Epoch 9249/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 228.9291 - mae: 14.7443 - val_loss: 227.7843 - val_mae: 14.8059\n",
            "Epoch 9250/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 228.9013 - mae: 14.7434 - val_loss: 227.7558 - val_mae: 14.8050\n",
            "Epoch 9251/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 228.8735 - mae: 14.7424 - val_loss: 227.7274 - val_mae: 14.8040\n",
            "Epoch 9252/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 228.8457 - mae: 14.7415 - val_loss: 227.6989 - val_mae: 14.8031\n",
            "Epoch 9253/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 228.8179 - mae: 14.7406 - val_loss: 227.6705 - val_mae: 14.8021\n",
            "Epoch 9254/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 228.7901 - mae: 14.7396 - val_loss: 227.6420 - val_mae: 14.8011\n",
            "Epoch 9255/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 228.7623 - mae: 14.7387 - val_loss: 227.6136 - val_mae: 14.8002\n",
            "Epoch 9256/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 228.7345 - mae: 14.7377 - val_loss: 227.5851 - val_mae: 14.7992\n",
            "Epoch 9257/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 228.7067 - mae: 14.7368 - val_loss: 227.5566 - val_mae: 14.7983\n",
            "Epoch 9258/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 228.6790 - mae: 14.7359 - val_loss: 227.5282 - val_mae: 14.7973\n",
            "Epoch 9259/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 228.6512 - mae: 14.7349 - val_loss: 227.4998 - val_mae: 14.7963\n",
            "Epoch 9260/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 228.6234 - mae: 14.7340 - val_loss: 227.4713 - val_mae: 14.7954\n",
            "Epoch 9261/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 228.5956 - mae: 14.7331 - val_loss: 227.4429 - val_mae: 14.7944\n",
            "Epoch 9262/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 228.5678 - mae: 14.7321 - val_loss: 227.4144 - val_mae: 14.7935\n",
            "Epoch 9263/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 228.5400 - mae: 14.7312 - val_loss: 227.3860 - val_mae: 14.7925\n",
            "Epoch 9264/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 228.5123 - mae: 14.7302 - val_loss: 227.3575 - val_mae: 14.7915\n",
            "Epoch 9265/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 228.4845 - mae: 14.7293 - val_loss: 227.3291 - val_mae: 14.7906\n",
            "Epoch 9266/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 228.4568 - mae: 14.7284 - val_loss: 227.3007 - val_mae: 14.7896\n",
            "Epoch 9267/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 228.4290 - mae: 14.7274 - val_loss: 227.2722 - val_mae: 14.7887\n",
            "Epoch 9268/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 228.4012 - mae: 14.7265 - val_loss: 227.2438 - val_mae: 14.7877\n",
            "Epoch 9269/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 228.3734 - mae: 14.7255 - val_loss: 227.2154 - val_mae: 14.7867\n",
            "Epoch 9270/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 228.3456 - mae: 14.7246 - val_loss: 227.1869 - val_mae: 14.7858\n",
            "Epoch 9271/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 228.3179 - mae: 14.7237 - val_loss: 227.1585 - val_mae: 14.7848\n",
            "Epoch 9272/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 228.2901 - mae: 14.7227 - val_loss: 227.1301 - val_mae: 14.7839\n",
            "Epoch 9273/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 228.2624 - mae: 14.7218 - val_loss: 227.1017 - val_mae: 14.7829\n",
            "Epoch 9274/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 228.2347 - mae: 14.7209 - val_loss: 227.0732 - val_mae: 14.7819\n",
            "Epoch 9275/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 228.2069 - mae: 14.7199 - val_loss: 227.0448 - val_mae: 14.7810\n",
            "Epoch 9276/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 228.1791 - mae: 14.7190 - val_loss: 227.0164 - val_mae: 14.7800\n",
            "Epoch 9277/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 228.1514 - mae: 14.7180 - val_loss: 226.9880 - val_mae: 14.7791\n",
            "Epoch 9278/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 228.1236 - mae: 14.7171 - val_loss: 226.9596 - val_mae: 14.7781\n",
            "Epoch 9279/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 228.0959 - mae: 14.7162 - val_loss: 226.9312 - val_mae: 14.7771\n",
            "Epoch 9280/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 228.0681 - mae: 14.7152 - val_loss: 226.9028 - val_mae: 14.7762\n",
            "Epoch 9281/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 228.0404 - mae: 14.7143 - val_loss: 226.8744 - val_mae: 14.7752\n",
            "Epoch 9282/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 228.0126 - mae: 14.7133 - val_loss: 226.8459 - val_mae: 14.7743\n",
            "Epoch 9283/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 227.9849 - mae: 14.7124 - val_loss: 226.8176 - val_mae: 14.7733\n",
            "Epoch 9284/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 227.9572 - mae: 14.7115 - val_loss: 226.7892 - val_mae: 14.7724\n",
            "Epoch 9285/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 227.9294 - mae: 14.7105 - val_loss: 226.7608 - val_mae: 14.7714\n",
            "Epoch 9286/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 227.9017 - mae: 14.7096 - val_loss: 226.7324 - val_mae: 14.7704\n",
            "Epoch 9287/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 227.8740 - mae: 14.7087 - val_loss: 226.7040 - val_mae: 14.7695\n",
            "Epoch 9288/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 227.8462 - mae: 14.7077 - val_loss: 226.6756 - val_mae: 14.7685\n",
            "Epoch 9289/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 227.8185 - mae: 14.7068 - val_loss: 226.6472 - val_mae: 14.7676\n",
            "Epoch 9290/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 227.7908 - mae: 14.7058 - val_loss: 226.6188 - val_mae: 14.7666\n",
            "Epoch 9291/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 227.7630 - mae: 14.7049 - val_loss: 226.5904 - val_mae: 14.7656\n",
            "Epoch 9292/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 227.7353 - mae: 14.7040 - val_loss: 226.5620 - val_mae: 14.7647\n",
            "Epoch 9293/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 227.7076 - mae: 14.7030 - val_loss: 226.5337 - val_mae: 14.7637\n",
            "Epoch 9294/10000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 227.6799 - mae: 14.7021 - val_loss: 226.5053 - val_mae: 14.7628\n",
            "Epoch 9295/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 227.6522 - mae: 14.7011 - val_loss: 226.4769 - val_mae: 14.7618\n",
            "Epoch 9296/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 227.6244 - mae: 14.7002 - val_loss: 226.4485 - val_mae: 14.7608\n",
            "Epoch 9297/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 227.5967 - mae: 14.6993 - val_loss: 226.4201 - val_mae: 14.7599\n",
            "Epoch 9298/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 227.5690 - mae: 14.6983 - val_loss: 226.3918 - val_mae: 14.7589\n",
            "Epoch 9299/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 227.5413 - mae: 14.6974 - val_loss: 226.3634 - val_mae: 14.7580\n",
            "Epoch 9300/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 227.5136 - mae: 14.6965 - val_loss: 226.3351 - val_mae: 14.7570\n",
            "Epoch 9301/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 227.4859 - mae: 14.6955 - val_loss: 226.3067 - val_mae: 14.7560\n",
            "Epoch 9302/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 227.4582 - mae: 14.6946 - val_loss: 226.2783 - val_mae: 14.7551\n",
            "Epoch 9303/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 227.4305 - mae: 14.6936 - val_loss: 226.2500 - val_mae: 14.7541\n",
            "Epoch 9304/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 227.4028 - mae: 14.6927 - val_loss: 226.2216 - val_mae: 14.7532\n",
            "Epoch 9305/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 227.3751 - mae: 14.6918 - val_loss: 226.1933 - val_mae: 14.7522\n",
            "Epoch 9306/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 227.3474 - mae: 14.6908 - val_loss: 226.1649 - val_mae: 14.7513\n",
            "Epoch 9307/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 227.3197 - mae: 14.6899 - val_loss: 226.1365 - val_mae: 14.7503\n",
            "Epoch 9308/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 227.2920 - mae: 14.6889 - val_loss: 226.1082 - val_mae: 14.7493\n",
            "Epoch 9309/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 227.2643 - mae: 14.6880 - val_loss: 226.0798 - val_mae: 14.7484\n",
            "Epoch 9310/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 227.2366 - mae: 14.6871 - val_loss: 226.0515 - val_mae: 14.7474\n",
            "Epoch 9311/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 227.2090 - mae: 14.6861 - val_loss: 226.0231 - val_mae: 14.7465\n",
            "Epoch 9312/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 227.1813 - mae: 14.6852 - val_loss: 225.9948 - val_mae: 14.7455\n",
            "Epoch 9313/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 227.1536 - mae: 14.6843 - val_loss: 225.9665 - val_mae: 14.7445\n",
            "Epoch 9314/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 227.1259 - mae: 14.6833 - val_loss: 225.9381 - val_mae: 14.7436\n",
            "Epoch 9315/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 227.0982 - mae: 14.6824 - val_loss: 225.9098 - val_mae: 14.7426\n",
            "Epoch 9316/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 227.0705 - mae: 14.6814 - val_loss: 225.8814 - val_mae: 14.7417\n",
            "Epoch 9317/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 227.0428 - mae: 14.6805 - val_loss: 225.8531 - val_mae: 14.7407\n",
            "Epoch 9318/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 227.0152 - mae: 14.6796 - val_loss: 225.8248 - val_mae: 14.7397\n",
            "Epoch 9319/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 226.9875 - mae: 14.6786 - val_loss: 225.7965 - val_mae: 14.7388\n",
            "Epoch 9320/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 226.9598 - mae: 14.6777 - val_loss: 225.7681 - val_mae: 14.7378\n",
            "Epoch 9321/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 226.9322 - mae: 14.6767 - val_loss: 225.7398 - val_mae: 14.7369\n",
            "Epoch 9322/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 226.9045 - mae: 14.6758 - val_loss: 225.7115 - val_mae: 14.7359\n",
            "Epoch 9323/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 226.8768 - mae: 14.6749 - val_loss: 225.6832 - val_mae: 14.7349\n",
            "Epoch 9324/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 226.8491 - mae: 14.6739 - val_loss: 225.6548 - val_mae: 14.7340\n",
            "Epoch 9325/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 226.8215 - mae: 14.6730 - val_loss: 225.6265 - val_mae: 14.7330\n",
            "Epoch 9326/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 226.7938 - mae: 14.6721 - val_loss: 225.5982 - val_mae: 14.7321\n",
            "Epoch 9327/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 226.7662 - mae: 14.6711 - val_loss: 225.5699 - val_mae: 14.7311\n",
            "Epoch 9328/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 226.7385 - mae: 14.6702 - val_loss: 225.5416 - val_mae: 14.7302\n",
            "Epoch 9329/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 226.7109 - mae: 14.6692 - val_loss: 225.5133 - val_mae: 14.7292\n",
            "Epoch 9330/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 226.6832 - mae: 14.6683 - val_loss: 225.4850 - val_mae: 14.7282\n",
            "Epoch 9331/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 226.6556 - mae: 14.6674 - val_loss: 225.4567 - val_mae: 14.7273\n",
            "Epoch 9332/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 226.6279 - mae: 14.6664 - val_loss: 225.4284 - val_mae: 14.7263\n",
            "Epoch 9333/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 226.6002 - mae: 14.6655 - val_loss: 225.4001 - val_mae: 14.7254\n",
            "Epoch 9334/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 226.5726 - mae: 14.6645 - val_loss: 225.3717 - val_mae: 14.7244\n",
            "Epoch 9335/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 226.5450 - mae: 14.6636 - val_loss: 225.3435 - val_mae: 14.7234\n",
            "Epoch 9336/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 226.5173 - mae: 14.6627 - val_loss: 225.3152 - val_mae: 14.7225\n",
            "Epoch 9337/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 226.4897 - mae: 14.6617 - val_loss: 225.2869 - val_mae: 14.7215\n",
            "Epoch 9338/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 226.4620 - mae: 14.6608 - val_loss: 225.2586 - val_mae: 14.7206\n",
            "Epoch 9339/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 226.4344 - mae: 14.6599 - val_loss: 225.2303 - val_mae: 14.7196\n",
            "Epoch 9340/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 226.4067 - mae: 14.6589 - val_loss: 225.2020 - val_mae: 14.7186\n",
            "Epoch 9341/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 226.3791 - mae: 14.6580 - val_loss: 225.1737 - val_mae: 14.7177\n",
            "Epoch 9342/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 226.3515 - mae: 14.6570 - val_loss: 225.1455 - val_mae: 14.7167\n",
            "Epoch 9343/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 226.3239 - mae: 14.6561 - val_loss: 225.1171 - val_mae: 14.7158\n",
            "Epoch 9344/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 226.2963 - mae: 14.6552 - val_loss: 225.0889 - val_mae: 14.7148\n",
            "Epoch 9345/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 226.2686 - mae: 14.6542 - val_loss: 225.0606 - val_mae: 14.7138\n",
            "Epoch 9346/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 226.2410 - mae: 14.6533 - val_loss: 225.0323 - val_mae: 14.7129\n",
            "Epoch 9347/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 226.2133 - mae: 14.6523 - val_loss: 225.0041 - val_mae: 14.7119\n",
            "Epoch 9348/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 226.1858 - mae: 14.6514 - val_loss: 224.9758 - val_mae: 14.7110\n",
            "Epoch 9349/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 226.1581 - mae: 14.6505 - val_loss: 224.9475 - val_mae: 14.7100\n",
            "Epoch 9350/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 226.1305 - mae: 14.6495 - val_loss: 224.9192 - val_mae: 14.7091\n",
            "Epoch 9351/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 226.1029 - mae: 14.6486 - val_loss: 224.8910 - val_mae: 14.7081\n",
            "Epoch 9352/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 226.0753 - mae: 14.6477 - val_loss: 224.8627 - val_mae: 14.7071\n",
            "Epoch 9353/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 226.0477 - mae: 14.6467 - val_loss: 224.8345 - val_mae: 14.7062\n",
            "Epoch 9354/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 226.0201 - mae: 14.6458 - val_loss: 224.8062 - val_mae: 14.7052\n",
            "Epoch 9355/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 225.9925 - mae: 14.6448 - val_loss: 224.7779 - val_mae: 14.7043\n",
            "Epoch 9356/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 225.9649 - mae: 14.6439 - val_loss: 224.7497 - val_mae: 14.7033\n",
            "Epoch 9357/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 225.9372 - mae: 14.6430 - val_loss: 224.7214 - val_mae: 14.7023\n",
            "Epoch 9358/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 225.9096 - mae: 14.6420 - val_loss: 224.6932 - val_mae: 14.7014\n",
            "Epoch 9359/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 225.8820 - mae: 14.6411 - val_loss: 224.6649 - val_mae: 14.7004\n",
            "Epoch 9360/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 225.8545 - mae: 14.6401 - val_loss: 224.6367 - val_mae: 14.6995\n",
            "Epoch 9361/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 225.8268 - mae: 14.6392 - val_loss: 224.6084 - val_mae: 14.6985\n",
            "Epoch 9362/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 225.7993 - mae: 14.6383 - val_loss: 224.5802 - val_mae: 14.6975\n",
            "Epoch 9363/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 225.7716 - mae: 14.6373 - val_loss: 224.5520 - val_mae: 14.6966\n",
            "Epoch 9364/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 225.7441 - mae: 14.6364 - val_loss: 224.5237 - val_mae: 14.6956\n",
            "Epoch 9365/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 225.7165 - mae: 14.6355 - val_loss: 224.4955 - val_mae: 14.6947\n",
            "Epoch 9366/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 225.6889 - mae: 14.6345 - val_loss: 224.4672 - val_mae: 14.6937\n",
            "Epoch 9367/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 225.6613 - mae: 14.6336 - val_loss: 224.4390 - val_mae: 14.6927\n",
            "Epoch 9368/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 225.6337 - mae: 14.6326 - val_loss: 224.4108 - val_mae: 14.6918\n",
            "Epoch 9369/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 225.6061 - mae: 14.6317 - val_loss: 224.3826 - val_mae: 14.6908\n",
            "Epoch 9370/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 225.5785 - mae: 14.6308 - val_loss: 224.3543 - val_mae: 14.6899\n",
            "Epoch 9371/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 225.5510 - mae: 14.6298 - val_loss: 224.3261 - val_mae: 14.6889\n",
            "Epoch 9372/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 225.5234 - mae: 14.6289 - val_loss: 224.2979 - val_mae: 14.6880\n",
            "Epoch 9373/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 225.4958 - mae: 14.6279 - val_loss: 224.2697 - val_mae: 14.6870\n",
            "Epoch 9374/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 225.4683 - mae: 14.6270 - val_loss: 224.2415 - val_mae: 14.6860\n",
            "Epoch 9375/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 225.4407 - mae: 14.6261 - val_loss: 224.2132 - val_mae: 14.6851\n",
            "Epoch 9376/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 225.4131 - mae: 14.6251 - val_loss: 224.1850 - val_mae: 14.6841\n",
            "Epoch 9377/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 225.3855 - mae: 14.6242 - val_loss: 224.1568 - val_mae: 14.6832\n",
            "Epoch 9378/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 225.3580 - mae: 14.6233 - val_loss: 224.1286 - val_mae: 14.6822\n",
            "Epoch 9379/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 225.3304 - mae: 14.6223 - val_loss: 224.1004 - val_mae: 14.6812\n",
            "Epoch 9380/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 225.3029 - mae: 14.6214 - val_loss: 224.0722 - val_mae: 14.6803\n",
            "Epoch 9381/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 225.2753 - mae: 14.6204 - val_loss: 224.0440 - val_mae: 14.6793\n",
            "Epoch 9382/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 225.2477 - mae: 14.6195 - val_loss: 224.0158 - val_mae: 14.6784\n",
            "Epoch 9383/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 225.2202 - mae: 14.6186 - val_loss: 223.9875 - val_mae: 14.6774\n",
            "Epoch 9384/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 225.1926 - mae: 14.6176 - val_loss: 223.9594 - val_mae: 14.6764\n",
            "Epoch 9385/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 225.1651 - mae: 14.6167 - val_loss: 223.9312 - val_mae: 14.6755\n",
            "Epoch 9386/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 225.1376 - mae: 14.6158 - val_loss: 223.9030 - val_mae: 14.6745\n",
            "Epoch 9387/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 225.1100 - mae: 14.6148 - val_loss: 223.8748 - val_mae: 14.6736\n",
            "Epoch 9388/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 225.0824 - mae: 14.6139 - val_loss: 223.8466 - val_mae: 14.6726\n",
            "Epoch 9389/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 225.0549 - mae: 14.6129 - val_loss: 223.8184 - val_mae: 14.6717\n",
            "Epoch 9390/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 225.0273 - mae: 14.6120 - val_loss: 223.7902 - val_mae: 14.6707\n",
            "Epoch 9391/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 224.9998 - mae: 14.6111 - val_loss: 223.7620 - val_mae: 14.6697\n",
            "Epoch 9392/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 224.9723 - mae: 14.6101 - val_loss: 223.7338 - val_mae: 14.6688\n",
            "Epoch 9393/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 224.9447 - mae: 14.6092 - val_loss: 223.7057 - val_mae: 14.6678\n",
            "Epoch 9394/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 224.9172 - mae: 14.6082 - val_loss: 223.6775 - val_mae: 14.6669\n",
            "Epoch 9395/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 224.8897 - mae: 14.6073 - val_loss: 223.6493 - val_mae: 14.6659\n",
            "Epoch 9396/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 224.8621 - mae: 14.6064 - val_loss: 223.6211 - val_mae: 14.6649\n",
            "Epoch 9397/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 224.8346 - mae: 14.6054 - val_loss: 223.5930 - val_mae: 14.6640\n",
            "Epoch 9398/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 224.8071 - mae: 14.6045 - val_loss: 223.5648 - val_mae: 14.6630\n",
            "Epoch 9399/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 224.7796 - mae: 14.6036 - val_loss: 223.5366 - val_mae: 14.6621\n",
            "Epoch 9400/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 224.7520 - mae: 14.6026 - val_loss: 223.5085 - val_mae: 14.6611\n",
            "Epoch 9401/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 224.7245 - mae: 14.6017 - val_loss: 223.4803 - val_mae: 14.6602\n",
            "Epoch 9402/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 224.6969 - mae: 14.6007 - val_loss: 223.4521 - val_mae: 14.6592\n",
            "Epoch 9403/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 224.6694 - mae: 14.5998 - val_loss: 223.4240 - val_mae: 14.6582\n",
            "Epoch 9404/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 224.6419 - mae: 14.5989 - val_loss: 223.3958 - val_mae: 14.6573\n",
            "Epoch 9405/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 224.6144 - mae: 14.5979 - val_loss: 223.3676 - val_mae: 14.6563\n",
            "Epoch 9406/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 224.5869 - mae: 14.5970 - val_loss: 223.3395 - val_mae: 14.6554\n",
            "Epoch 9407/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 224.5594 - mae: 14.5960 - val_loss: 223.3114 - val_mae: 14.6544\n",
            "Epoch 9408/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 224.5319 - mae: 14.5951 - val_loss: 223.2832 - val_mae: 14.6534\n",
            "Epoch 9409/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 224.5044 - mae: 14.5942 - val_loss: 223.2550 - val_mae: 14.6525\n",
            "Epoch 9410/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 224.4769 - mae: 14.5932 - val_loss: 223.2269 - val_mae: 14.6515\n",
            "Epoch 9411/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 224.4494 - mae: 14.5923 - val_loss: 223.1988 - val_mae: 14.6506\n",
            "Epoch 9412/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 224.4219 - mae: 14.5914 - val_loss: 223.1706 - val_mae: 14.6496\n",
            "Epoch 9413/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 224.3944 - mae: 14.5904 - val_loss: 223.1425 - val_mae: 14.6486\n",
            "Epoch 9414/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 224.3668 - mae: 14.5895 - val_loss: 223.1143 - val_mae: 14.6477\n",
            "Epoch 9415/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 224.3394 - mae: 14.5885 - val_loss: 223.0862 - val_mae: 14.6467\n",
            "Epoch 9416/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 224.3119 - mae: 14.5876 - val_loss: 223.0581 - val_mae: 14.6458\n",
            "Epoch 9417/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 224.2844 - mae: 14.5867 - val_loss: 223.0299 - val_mae: 14.6448\n",
            "Epoch 9418/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 224.2569 - mae: 14.5857 - val_loss: 223.0018 - val_mae: 14.6439\n",
            "Epoch 9419/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 224.2294 - mae: 14.5848 - val_loss: 222.9737 - val_mae: 14.6429\n",
            "Epoch 9420/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 224.2019 - mae: 14.5838 - val_loss: 222.9456 - val_mae: 14.6419\n",
            "Epoch 9421/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 224.1744 - mae: 14.5829 - val_loss: 222.9174 - val_mae: 14.6410\n",
            "Epoch 9422/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 224.1469 - mae: 14.5820 - val_loss: 222.8893 - val_mae: 14.6400\n",
            "Epoch 9423/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 224.1194 - mae: 14.5810 - val_loss: 222.8612 - val_mae: 14.6391\n",
            "Epoch 9424/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 224.0919 - mae: 14.5801 - val_loss: 222.8331 - val_mae: 14.6381\n",
            "Epoch 9425/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 224.0645 - mae: 14.5792 - val_loss: 222.8049 - val_mae: 14.6371\n",
            "Epoch 9426/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 224.0370 - mae: 14.5782 - val_loss: 222.7768 - val_mae: 14.6362\n",
            "Epoch 9427/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 224.0095 - mae: 14.5773 - val_loss: 222.7487 - val_mae: 14.6352\n",
            "Epoch 9428/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 223.9820 - mae: 14.5763 - val_loss: 222.7206 - val_mae: 14.6343\n",
            "Epoch 9429/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 223.9546 - mae: 14.5754 - val_loss: 222.6925 - val_mae: 14.6333\n",
            "Epoch 9430/10000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 223.9271 - mae: 14.5745 - val_loss: 222.6644 - val_mae: 14.6324\n",
            "Epoch 9431/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 223.8996 - mae: 14.5735 - val_loss: 222.6363 - val_mae: 14.6314\n",
            "Epoch 9432/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 223.8722 - mae: 14.5726 - val_loss: 222.6082 - val_mae: 14.6304\n",
            "Epoch 9433/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 223.8447 - mae: 14.5716 - val_loss: 222.5801 - val_mae: 14.6295\n",
            "Epoch 9434/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 223.8173 - mae: 14.5707 - val_loss: 222.5520 - val_mae: 14.6285\n",
            "Epoch 9435/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 223.7898 - mae: 14.5698 - val_loss: 222.5239 - val_mae: 14.6276\n",
            "Epoch 9436/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 223.7623 - mae: 14.5688 - val_loss: 222.4958 - val_mae: 14.6266\n",
            "Epoch 9437/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 223.7349 - mae: 14.5679 - val_loss: 222.4677 - val_mae: 14.6256\n",
            "Epoch 9438/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 223.7074 - mae: 14.5670 - val_loss: 222.4396 - val_mae: 14.6247\n",
            "Epoch 9439/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 223.6800 - mae: 14.5660 - val_loss: 222.4115 - val_mae: 14.6237\n",
            "Epoch 9440/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 223.6525 - mae: 14.5651 - val_loss: 222.3834 - val_mae: 14.6228\n",
            "Epoch 9441/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 223.6251 - mae: 14.5641 - val_loss: 222.3553 - val_mae: 14.6218\n",
            "Epoch 9442/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 223.5976 - mae: 14.5632 - val_loss: 222.3272 - val_mae: 14.6209\n",
            "Epoch 9443/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 223.5702 - mae: 14.5623 - val_loss: 222.2992 - val_mae: 14.6199\n",
            "Epoch 9444/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 223.5428 - mae: 14.5613 - val_loss: 222.2711 - val_mae: 14.6189\n",
            "Epoch 9445/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 223.5153 - mae: 14.5604 - val_loss: 222.2430 - val_mae: 14.6180\n",
            "Epoch 9446/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 223.4878 - mae: 14.5594 - val_loss: 222.2149 - val_mae: 14.6170\n",
            "Epoch 9447/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 223.4604 - mae: 14.5585 - val_loss: 222.1869 - val_mae: 14.6161\n",
            "Epoch 9448/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 223.4330 - mae: 14.5576 - val_loss: 222.1588 - val_mae: 14.6151\n",
            "Epoch 9449/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 223.4055 - mae: 14.5566 - val_loss: 222.1307 - val_mae: 14.6141\n",
            "Epoch 9450/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 223.3781 - mae: 14.5557 - val_loss: 222.1027 - val_mae: 14.6132\n",
            "Epoch 9451/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 223.3507 - mae: 14.5548 - val_loss: 222.0746 - val_mae: 14.6122\n",
            "Epoch 9452/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 223.3232 - mae: 14.5538 - val_loss: 222.0465 - val_mae: 14.6113\n",
            "Epoch 9453/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 223.2958 - mae: 14.5529 - val_loss: 222.0185 - val_mae: 14.6103\n",
            "Epoch 9454/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 223.2684 - mae: 14.5519 - val_loss: 221.9904 - val_mae: 14.6094\n",
            "Epoch 9455/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 223.2410 - mae: 14.5510 - val_loss: 221.9624 - val_mae: 14.6084\n",
            "Epoch 9456/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 223.2135 - mae: 14.5501 - val_loss: 221.9343 - val_mae: 14.6074\n",
            "Epoch 9457/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 223.1861 - mae: 14.5491 - val_loss: 221.9062 - val_mae: 14.6065\n",
            "Epoch 9458/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 223.1587 - mae: 14.5482 - val_loss: 221.8782 - val_mae: 14.6055\n",
            "Epoch 9459/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 223.1313 - mae: 14.5472 - val_loss: 221.8501 - val_mae: 14.6046\n",
            "Epoch 9460/10000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 223.1039 - mae: 14.5463 - val_loss: 221.8221 - val_mae: 14.6036\n",
            "Epoch 9461/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 223.0765 - mae: 14.5454 - val_loss: 221.7940 - val_mae: 14.6026\n",
            "Epoch 9462/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 223.0490 - mae: 14.5444 - val_loss: 221.7660 - val_mae: 14.6017\n",
            "Epoch 9463/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 223.0216 - mae: 14.5435 - val_loss: 221.7380 - val_mae: 14.6007\n",
            "Epoch 9464/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 222.9942 - mae: 14.5426 - val_loss: 221.7099 - val_mae: 14.5998\n",
            "Epoch 9465/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 222.9668 - mae: 14.5416 - val_loss: 221.6819 - val_mae: 14.5988\n",
            "Epoch 9466/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 222.9394 - mae: 14.5407 - val_loss: 221.6539 - val_mae: 14.5979\n",
            "Epoch 9467/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 222.9120 - mae: 14.5397 - val_loss: 221.6258 - val_mae: 14.5969\n",
            "Epoch 9468/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 222.8846 - mae: 14.5388 - val_loss: 221.5978 - val_mae: 14.5959\n",
            "Epoch 9469/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 222.8572 - mae: 14.5379 - val_loss: 221.5698 - val_mae: 14.5950\n",
            "Epoch 9470/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 222.8298 - mae: 14.5369 - val_loss: 221.5417 - val_mae: 14.5940\n",
            "Epoch 9471/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 222.8024 - mae: 14.5360 - val_loss: 221.5137 - val_mae: 14.5931\n",
            "Epoch 9472/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 222.7750 - mae: 14.5350 - val_loss: 221.4857 - val_mae: 14.5921\n",
            "Epoch 9473/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 222.7476 - mae: 14.5341 - val_loss: 221.4577 - val_mae: 14.5911\n",
            "Epoch 9474/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 222.7202 - mae: 14.5332 - val_loss: 221.4296 - val_mae: 14.5902\n",
            "Epoch 9475/10000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 222.6928 - mae: 14.5322 - val_loss: 221.4016 - val_mae: 14.5892\n",
            "Epoch 9476/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 222.6655 - mae: 14.5313 - val_loss: 221.3736 - val_mae: 14.5883\n",
            "Epoch 9477/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 222.6381 - mae: 14.5304 - val_loss: 221.3456 - val_mae: 14.5873\n",
            "Epoch 9478/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 222.6107 - mae: 14.5294 - val_loss: 221.3176 - val_mae: 14.5864\n",
            "Epoch 9479/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 222.5833 - mae: 14.5285 - val_loss: 221.2896 - val_mae: 14.5854\n",
            "Epoch 9480/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 222.5560 - mae: 14.5275 - val_loss: 221.2616 - val_mae: 14.5844\n",
            "Epoch 9481/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 222.5286 - mae: 14.5266 - val_loss: 221.2336 - val_mae: 14.5835\n",
            "Epoch 9482/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 222.5012 - mae: 14.5257 - val_loss: 221.2056 - val_mae: 14.5825\n",
            "Epoch 9483/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 222.4738 - mae: 14.5247 - val_loss: 221.1776 - val_mae: 14.5816\n",
            "Epoch 9484/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 222.4465 - mae: 14.5238 - val_loss: 221.1496 - val_mae: 14.5806\n",
            "Epoch 9485/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 222.4191 - mae: 14.5228 - val_loss: 221.1216 - val_mae: 14.5796\n",
            "Epoch 9486/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 222.3917 - mae: 14.5219 - val_loss: 221.0936 - val_mae: 14.5787\n",
            "Epoch 9487/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 222.3643 - mae: 14.5210 - val_loss: 221.0656 - val_mae: 14.5777\n",
            "Epoch 9488/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 222.3370 - mae: 14.5200 - val_loss: 221.0376 - val_mae: 14.5768\n",
            "Epoch 9489/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 222.3096 - mae: 14.5191 - val_loss: 221.0096 - val_mae: 14.5758\n",
            "Epoch 9490/10000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 222.2823 - mae: 14.5182 - val_loss: 220.9816 - val_mae: 14.5749\n",
            "Epoch 9491/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 222.2549 - mae: 14.5172 - val_loss: 220.9537 - val_mae: 14.5739\n",
            "Epoch 9492/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 222.2275 - mae: 14.5163 - val_loss: 220.9257 - val_mae: 14.5729\n",
            "Epoch 9493/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 222.2002 - mae: 14.5153 - val_loss: 220.8977 - val_mae: 14.5720\n",
            "Epoch 9494/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 222.1728 - mae: 14.5144 - val_loss: 220.8697 - val_mae: 14.5710\n",
            "Epoch 9495/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 222.1455 - mae: 14.5135 - val_loss: 220.8417 - val_mae: 14.5701\n",
            "Epoch 9496/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 222.1181 - mae: 14.5125 - val_loss: 220.8138 - val_mae: 14.5691\n",
            "Epoch 9497/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 222.0908 - mae: 14.5116 - val_loss: 220.7858 - val_mae: 14.5681\n",
            "Epoch 9498/10000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 222.0635 - mae: 14.5106 - val_loss: 220.7578 - val_mae: 14.5672\n",
            "Epoch 9499/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 222.0361 - mae: 14.5097 - val_loss: 220.7298 - val_mae: 14.5662\n",
            "Epoch 9500/10000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 222.0088 - mae: 14.5088 - val_loss: 220.7019 - val_mae: 14.5653\n",
            "Epoch 9501/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 221.9814 - mae: 14.5078 - val_loss: 220.6739 - val_mae: 14.5643\n",
            "Epoch 9502/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 221.9541 - mae: 14.5069 - val_loss: 220.6460 - val_mae: 14.5634\n",
            "Epoch 9503/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 221.9267 - mae: 14.5060 - val_loss: 220.6180 - val_mae: 14.5624\n",
            "Epoch 9504/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 221.8994 - mae: 14.5050 - val_loss: 220.5900 - val_mae: 14.5614\n",
            "Epoch 9505/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 221.8721 - mae: 14.5041 - val_loss: 220.5621 - val_mae: 14.5605\n",
            "Epoch 9506/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 221.8447 - mae: 14.5031 - val_loss: 220.5341 - val_mae: 14.5595\n",
            "Epoch 9507/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 221.8174 - mae: 14.5022 - val_loss: 220.5061 - val_mae: 14.5586\n",
            "Epoch 9508/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 221.7901 - mae: 14.5013 - val_loss: 220.4782 - val_mae: 14.5576\n",
            "Epoch 9509/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 221.7628 - mae: 14.5003 - val_loss: 220.4502 - val_mae: 14.5566\n",
            "Epoch 9510/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 221.7355 - mae: 14.4994 - val_loss: 220.4223 - val_mae: 14.5557\n",
            "Epoch 9511/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 221.7082 - mae: 14.4985 - val_loss: 220.3944 - val_mae: 14.5547\n",
            "Epoch 9512/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 221.6809 - mae: 14.4975 - val_loss: 220.3665 - val_mae: 14.5538\n",
            "Epoch 9513/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 221.6536 - mae: 14.4966 - val_loss: 220.3386 - val_mae: 14.5528\n",
            "Epoch 9514/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 221.6263 - mae: 14.4956 - val_loss: 220.3107 - val_mae: 14.5519\n",
            "Epoch 9515/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 221.5990 - mae: 14.4947 - val_loss: 220.2828 - val_mae: 14.5509\n",
            "Epoch 9516/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 221.5717 - mae: 14.4938 - val_loss: 220.2549 - val_mae: 14.5499\n",
            "Epoch 9517/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 221.5444 - mae: 14.4928 - val_loss: 220.2270 - val_mae: 14.5490\n",
            "Epoch 9518/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 221.5172 - mae: 14.4919 - val_loss: 220.1991 - val_mae: 14.5480\n",
            "Epoch 9519/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 221.4899 - mae: 14.4909 - val_loss: 220.1712 - val_mae: 14.5471\n",
            "Epoch 9520/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 221.4626 - mae: 14.4900 - val_loss: 220.1433 - val_mae: 14.5461\n",
            "Epoch 9521/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 221.4353 - mae: 14.4891 - val_loss: 220.1154 - val_mae: 14.5452\n",
            "Epoch 9522/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 221.4081 - mae: 14.4881 - val_loss: 220.0874 - val_mae: 14.5442\n",
            "Epoch 9523/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 221.3808 - mae: 14.4872 - val_loss: 220.0596 - val_mae: 14.5432\n",
            "Epoch 9524/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 221.3535 - mae: 14.4863 - val_loss: 220.0317 - val_mae: 14.5423\n",
            "Epoch 9525/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 221.3262 - mae: 14.4853 - val_loss: 220.0038 - val_mae: 14.5413\n",
            "Epoch 9526/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 221.2990 - mae: 14.4844 - val_loss: 219.9759 - val_mae: 14.5404\n",
            "Epoch 9527/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 221.2717 - mae: 14.4835 - val_loss: 219.9480 - val_mae: 14.5394\n",
            "Epoch 9528/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 221.2444 - mae: 14.4825 - val_loss: 219.9201 - val_mae: 14.5385\n",
            "Epoch 9529/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 221.2172 - mae: 14.4816 - val_loss: 219.8923 - val_mae: 14.5375\n",
            "Epoch 9530/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 221.1899 - mae: 14.4806 - val_loss: 219.8644 - val_mae: 14.5366\n",
            "Epoch 9531/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 221.1627 - mae: 14.4797 - val_loss: 219.8365 - val_mae: 14.5356\n",
            "Epoch 9532/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 221.1354 - mae: 14.4788 - val_loss: 219.8086 - val_mae: 14.5346\n",
            "Epoch 9533/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 221.1082 - mae: 14.4778 - val_loss: 219.7808 - val_mae: 14.5337\n",
            "Epoch 9534/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 221.0809 - mae: 14.4769 - val_loss: 219.7529 - val_mae: 14.5327\n",
            "Epoch 9535/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 221.0536 - mae: 14.4760 - val_loss: 219.7250 - val_mae: 14.5318\n",
            "Epoch 9536/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 221.0264 - mae: 14.4750 - val_loss: 219.6971 - val_mae: 14.5308\n",
            "Epoch 9537/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 220.9991 - mae: 14.4741 - val_loss: 219.6693 - val_mae: 14.5299\n",
            "Epoch 9538/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 220.9719 - mae: 14.4731 - val_loss: 219.6414 - val_mae: 14.5289\n",
            "Epoch 9539/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 220.9447 - mae: 14.4722 - val_loss: 219.6136 - val_mae: 14.5279\n",
            "Epoch 9540/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 220.9174 - mae: 14.4713 - val_loss: 219.5857 - val_mae: 14.5270\n",
            "Epoch 9541/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 220.8902 - mae: 14.4703 - val_loss: 219.5579 - val_mae: 14.5260\n",
            "Epoch 9542/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 220.8630 - mae: 14.4694 - val_loss: 219.5300 - val_mae: 14.5251\n",
            "Epoch 9543/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 220.8357 - mae: 14.4685 - val_loss: 219.5022 - val_mae: 14.5241\n",
            "Epoch 9544/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 220.8085 - mae: 14.4675 - val_loss: 219.4743 - val_mae: 14.5232\n",
            "Epoch 9545/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 220.7812 - mae: 14.4666 - val_loss: 219.4464 - val_mae: 14.5222\n",
            "Epoch 9546/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 220.7540 - mae: 14.4656 - val_loss: 219.4186 - val_mae: 14.5212\n",
            "Epoch 9547/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 220.7268 - mae: 14.4647 - val_loss: 219.3907 - val_mae: 14.5203\n",
            "Epoch 9548/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 220.6996 - mae: 14.4638 - val_loss: 219.3629 - val_mae: 14.5193\n",
            "Epoch 9549/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 220.6723 - mae: 14.4628 - val_loss: 219.3351 - val_mae: 14.5184\n",
            "Epoch 9550/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 220.6451 - mae: 14.4619 - val_loss: 219.3072 - val_mae: 14.5174\n",
            "Epoch 9551/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 220.6179 - mae: 14.4609 - val_loss: 219.2794 - val_mae: 14.5165\n",
            "Epoch 9552/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 220.5907 - mae: 14.4600 - val_loss: 219.2516 - val_mae: 14.5155\n",
            "Epoch 9553/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 220.5635 - mae: 14.4591 - val_loss: 219.2237 - val_mae: 14.5145\n",
            "Epoch 9554/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 220.5362 - mae: 14.4581 - val_loss: 219.1959 - val_mae: 14.5136\n",
            "Epoch 9555/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 220.5090 - mae: 14.4572 - val_loss: 219.1681 - val_mae: 14.5126\n",
            "Epoch 9556/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 220.4818 - mae: 14.4563 - val_loss: 219.1402 - val_mae: 14.5117\n",
            "Epoch 9557/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 220.4546 - mae: 14.4553 - val_loss: 219.1124 - val_mae: 14.5107\n",
            "Epoch 9558/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 220.4274 - mae: 14.4544 - val_loss: 219.0846 - val_mae: 14.5098\n",
            "Epoch 9559/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 220.4002 - mae: 14.4535 - val_loss: 219.0568 - val_mae: 14.5088\n",
            "Epoch 9560/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 220.3730 - mae: 14.4525 - val_loss: 219.0290 - val_mae: 14.5078\n",
            "Epoch 9561/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 220.3458 - mae: 14.4516 - val_loss: 219.0011 - val_mae: 14.5069\n",
            "Epoch 9562/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 220.3186 - mae: 14.4506 - val_loss: 218.9733 - val_mae: 14.5059\n",
            "Epoch 9563/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 220.2914 - mae: 14.4497 - val_loss: 218.9455 - val_mae: 14.5050\n",
            "Epoch 9564/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 220.2642 - mae: 14.4488 - val_loss: 218.9177 - val_mae: 14.5040\n",
            "Epoch 9565/10000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 220.2370 - mae: 14.4478 - val_loss: 218.8899 - val_mae: 14.5031\n",
            "Epoch 9566/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 220.2098 - mae: 14.4469 - val_loss: 218.8621 - val_mae: 14.5021\n",
            "Epoch 9567/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 220.1826 - mae: 14.4460 - val_loss: 218.8343 - val_mae: 14.5011\n",
            "Epoch 9568/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 220.1554 - mae: 14.4450 - val_loss: 218.8065 - val_mae: 14.5002\n",
            "Epoch 9569/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 220.1283 - mae: 14.4441 - val_loss: 218.7787 - val_mae: 14.4992\n",
            "Epoch 9570/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 220.1010 - mae: 14.4431 - val_loss: 218.7509 - val_mae: 14.4983\n",
            "Epoch 9571/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 220.0739 - mae: 14.4422 - val_loss: 218.7231 - val_mae: 14.4973\n",
            "Epoch 9572/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 220.0467 - mae: 14.4413 - val_loss: 218.6953 - val_mae: 14.4964\n",
            "Epoch 9573/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 220.0195 - mae: 14.4403 - val_loss: 218.6675 - val_mae: 14.4954\n",
            "Epoch 9574/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 219.9923 - mae: 14.4394 - val_loss: 218.6397 - val_mae: 14.4944\n",
            "Epoch 9575/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 219.9651 - mae: 14.4385 - val_loss: 218.6119 - val_mae: 14.4935\n",
            "Epoch 9576/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 219.9380 - mae: 14.4375 - val_loss: 218.5841 - val_mae: 14.4925\n",
            "Epoch 9577/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 219.9108 - mae: 14.4366 - val_loss: 218.5563 - val_mae: 14.4916\n",
            "Epoch 9578/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 219.8836 - mae: 14.4356 - val_loss: 218.5286 - val_mae: 14.4906\n",
            "Epoch 9579/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 219.8564 - mae: 14.4347 - val_loss: 218.5008 - val_mae: 14.4897\n",
            "Epoch 9580/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 219.8293 - mae: 14.4338 - val_loss: 218.4730 - val_mae: 14.4887\n",
            "Epoch 9581/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 219.8021 - mae: 14.4328 - val_loss: 218.4452 - val_mae: 14.4878\n",
            "Epoch 9582/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 219.7750 - mae: 14.4319 - val_loss: 218.4174 - val_mae: 14.4868\n",
            "Epoch 9583/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 219.7478 - mae: 14.4310 - val_loss: 218.3896 - val_mae: 14.4858\n",
            "Epoch 9584/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 219.7206 - mae: 14.4300 - val_loss: 218.3619 - val_mae: 14.4849\n",
            "Epoch 9585/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 219.6935 - mae: 14.4291 - val_loss: 218.3341 - val_mae: 14.4839\n",
            "Epoch 9586/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 219.6663 - mae: 14.4281 - val_loss: 218.3064 - val_mae: 14.4830\n",
            "Epoch 9587/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 219.6391 - mae: 14.4272 - val_loss: 218.2786 - val_mae: 14.4820\n",
            "Epoch 9588/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 219.6120 - mae: 14.4263 - val_loss: 218.2508 - val_mae: 14.4811\n",
            "Epoch 9589/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 219.5849 - mae: 14.4253 - val_loss: 218.2231 - val_mae: 14.4801\n",
            "Epoch 9590/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 219.5577 - mae: 14.4244 - val_loss: 218.1953 - val_mae: 14.4791\n",
            "Epoch 9591/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 219.5306 - mae: 14.4235 - val_loss: 218.1675 - val_mae: 14.4782\n",
            "Epoch 9592/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 219.5034 - mae: 14.4225 - val_loss: 218.1398 - val_mae: 14.4772\n",
            "Epoch 9593/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 219.4763 - mae: 14.4216 - val_loss: 218.1120 - val_mae: 14.4763\n",
            "Epoch 9594/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 219.4491 - mae: 14.4206 - val_loss: 218.0843 - val_mae: 14.4753\n",
            "Epoch 9595/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 219.4220 - mae: 14.4197 - val_loss: 218.0565 - val_mae: 14.4744\n",
            "Epoch 9596/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 219.3949 - mae: 14.4188 - val_loss: 218.0288 - val_mae: 14.4734\n",
            "Epoch 9597/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 219.3677 - mae: 14.4178 - val_loss: 218.0011 - val_mae: 14.4724\n",
            "Epoch 9598/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 219.3406 - mae: 14.4169 - val_loss: 217.9733 - val_mae: 14.4715\n",
            "Epoch 9599/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 219.3135 - mae: 14.4160 - val_loss: 217.9456 - val_mae: 14.4705\n",
            "Epoch 9600/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 219.2863 - mae: 14.4150 - val_loss: 217.9178 - val_mae: 14.4696\n",
            "Epoch 9601/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 219.2592 - mae: 14.4141 - val_loss: 217.8901 - val_mae: 14.4686\n",
            "Epoch 9602/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 219.2320 - mae: 14.4131 - val_loss: 217.8623 - val_mae: 14.4677\n",
            "Epoch 9603/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 219.2049 - mae: 14.4122 - val_loss: 217.8346 - val_mae: 14.4667\n",
            "Epoch 9604/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 219.1778 - mae: 14.4113 - val_loss: 217.8069 - val_mae: 14.4657\n",
            "Epoch 9605/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 219.1507 - mae: 14.4103 - val_loss: 217.7791 - val_mae: 14.4648\n",
            "Epoch 9606/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 219.1236 - mae: 14.4094 - val_loss: 217.7514 - val_mae: 14.4638\n",
            "Epoch 9607/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 219.0964 - mae: 14.4085 - val_loss: 217.7237 - val_mae: 14.4629\n",
            "Epoch 9608/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 219.0693 - mae: 14.4075 - val_loss: 217.6960 - val_mae: 14.4619\n",
            "Epoch 9609/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 219.0422 - mae: 14.4066 - val_loss: 217.6683 - val_mae: 14.4610\n",
            "Epoch 9610/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 219.0151 - mae: 14.4056 - val_loss: 217.6405 - val_mae: 14.4600\n",
            "Epoch 9611/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 218.9880 - mae: 14.4047 - val_loss: 217.6128 - val_mae: 14.4591\n",
            "Epoch 9612/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 218.9609 - mae: 14.4038 - val_loss: 217.5851 - val_mae: 14.4581\n",
            "Epoch 9613/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 218.9338 - mae: 14.4028 - val_loss: 217.5574 - val_mae: 14.4571\n",
            "Epoch 9614/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 218.9067 - mae: 14.4019 - val_loss: 217.5297 - val_mae: 14.4562\n",
            "Epoch 9615/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 218.8796 - mae: 14.4010 - val_loss: 217.5020 - val_mae: 14.4552\n",
            "Epoch 9616/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 218.8525 - mae: 14.4000 - val_loss: 217.4743 - val_mae: 14.4543\n",
            "Epoch 9617/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 218.8253 - mae: 14.3991 - val_loss: 217.4466 - val_mae: 14.4533\n",
            "Epoch 9618/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 218.7983 - mae: 14.3981 - val_loss: 217.4189 - val_mae: 14.4524\n",
            "Epoch 9619/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 218.7712 - mae: 14.3972 - val_loss: 217.3912 - val_mae: 14.4514\n",
            "Epoch 9620/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 218.7440 - mae: 14.3963 - val_loss: 217.3634 - val_mae: 14.4504\n",
            "Epoch 9621/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 218.7170 - mae: 14.3953 - val_loss: 217.3358 - val_mae: 14.4495\n",
            "Epoch 9622/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 218.6899 - mae: 14.3944 - val_loss: 217.3081 - val_mae: 14.4485\n",
            "Epoch 9623/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 218.6628 - mae: 14.3935 - val_loss: 217.2804 - val_mae: 14.4476\n",
            "Epoch 9624/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 218.6357 - mae: 14.3925 - val_loss: 217.2527 - val_mae: 14.4466\n",
            "Epoch 9625/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 218.6086 - mae: 14.3916 - val_loss: 217.2250 - val_mae: 14.4457\n",
            "Epoch 9626/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 218.5816 - mae: 14.3906 - val_loss: 217.1973 - val_mae: 14.4447\n",
            "Epoch 9627/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 218.5544 - mae: 14.3897 - val_loss: 217.1696 - val_mae: 14.4438\n",
            "Epoch 9628/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 218.5274 - mae: 14.3888 - val_loss: 217.1419 - val_mae: 14.4428\n",
            "Epoch 9629/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 218.5003 - mae: 14.3878 - val_loss: 217.1143 - val_mae: 14.4418\n",
            "Epoch 9630/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 218.4733 - mae: 14.3869 - val_loss: 217.0866 - val_mae: 14.4409\n",
            "Epoch 9631/10000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 218.4462 - mae: 14.3860 - val_loss: 217.0589 - val_mae: 14.4399\n",
            "Epoch 9632/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 218.4191 - mae: 14.3850 - val_loss: 217.0312 - val_mae: 14.4390\n",
            "Epoch 9633/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 218.3920 - mae: 14.3841 - val_loss: 217.0036 - val_mae: 14.4380\n",
            "Epoch 9634/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 218.3649 - mae: 14.3831 - val_loss: 216.9759 - val_mae: 14.4371\n",
            "Epoch 9635/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 218.3379 - mae: 14.3822 - val_loss: 216.9482 - val_mae: 14.4361\n",
            "Epoch 9636/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 218.3108 - mae: 14.3813 - val_loss: 216.9206 - val_mae: 14.4351\n",
            "Epoch 9637/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 218.2838 - mae: 14.3803 - val_loss: 216.8929 - val_mae: 14.4342\n",
            "Epoch 9638/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 218.2567 - mae: 14.3794 - val_loss: 216.8652 - val_mae: 14.4332\n",
            "Epoch 9639/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 218.2296 - mae: 14.3785 - val_loss: 216.8376 - val_mae: 14.4323\n",
            "Epoch 9640/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 218.2025 - mae: 14.3775 - val_loss: 216.8099 - val_mae: 14.4313\n",
            "Epoch 9641/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 218.1755 - mae: 14.3766 - val_loss: 216.7823 - val_mae: 14.4304\n",
            "Epoch 9642/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 218.1485 - mae: 14.3756 - val_loss: 216.7546 - val_mae: 14.4294\n",
            "Epoch 9643/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 218.1214 - mae: 14.3747 - val_loss: 216.7270 - val_mae: 14.4284\n",
            "Epoch 9644/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 218.0944 - mae: 14.3738 - val_loss: 216.6993 - val_mae: 14.4275\n",
            "Epoch 9645/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 218.0673 - mae: 14.3728 - val_loss: 216.6716 - val_mae: 14.4265\n",
            "Epoch 9646/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 218.0403 - mae: 14.3719 - val_loss: 216.6440 - val_mae: 14.4256\n",
            "Epoch 9647/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 218.0132 - mae: 14.3710 - val_loss: 216.6163 - val_mae: 14.4246\n",
            "Epoch 9648/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 217.9862 - mae: 14.3700 - val_loss: 216.5887 - val_mae: 14.4237\n",
            "Epoch 9649/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 217.9591 - mae: 14.3691 - val_loss: 216.5610 - val_mae: 14.4227\n",
            "Epoch 9650/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 217.9321 - mae: 14.3681 - val_loss: 216.5334 - val_mae: 14.4218\n",
            "Epoch 9651/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 217.9050 - mae: 14.3672 - val_loss: 216.5058 - val_mae: 14.4208\n",
            "Epoch 9652/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 217.8780 - mae: 14.3663 - val_loss: 216.4781 - val_mae: 14.4198\n",
            "Epoch 9653/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 217.8510 - mae: 14.3653 - val_loss: 216.4505 - val_mae: 14.4189\n",
            "Epoch 9654/10000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 217.8239 - mae: 14.3644 - val_loss: 216.4229 - val_mae: 14.4179\n",
            "Epoch 9655/10000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 217.7969 - mae: 14.3635 - val_loss: 216.3953 - val_mae: 14.4170\n",
            "Epoch 9656/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 217.7699 - mae: 14.3625 - val_loss: 216.3676 - val_mae: 14.4160\n",
            "Epoch 9657/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 217.7428 - mae: 14.3616 - val_loss: 216.3400 - val_mae: 14.4151\n",
            "Epoch 9658/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 217.7158 - mae: 14.3606 - val_loss: 216.3124 - val_mae: 14.4141\n",
            "Epoch 9659/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 217.6888 - mae: 14.3597 - val_loss: 216.2848 - val_mae: 14.4131\n",
            "Epoch 9660/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 217.6618 - mae: 14.3588 - val_loss: 216.2571 - val_mae: 14.4122\n",
            "Epoch 9661/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 217.6348 - mae: 14.3578 - val_loss: 216.2295 - val_mae: 14.4112\n",
            "Epoch 9662/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 217.6078 - mae: 14.3569 - val_loss: 216.2019 - val_mae: 14.4103\n",
            "Epoch 9663/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 217.5807 - mae: 14.3560 - val_loss: 216.1743 - val_mae: 14.4093\n",
            "Epoch 9664/10000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 217.5537 - mae: 14.3550 - val_loss: 216.1467 - val_mae: 14.4084\n",
            "Epoch 9665/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 217.5267 - mae: 14.3541 - val_loss: 216.1191 - val_mae: 14.4074\n",
            "Epoch 9666/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 217.4997 - mae: 14.3531 - val_loss: 216.0915 - val_mae: 14.4065\n",
            "Epoch 9667/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 217.4727 - mae: 14.3522 - val_loss: 216.0639 - val_mae: 14.4055\n",
            "Epoch 9668/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 217.4457 - mae: 14.3513 - val_loss: 216.0363 - val_mae: 14.4045\n",
            "Epoch 9669/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 217.4187 - mae: 14.3503 - val_loss: 216.0086 - val_mae: 14.4036\n",
            "Epoch 9670/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 217.3917 - mae: 14.3494 - val_loss: 215.9810 - val_mae: 14.4026\n",
            "Epoch 9671/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 217.3647 - mae: 14.3485 - val_loss: 215.9535 - val_mae: 14.4017\n",
            "Epoch 9672/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 217.3377 - mae: 14.3475 - val_loss: 215.9259 - val_mae: 14.4007\n",
            "Epoch 9673/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 217.3107 - mae: 14.3466 - val_loss: 215.8983 - val_mae: 14.3998\n",
            "Epoch 9674/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 217.2837 - mae: 14.3456 - val_loss: 215.8707 - val_mae: 14.3988\n",
            "Epoch 9675/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 217.2567 - mae: 14.3447 - val_loss: 215.8431 - val_mae: 14.3978\n",
            "Epoch 9676/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 217.2297 - mae: 14.3438 - val_loss: 215.8155 - val_mae: 14.3969\n",
            "Epoch 9677/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 217.2027 - mae: 14.3428 - val_loss: 215.7879 - val_mae: 14.3959\n",
            "Epoch 9678/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 217.1757 - mae: 14.3419 - val_loss: 215.7603 - val_mae: 14.3950\n",
            "Epoch 9679/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 217.1487 - mae: 14.3410 - val_loss: 215.7328 - val_mae: 14.3940\n",
            "Epoch 9680/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 217.1217 - mae: 14.3400 - val_loss: 215.7052 - val_mae: 14.3931\n",
            "Epoch 9681/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 217.0947 - mae: 14.3391 - val_loss: 215.6776 - val_mae: 14.3921\n",
            "Epoch 9682/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 217.0678 - mae: 14.3381 - val_loss: 215.6500 - val_mae: 14.3912\n",
            "Epoch 9683/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 217.0408 - mae: 14.3372 - val_loss: 215.6225 - val_mae: 14.3902\n",
            "Epoch 9684/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 217.0138 - mae: 14.3363 - val_loss: 215.5949 - val_mae: 14.3892\n",
            "Epoch 9685/10000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 216.9868 - mae: 14.3353 - val_loss: 215.5673 - val_mae: 14.3883\n",
            "Epoch 9686/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 216.9599 - mae: 14.3344 - val_loss: 215.5397 - val_mae: 14.3873\n",
            "Epoch 9687/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 216.9329 - mae: 14.3335 - val_loss: 215.5122 - val_mae: 14.3864\n",
            "Epoch 9688/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 216.9059 - mae: 14.3325 - val_loss: 215.4846 - val_mae: 14.3854\n",
            "Epoch 9689/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 216.8789 - mae: 14.3316 - val_loss: 215.4571 - val_mae: 14.3845\n",
            "Epoch 9690/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 216.8520 - mae: 14.3306 - val_loss: 215.4295 - val_mae: 14.3835\n",
            "Epoch 9691/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 216.8250 - mae: 14.3297 - val_loss: 215.4019 - val_mae: 14.3826\n",
            "Epoch 9692/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 216.7980 - mae: 14.3288 - val_loss: 215.3744 - val_mae: 14.3816\n",
            "Epoch 9693/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 216.7711 - mae: 14.3278 - val_loss: 215.3468 - val_mae: 14.3806\n",
            "Epoch 9694/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 216.7442 - mae: 14.3269 - val_loss: 215.3193 - val_mae: 14.3797\n",
            "Epoch 9695/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 216.7171 - mae: 14.3260 - val_loss: 215.2917 - val_mae: 14.3787\n",
            "Epoch 9696/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 216.6902 - mae: 14.3250 - val_loss: 215.2642 - val_mae: 14.3778\n",
            "Epoch 9697/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 216.6633 - mae: 14.3241 - val_loss: 215.2366 - val_mae: 14.3768\n",
            "Epoch 9698/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 216.6363 - mae: 14.3231 - val_loss: 215.2091 - val_mae: 14.3759\n",
            "Epoch 9699/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 216.6093 - mae: 14.3222 - val_loss: 215.1815 - val_mae: 14.3749\n",
            "Epoch 9700/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 216.5824 - mae: 14.3213 - val_loss: 215.1540 - val_mae: 14.3739\n",
            "Epoch 9701/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 216.5555 - mae: 14.3203 - val_loss: 215.1265 - val_mae: 14.3730\n",
            "Epoch 9702/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 216.5285 - mae: 14.3194 - val_loss: 215.0989 - val_mae: 14.3720\n",
            "Epoch 9703/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 216.5016 - mae: 14.3185 - val_loss: 215.0714 - val_mae: 14.3711\n",
            "Epoch 9704/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 216.4746 - mae: 14.3175 - val_loss: 215.0439 - val_mae: 14.3701\n",
            "Epoch 9705/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 216.4477 - mae: 14.3166 - val_loss: 215.0163 - val_mae: 14.3692\n",
            "Epoch 9706/10000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 216.4208 - mae: 14.3156 - val_loss: 214.9888 - val_mae: 14.3682\n",
            "Epoch 9707/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 216.3938 - mae: 14.3147 - val_loss: 214.9613 - val_mae: 14.3673\n",
            "Epoch 9708/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 216.3669 - mae: 14.3138 - val_loss: 214.9337 - val_mae: 14.3663\n",
            "Epoch 9709/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 216.3400 - mae: 14.3128 - val_loss: 214.9062 - val_mae: 14.3653\n",
            "Epoch 9710/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 216.3130 - mae: 14.3119 - val_loss: 214.8787 - val_mae: 14.3644\n",
            "Epoch 9711/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 216.2861 - mae: 14.3110 - val_loss: 214.8512 - val_mae: 14.3634\n",
            "Epoch 9712/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 216.2592 - mae: 14.3100 - val_loss: 214.8237 - val_mae: 14.3625\n",
            "Epoch 9713/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 216.2322 - mae: 14.3091 - val_loss: 214.7962 - val_mae: 14.3615\n",
            "Epoch 9714/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 216.2053 - mae: 14.3081 - val_loss: 214.7687 - val_mae: 14.3606\n",
            "Epoch 9715/10000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 216.1784 - mae: 14.3072 - val_loss: 214.7412 - val_mae: 14.3596\n",
            "Epoch 9716/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 216.1515 - mae: 14.3063 - val_loss: 214.7137 - val_mae: 14.3587\n",
            "Epoch 9717/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 216.1246 - mae: 14.3053 - val_loss: 214.6862 - val_mae: 14.3577\n",
            "Epoch 9718/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 216.0977 - mae: 14.3044 - val_loss: 214.6586 - val_mae: 14.3567\n",
            "Epoch 9719/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 216.0707 - mae: 14.3035 - val_loss: 214.6311 - val_mae: 14.3558\n",
            "Epoch 9720/10000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 216.0438 - mae: 14.3025 - val_loss: 214.6037 - val_mae: 14.3548\n",
            "Epoch 9721/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 216.0169 - mae: 14.3016 - val_loss: 214.5761 - val_mae: 14.3539\n",
            "Epoch 9722/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 215.9900 - mae: 14.3006 - val_loss: 214.5487 - val_mae: 14.3529\n",
            "Epoch 9723/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 215.9631 - mae: 14.2997 - val_loss: 214.5212 - val_mae: 14.3520\n",
            "Epoch 9724/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 215.9362 - mae: 14.2988 - val_loss: 214.4937 - val_mae: 14.3510\n",
            "Epoch 9725/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 215.9093 - mae: 14.2978 - val_loss: 214.4662 - val_mae: 14.3500\n",
            "Epoch 9726/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 215.8824 - mae: 14.2969 - val_loss: 214.4387 - val_mae: 14.3491\n",
            "Epoch 9727/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 215.8555 - mae: 14.2960 - val_loss: 214.4112 - val_mae: 14.3481\n",
            "Epoch 9728/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 215.8286 - mae: 14.2950 - val_loss: 214.3837 - val_mae: 14.3472\n",
            "Epoch 9729/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 215.8017 - mae: 14.2941 - val_loss: 214.3562 - val_mae: 14.3462\n",
            "Epoch 9730/10000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 215.7748 - mae: 14.2931 - val_loss: 214.3288 - val_mae: 14.3453\n",
            "Epoch 9731/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 215.7479 - mae: 14.2922 - val_loss: 214.3013 - val_mae: 14.3443\n",
            "Epoch 9732/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 215.7210 - mae: 14.2913 - val_loss: 214.2738 - val_mae: 14.3434\n",
            "Epoch 9733/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 215.6941 - mae: 14.2903 - val_loss: 214.2463 - val_mae: 14.3424\n",
            "Epoch 9734/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 215.6673 - mae: 14.2894 - val_loss: 214.2189 - val_mae: 14.3414\n",
            "Epoch 9735/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 215.6404 - mae: 14.2885 - val_loss: 214.1914 - val_mae: 14.3405\n",
            "Epoch 9736/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 215.6134 - mae: 14.2875 - val_loss: 214.1639 - val_mae: 14.3395\n",
            "Epoch 9737/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 215.5866 - mae: 14.2866 - val_loss: 214.1365 - val_mae: 14.3386\n",
            "Epoch 9738/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 215.5597 - mae: 14.2856 - val_loss: 214.1090 - val_mae: 14.3376\n",
            "Epoch 9739/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 215.5328 - mae: 14.2847 - val_loss: 214.0815 - val_mae: 14.3367\n",
            "Epoch 9740/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 215.5060 - mae: 14.2838 - val_loss: 214.0541 - val_mae: 14.3357\n",
            "Epoch 9741/10000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 215.4791 - mae: 14.2828 - val_loss: 214.0266 - val_mae: 14.3348\n",
            "Epoch 9742/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 215.4522 - mae: 14.2819 - val_loss: 213.9992 - val_mae: 14.3338\n",
            "Epoch 9743/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 215.4253 - mae: 14.2810 - val_loss: 213.9717 - val_mae: 14.3328\n",
            "Epoch 9744/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 215.3985 - mae: 14.2800 - val_loss: 213.9442 - val_mae: 14.3319\n",
            "Epoch 9745/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 215.3716 - mae: 14.2791 - val_loss: 213.9168 - val_mae: 14.3309\n",
            "Epoch 9746/10000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 215.3448 - mae: 14.2781 - val_loss: 213.8894 - val_mae: 14.3300\n",
            "Epoch 9747/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 215.3179 - mae: 14.2772 - val_loss: 213.8619 - val_mae: 14.3290\n",
            "Epoch 9748/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 215.2910 - mae: 14.2763 - val_loss: 213.8345 - val_mae: 14.3281\n",
            "Epoch 9749/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 215.2641 - mae: 14.2753 - val_loss: 213.8070 - val_mae: 14.3271\n",
            "Epoch 9750/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 215.2373 - mae: 14.2744 - val_loss: 213.7796 - val_mae: 14.3262\n",
            "Epoch 9751/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 215.2104 - mae: 14.2735 - val_loss: 213.7522 - val_mae: 14.3252\n",
            "Epoch 9752/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 215.1836 - mae: 14.2725 - val_loss: 213.7247 - val_mae: 14.3242\n",
            "Epoch 9753/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 215.1567 - mae: 14.2716 - val_loss: 213.6973 - val_mae: 14.3233\n",
            "Epoch 9754/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 215.1299 - mae: 14.2706 - val_loss: 213.6699 - val_mae: 14.3223\n",
            "Epoch 9755/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 215.1031 - mae: 14.2697 - val_loss: 213.6424 - val_mae: 14.3214\n",
            "Epoch 9756/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 215.0762 - mae: 14.2688 - val_loss: 213.6150 - val_mae: 14.3204\n",
            "Epoch 9757/10000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 215.0494 - mae: 14.2678 - val_loss: 213.5876 - val_mae: 14.3195\n",
            "Epoch 9758/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 215.0225 - mae: 14.2669 - val_loss: 213.5602 - val_mae: 14.3185\n",
            "Epoch 9759/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 214.9957 - mae: 14.2660 - val_loss: 213.5327 - val_mae: 14.3176\n",
            "Epoch 9760/10000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 214.9688 - mae: 14.2650 - val_loss: 213.5053 - val_mae: 14.3166\n",
            "Epoch 9761/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 214.9420 - mae: 14.2641 - val_loss: 213.4779 - val_mae: 14.3156\n",
            "Epoch 9762/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 214.9152 - mae: 14.2631 - val_loss: 213.4505 - val_mae: 14.3147\n",
            "Epoch 9763/10000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 214.8883 - mae: 14.2622 - val_loss: 213.4231 - val_mae: 14.3137\n",
            "Epoch 9764/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 214.8615 - mae: 14.2613 - val_loss: 213.3957 - val_mae: 14.3128\n",
            "Epoch 9765/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 214.8347 - mae: 14.2603 - val_loss: 213.3683 - val_mae: 14.3118\n",
            "Epoch 9766/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 214.8079 - mae: 14.2594 - val_loss: 213.3409 - val_mae: 14.3109\n",
            "Epoch 9767/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 214.7811 - mae: 14.2585 - val_loss: 213.3135 - val_mae: 14.3099\n",
            "Epoch 9768/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 214.7543 - mae: 14.2575 - val_loss: 213.2862 - val_mae: 14.3090\n",
            "Epoch 9769/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 214.7275 - mae: 14.2566 - val_loss: 213.2588 - val_mae: 14.3080\n",
            "Epoch 9770/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 214.7007 - mae: 14.2557 - val_loss: 213.2314 - val_mae: 14.3070\n",
            "Epoch 9771/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 214.6739 - mae: 14.2547 - val_loss: 213.2040 - val_mae: 14.3061\n",
            "Epoch 9772/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 214.6471 - mae: 14.2538 - val_loss: 213.1767 - val_mae: 14.3051\n",
            "Epoch 9773/10000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 214.6203 - mae: 14.2528 - val_loss: 213.1493 - val_mae: 14.3042\n",
            "Epoch 9774/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 214.5935 - mae: 14.2519 - val_loss: 213.1219 - val_mae: 14.3032\n",
            "Epoch 9775/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 214.5668 - mae: 14.2510 - val_loss: 213.0946 - val_mae: 14.3023\n",
            "Epoch 9776/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 214.5400 - mae: 14.2500 - val_loss: 213.0672 - val_mae: 14.3013\n",
            "Epoch 9777/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 214.5132 - mae: 14.2491 - val_loss: 213.0398 - val_mae: 14.3004\n",
            "Epoch 9778/10000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 214.4864 - mae: 14.2482 - val_loss: 213.0125 - val_mae: 14.2994\n",
            "Epoch 9779/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 214.4596 - mae: 14.2472 - val_loss: 212.9852 - val_mae: 14.2985\n",
            "Epoch 9780/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 214.4329 - mae: 14.2463 - val_loss: 212.9578 - val_mae: 14.2975\n",
            "Epoch 9781/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 214.4061 - mae: 14.2454 - val_loss: 212.9305 - val_mae: 14.2965\n",
            "Epoch 9782/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 214.3793 - mae: 14.2444 - val_loss: 212.9031 - val_mae: 14.2956\n",
            "Epoch 9783/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 214.3525 - mae: 14.2435 - val_loss: 212.8757 - val_mae: 14.2946\n",
            "Epoch 9784/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 214.3257 - mae: 14.2425 - val_loss: 212.8484 - val_mae: 14.2937\n",
            "Epoch 9785/10000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 214.2990 - mae: 14.2416 - val_loss: 212.8210 - val_mae: 14.2927\n",
            "Epoch 9786/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 214.2722 - mae: 14.2407 - val_loss: 212.7937 - val_mae: 14.2918\n",
            "Epoch 9787/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 214.2455 - mae: 14.2397 - val_loss: 212.7664 - val_mae: 14.2908\n",
            "Epoch 9788/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 214.2187 - mae: 14.2388 - val_loss: 212.7391 - val_mae: 14.2899\n",
            "Epoch 9789/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 214.1919 - mae: 14.2379 - val_loss: 212.7117 - val_mae: 14.2889\n",
            "Epoch 9790/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 214.1652 - mae: 14.2369 - val_loss: 212.6844 - val_mae: 14.2880\n",
            "Epoch 9791/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 214.1384 - mae: 14.2360 - val_loss: 212.6571 - val_mae: 14.2870\n",
            "Epoch 9792/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 214.1117 - mae: 14.2350 - val_loss: 212.6297 - val_mae: 14.2860\n",
            "Epoch 9793/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 214.0849 - mae: 14.2341 - val_loss: 212.6024 - val_mae: 14.2851\n",
            "Epoch 9794/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 214.0582 - mae: 14.2332 - val_loss: 212.5751 - val_mae: 14.2841\n",
            "Epoch 9795/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 214.0314 - mae: 14.2322 - val_loss: 212.5478 - val_mae: 14.2832\n",
            "Epoch 9796/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 214.0047 - mae: 14.2313 - val_loss: 212.5204 - val_mae: 14.2822\n",
            "Epoch 9797/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 213.9780 - mae: 14.2304 - val_loss: 212.4931 - val_mae: 14.2813\n",
            "Epoch 9798/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 213.9512 - mae: 14.2294 - val_loss: 212.4658 - val_mae: 14.2803\n",
            "Epoch 9799/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 213.9245 - mae: 14.2285 - val_loss: 212.4385 - val_mae: 14.2794\n",
            "Epoch 9800/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 213.8977 - mae: 14.2276 - val_loss: 212.4112 - val_mae: 14.2784\n",
            "Epoch 9801/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 213.8710 - mae: 14.2266 - val_loss: 212.3839 - val_mae: 14.2775\n",
            "Epoch 9802/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 213.8442 - mae: 14.2257 - val_loss: 212.3566 - val_mae: 14.2765\n",
            "Epoch 9803/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 213.8175 - mae: 14.2247 - val_loss: 212.3293 - val_mae: 14.2755\n",
            "Epoch 9804/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 213.7908 - mae: 14.2238 - val_loss: 212.3020 - val_mae: 14.2746\n",
            "Epoch 9805/10000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 213.7641 - mae: 14.2229 - val_loss: 212.2747 - val_mae: 14.2736\n",
            "Epoch 9806/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 213.7373 - mae: 14.2219 - val_loss: 212.2473 - val_mae: 14.2727\n",
            "Epoch 9807/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 213.7106 - mae: 14.2210 - val_loss: 212.2200 - val_mae: 14.2717\n",
            "Epoch 9808/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 213.6839 - mae: 14.2201 - val_loss: 212.1927 - val_mae: 14.2708\n",
            "Epoch 9809/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 213.6572 - mae: 14.2191 - val_loss: 212.1655 - val_mae: 14.2698\n",
            "Epoch 9810/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 213.6304 - mae: 14.2182 - val_loss: 212.1382 - val_mae: 14.2689\n",
            "Epoch 9811/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 213.6037 - mae: 14.2173 - val_loss: 212.1109 - val_mae: 14.2679\n",
            "Epoch 9812/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 213.5770 - mae: 14.2163 - val_loss: 212.0836 - val_mae: 14.2670\n",
            "Epoch 9813/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 213.5503 - mae: 14.2154 - val_loss: 212.0563 - val_mae: 14.2660\n",
            "Epoch 9814/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 213.5236 - mae: 14.2144 - val_loss: 212.0290 - val_mae: 14.2650\n",
            "Epoch 9815/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 213.4969 - mae: 14.2135 - val_loss: 212.0017 - val_mae: 14.2641\n",
            "Epoch 9816/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 213.4701 - mae: 14.2126 - val_loss: 211.9744 - val_mae: 14.2631\n",
            "Epoch 9817/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 213.4434 - mae: 14.2116 - val_loss: 211.9472 - val_mae: 14.2622\n",
            "Epoch 9818/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 213.4167 - mae: 14.2107 - val_loss: 211.9199 - val_mae: 14.2612\n",
            "Epoch 9819/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 213.3900 - mae: 14.2098 - val_loss: 211.8926 - val_mae: 14.2603\n",
            "Epoch 9820/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 213.3633 - mae: 14.2088 - val_loss: 211.8654 - val_mae: 14.2593\n",
            "Epoch 9821/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 213.3366 - mae: 14.2079 - val_loss: 211.8381 - val_mae: 14.2584\n",
            "Epoch 9822/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 213.3099 - mae: 14.2070 - val_loss: 211.8108 - val_mae: 14.2574\n",
            "Epoch 9823/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 213.2832 - mae: 14.2060 - val_loss: 211.7835 - val_mae: 14.2565\n",
            "Epoch 9824/10000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 213.2565 - mae: 14.2051 - val_loss: 211.7563 - val_mae: 14.2555\n",
            "Epoch 9825/10000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 213.2298 - mae: 14.2041 - val_loss: 211.7290 - val_mae: 14.2545\n",
            "Epoch 9826/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 213.2031 - mae: 14.2032 - val_loss: 211.7018 - val_mae: 14.2536\n",
            "Epoch 9827/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 213.1764 - mae: 14.2023 - val_loss: 211.6745 - val_mae: 14.2526\n",
            "Epoch 9828/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 213.1498 - mae: 14.2013 - val_loss: 211.6472 - val_mae: 14.2517\n",
            "Epoch 9829/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 213.1231 - mae: 14.2004 - val_loss: 211.6200 - val_mae: 14.2507\n",
            "Epoch 9830/10000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 213.0964 - mae: 14.1995 - val_loss: 211.5927 - val_mae: 14.2498\n",
            "Epoch 9831/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 213.0697 - mae: 14.1985 - val_loss: 211.5655 - val_mae: 14.2488\n",
            "Epoch 9832/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 213.0430 - mae: 14.1976 - val_loss: 211.5382 - val_mae: 14.2479\n",
            "Epoch 9833/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 213.0163 - mae: 14.1966 - val_loss: 211.5110 - val_mae: 14.2469\n",
            "Epoch 9834/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 212.9897 - mae: 14.1957 - val_loss: 211.4837 - val_mae: 14.2460\n",
            "Epoch 9835/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 212.9630 - mae: 14.1948 - val_loss: 211.4565 - val_mae: 14.2450\n",
            "Epoch 9836/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 212.9363 - mae: 14.1938 - val_loss: 211.4292 - val_mae: 14.2441\n",
            "Epoch 9837/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 212.9096 - mae: 14.1929 - val_loss: 211.4020 - val_mae: 14.2431\n",
            "Epoch 9838/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 212.8830 - mae: 14.1920 - val_loss: 211.3748 - val_mae: 14.2421\n",
            "Epoch 9839/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 212.8563 - mae: 14.1910 - val_loss: 211.3476 - val_mae: 14.2412\n",
            "Epoch 9840/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 212.8296 - mae: 14.1901 - val_loss: 211.3203 - val_mae: 14.2402\n",
            "Epoch 9841/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 212.8029 - mae: 14.1892 - val_loss: 211.2931 - val_mae: 14.2393\n",
            "Epoch 9842/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 212.7763 - mae: 14.1882 - val_loss: 211.2659 - val_mae: 14.2383\n",
            "Epoch 9843/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 212.7496 - mae: 14.1873 - val_loss: 211.2386 - val_mae: 14.2374\n",
            "Epoch 9844/10000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 212.7230 - mae: 14.1863 - val_loss: 211.2114 - val_mae: 14.2364\n",
            "Epoch 9845/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 212.6963 - mae: 14.1854 - val_loss: 211.1842 - val_mae: 14.2355\n",
            "Epoch 9846/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 212.6697 - mae: 14.1845 - val_loss: 211.1570 - val_mae: 14.2345\n",
            "Epoch 9847/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 212.6430 - mae: 14.1835 - val_loss: 211.1297 - val_mae: 14.2336\n",
            "Epoch 9848/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 212.6163 - mae: 14.1826 - val_loss: 211.1025 - val_mae: 14.2326\n",
            "Epoch 9849/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 212.5897 - mae: 14.1817 - val_loss: 211.0753 - val_mae: 14.2316\n",
            "Epoch 9850/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 212.5631 - mae: 14.1807 - val_loss: 211.0481 - val_mae: 14.2307\n",
            "Epoch 9851/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 212.5364 - mae: 14.1798 - val_loss: 211.0209 - val_mae: 14.2297\n",
            "Epoch 9852/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 212.5098 - mae: 14.1789 - val_loss: 210.9937 - val_mae: 14.2288\n",
            "Epoch 9853/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 212.4831 - mae: 14.1779 - val_loss: 210.9665 - val_mae: 14.2278\n",
            "Epoch 9854/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 212.4565 - mae: 14.1770 - val_loss: 210.9393 - val_mae: 14.2269\n",
            "Epoch 9855/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 212.4298 - mae: 14.1760 - val_loss: 210.9121 - val_mae: 14.2259\n",
            "Epoch 9856/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 212.4032 - mae: 14.1751 - val_loss: 210.8849 - val_mae: 14.2250\n",
            "Epoch 9857/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 212.3766 - mae: 14.1742 - val_loss: 210.8577 - val_mae: 14.2240\n",
            "Epoch 9858/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 212.3499 - mae: 14.1732 - val_loss: 210.8305 - val_mae: 14.2231\n",
            "Epoch 9859/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 212.3233 - mae: 14.1723 - val_loss: 210.8033 - val_mae: 14.2221\n",
            "Epoch 9860/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 212.2967 - mae: 14.1714 - val_loss: 210.7761 - val_mae: 14.2212\n",
            "Epoch 9861/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 212.2701 - mae: 14.1704 - val_loss: 210.7489 - val_mae: 14.2202\n",
            "Epoch 9862/10000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 212.2434 - mae: 14.1695 - val_loss: 210.7217 - val_mae: 14.2192\n",
            "Epoch 9863/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 212.2168 - mae: 14.1686 - val_loss: 210.6945 - val_mae: 14.2183\n",
            "Epoch 9864/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 212.1902 - mae: 14.1676 - val_loss: 210.6673 - val_mae: 14.2173\n",
            "Epoch 9865/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 212.1635 - mae: 14.1667 - val_loss: 210.6401 - val_mae: 14.2164\n",
            "Epoch 9866/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 212.1369 - mae: 14.1657 - val_loss: 210.6130 - val_mae: 14.2154\n",
            "Epoch 9867/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 212.1103 - mae: 14.1648 - val_loss: 210.5858 - val_mae: 14.2145\n",
            "Epoch 9868/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 212.0837 - mae: 14.1639 - val_loss: 210.5586 - val_mae: 14.2135\n",
            "Epoch 9869/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 212.0571 - mae: 14.1629 - val_loss: 210.5314 - val_mae: 14.2126\n",
            "Epoch 9870/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 212.0305 - mae: 14.1620 - val_loss: 210.5043 - val_mae: 14.2116\n",
            "Epoch 9871/10000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 212.0039 - mae: 14.1611 - val_loss: 210.4771 - val_mae: 14.2107\n",
            "Epoch 9872/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 211.9773 - mae: 14.1601 - val_loss: 210.4500 - val_mae: 14.2097\n",
            "Epoch 9873/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 211.9506 - mae: 14.1592 - val_loss: 210.4228 - val_mae: 14.2088\n",
            "Epoch 9874/10000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 211.9241 - mae: 14.1583 - val_loss: 210.3956 - val_mae: 14.2078\n",
            "Epoch 9875/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 211.8974 - mae: 14.1573 - val_loss: 210.3685 - val_mae: 14.2068\n",
            "Epoch 9876/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 211.8708 - mae: 14.1564 - val_loss: 210.3413 - val_mae: 14.2059\n",
            "Epoch 9877/10000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 211.8442 - mae: 14.1554 - val_loss: 210.3141 - val_mae: 14.2049\n",
            "Epoch 9878/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 211.8176 - mae: 14.1545 - val_loss: 210.2870 - val_mae: 14.2040\n",
            "Epoch 9879/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 211.7910 - mae: 14.1536 - val_loss: 210.2598 - val_mae: 14.2030\n",
            "Epoch 9880/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 211.7645 - mae: 14.1526 - val_loss: 210.2327 - val_mae: 14.2021\n",
            "Epoch 9881/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 211.7379 - mae: 14.1517 - val_loss: 210.2055 - val_mae: 14.2011\n",
            "Epoch 9882/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 211.7113 - mae: 14.1508 - val_loss: 210.1783 - val_mae: 14.2002\n",
            "Epoch 9883/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 211.6847 - mae: 14.1498 - val_loss: 210.1512 - val_mae: 14.1992\n",
            "Epoch 9884/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 211.6581 - mae: 14.1489 - val_loss: 210.1241 - val_mae: 14.1983\n",
            "Epoch 9885/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 211.6315 - mae: 14.1480 - val_loss: 210.0969 - val_mae: 14.1973\n",
            "Epoch 9886/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 211.6049 - mae: 14.1470 - val_loss: 210.0698 - val_mae: 14.1964\n",
            "Epoch 9887/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 211.5783 - mae: 14.1461 - val_loss: 210.0426 - val_mae: 14.1954\n",
            "Epoch 9888/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 211.5518 - mae: 14.1451 - val_loss: 210.0155 - val_mae: 14.1944\n",
            "Epoch 9889/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 211.5252 - mae: 14.1442 - val_loss: 209.9884 - val_mae: 14.1935\n",
            "Epoch 9890/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 211.4986 - mae: 14.1433 - val_loss: 209.9612 - val_mae: 14.1925\n",
            "Epoch 9891/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 211.4720 - mae: 14.1423 - val_loss: 209.9341 - val_mae: 14.1916\n",
            "Epoch 9892/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 211.4455 - mae: 14.1414 - val_loss: 209.9070 - val_mae: 14.1906\n",
            "Epoch 9893/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 211.4189 - mae: 14.1405 - val_loss: 209.8798 - val_mae: 14.1897\n",
            "Epoch 9894/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 211.3923 - mae: 14.1395 - val_loss: 209.8527 - val_mae: 14.1887\n",
            "Epoch 9895/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 211.3658 - mae: 14.1386 - val_loss: 209.8256 - val_mae: 14.1878\n",
            "Epoch 9896/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 211.3392 - mae: 14.1377 - val_loss: 209.7985 - val_mae: 14.1868\n",
            "Epoch 9897/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 211.3127 - mae: 14.1367 - val_loss: 209.7714 - val_mae: 14.1859\n",
            "Epoch 9898/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 211.2861 - mae: 14.1358 - val_loss: 209.7442 - val_mae: 14.1849\n",
            "Epoch 9899/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 211.2595 - mae: 14.1348 - val_loss: 209.7171 - val_mae: 14.1839\n",
            "Epoch 9900/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 211.2330 - mae: 14.1339 - val_loss: 209.6900 - val_mae: 14.1830\n",
            "Epoch 9901/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 211.2064 - mae: 14.1330 - val_loss: 209.6629 - val_mae: 14.1820\n",
            "Epoch 9902/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 211.1799 - mae: 14.1320 - val_loss: 209.6358 - val_mae: 14.1811\n",
            "Epoch 9903/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 211.1533 - mae: 14.1311 - val_loss: 209.6087 - val_mae: 14.1801\n",
            "Epoch 9904/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 211.1267 - mae: 14.1302 - val_loss: 209.5816 - val_mae: 14.1792\n",
            "Epoch 9905/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 211.1002 - mae: 14.1292 - val_loss: 209.5545 - val_mae: 14.1782\n",
            "Epoch 9906/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 211.0737 - mae: 14.1283 - val_loss: 209.5274 - val_mae: 14.1773\n",
            "Epoch 9907/10000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 211.0471 - mae: 14.1273 - val_loss: 209.5003 - val_mae: 14.1763\n",
            "Epoch 9908/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 211.0206 - mae: 14.1264 - val_loss: 209.4732 - val_mae: 14.1754\n",
            "Epoch 9909/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 210.9940 - mae: 14.1255 - val_loss: 209.4461 - val_mae: 14.1744\n",
            "Epoch 9910/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 210.9675 - mae: 14.1245 - val_loss: 209.4190 - val_mae: 14.1735\n",
            "Epoch 9911/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 210.9409 - mae: 14.1236 - val_loss: 209.3919 - val_mae: 14.1725\n",
            "Epoch 9912/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 210.9144 - mae: 14.1227 - val_loss: 209.3648 - val_mae: 14.1715\n",
            "Epoch 9913/10000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 210.8879 - mae: 14.1217 - val_loss: 209.3377 - val_mae: 14.1706\n",
            "Epoch 9914/10000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 210.8613 - mae: 14.1208 - val_loss: 209.3106 - val_mae: 14.1696\n",
            "Epoch 9915/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 210.8348 - mae: 14.1199 - val_loss: 209.2836 - val_mae: 14.1687\n",
            "Epoch 9916/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 210.8083 - mae: 14.1189 - val_loss: 209.2565 - val_mae: 14.1677\n",
            "Epoch 9917/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 210.7817 - mae: 14.1180 - val_loss: 209.2294 - val_mae: 14.1668\n",
            "Epoch 9918/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 210.7552 - mae: 14.1170 - val_loss: 209.2023 - val_mae: 14.1658\n",
            "Epoch 9919/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 210.7287 - mae: 14.1161 - val_loss: 209.1752 - val_mae: 14.1649\n",
            "Epoch 9920/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 210.7022 - mae: 14.1152 - val_loss: 209.1482 - val_mae: 14.1639\n",
            "Epoch 9921/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 210.6757 - mae: 14.1142 - val_loss: 209.1211 - val_mae: 14.1630\n",
            "Epoch 9922/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 210.6492 - mae: 14.1133 - val_loss: 209.0940 - val_mae: 14.1620\n",
            "Epoch 9923/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 210.6226 - mae: 14.1124 - val_loss: 209.0670 - val_mae: 14.1611\n",
            "Epoch 9924/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 210.5961 - mae: 14.1114 - val_loss: 209.0399 - val_mae: 14.1601\n",
            "Epoch 9925/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 210.5696 - mae: 14.1105 - val_loss: 209.0128 - val_mae: 14.1592\n",
            "Epoch 9926/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 210.5431 - mae: 14.1096 - val_loss: 208.9858 - val_mae: 14.1582\n",
            "Epoch 9927/10000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 210.5166 - mae: 14.1086 - val_loss: 208.9587 - val_mae: 14.1572\n",
            "Epoch 9928/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 210.4901 - mae: 14.1077 - val_loss: 208.9317 - val_mae: 14.1563\n",
            "Epoch 9929/10000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 210.4636 - mae: 14.1067 - val_loss: 208.9046 - val_mae: 14.1553\n",
            "Epoch 9930/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 210.4371 - mae: 14.1058 - val_loss: 208.8776 - val_mae: 14.1544\n",
            "Epoch 9931/10000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 210.4106 - mae: 14.1049 - val_loss: 208.8505 - val_mae: 14.1534\n",
            "Epoch 9932/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 210.3841 - mae: 14.1039 - val_loss: 208.8235 - val_mae: 14.1525\n",
            "Epoch 9933/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 210.3576 - mae: 14.1030 - val_loss: 208.7964 - val_mae: 14.1515\n",
            "Epoch 9934/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 210.3311 - mae: 14.1021 - val_loss: 208.7694 - val_mae: 14.1506\n",
            "Epoch 9935/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 210.3046 - mae: 14.1011 - val_loss: 208.7423 - val_mae: 14.1496\n",
            "Epoch 9936/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 210.2781 - mae: 14.1002 - val_loss: 208.7153 - val_mae: 14.1487\n",
            "Epoch 9937/10000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 210.2516 - mae: 14.0993 - val_loss: 208.6882 - val_mae: 14.1477\n",
            "Epoch 9938/10000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 210.2251 - mae: 14.0983 - val_loss: 208.6612 - val_mae: 14.1468\n",
            "Epoch 9939/10000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 210.1986 - mae: 14.0974 - val_loss: 208.6342 - val_mae: 14.1458\n",
            "Epoch 9940/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 210.1721 - mae: 14.0964 - val_loss: 208.6071 - val_mae: 14.1448\n",
            "Epoch 9941/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 210.1457 - mae: 14.0955 - val_loss: 208.5801 - val_mae: 14.1439\n",
            "Epoch 9942/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 210.1192 - mae: 14.0946 - val_loss: 208.5531 - val_mae: 14.1429\n",
            "Epoch 9943/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 210.0927 - mae: 14.0936 - val_loss: 208.5260 - val_mae: 14.1420\n",
            "Epoch 9944/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 210.0662 - mae: 14.0927 - val_loss: 208.4990 - val_mae: 14.1410\n",
            "Epoch 9945/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 210.0397 - mae: 14.0918 - val_loss: 208.4720 - val_mae: 14.1401\n",
            "Epoch 9946/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 210.0133 - mae: 14.0908 - val_loss: 208.4450 - val_mae: 14.1391\n",
            "Epoch 9947/10000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 209.9868 - mae: 14.0899 - val_loss: 208.4179 - val_mae: 14.1382\n",
            "Epoch 9948/10000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 209.9603 - mae: 14.0890 - val_loss: 208.3909 - val_mae: 14.1372\n",
            "Epoch 9949/10000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 209.9339 - mae: 14.0880 - val_loss: 208.3639 - val_mae: 14.1363\n",
            "Epoch 9950/10000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 209.9074 - mae: 14.0871 - val_loss: 208.3369 - val_mae: 14.1353\n",
            "Epoch 9951/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 209.8809 - mae: 14.0861 - val_loss: 208.3099 - val_mae: 14.1344\n",
            "Epoch 9952/10000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 209.8545 - mae: 14.0852 - val_loss: 208.2829 - val_mae: 14.1334\n",
            "Epoch 9953/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 209.8280 - mae: 14.0843 - val_loss: 208.2559 - val_mae: 14.1324\n",
            "Epoch 9954/10000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 209.8015 - mae: 14.0833 - val_loss: 208.2289 - val_mae: 14.1315\n",
            "Epoch 9955/10000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 209.7751 - mae: 14.0824 - val_loss: 208.2019 - val_mae: 14.1305\n",
            "Epoch 9956/10000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 209.7486 - mae: 14.0815 - val_loss: 208.1749 - val_mae: 14.1296\n",
            "Epoch 9957/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 209.7222 - mae: 14.0805 - val_loss: 208.1479 - val_mae: 14.1286\n",
            "Epoch 9958/10000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 209.6957 - mae: 14.0796 - val_loss: 208.1209 - val_mae: 14.1277\n",
            "Epoch 9959/10000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 209.6693 - mae: 14.0787 - val_loss: 208.0939 - val_mae: 14.1267\n",
            "Epoch 9960/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 209.6428 - mae: 14.0777 - val_loss: 208.0669 - val_mae: 14.1258\n",
            "Epoch 9961/10000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 209.6164 - mae: 14.0768 - val_loss: 208.0399 - val_mae: 14.1248\n",
            "Epoch 9962/10000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 209.5899 - mae: 14.0758 - val_loss: 208.0129 - val_mae: 14.1239\n",
            "Epoch 9963/10000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 209.5635 - mae: 14.0749 - val_loss: 207.9859 - val_mae: 14.1229\n",
            "Epoch 9964/10000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 209.5370 - mae: 14.0740 - val_loss: 207.9589 - val_mae: 14.1220\n",
            "Epoch 9965/10000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 209.5106 - mae: 14.0730 - val_loss: 207.9319 - val_mae: 14.1210\n",
            "Epoch 9966/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 209.4842 - mae: 14.0721 - val_loss: 207.9050 - val_mae: 14.1201\n",
            "Epoch 9967/10000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 209.4577 - mae: 14.0712 - val_loss: 207.8780 - val_mae: 14.1191\n",
            "Epoch 9968/10000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 209.4313 - mae: 14.0702 - val_loss: 207.8510 - val_mae: 14.1181\n",
            "Epoch 9969/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 209.4049 - mae: 14.0693 - val_loss: 207.8241 - val_mae: 14.1172\n",
            "Epoch 9970/10000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 209.3784 - mae: 14.0684 - val_loss: 207.7971 - val_mae: 14.1162\n",
            "Epoch 9971/10000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 209.3520 - mae: 14.0674 - val_loss: 207.7701 - val_mae: 14.1153\n",
            "Epoch 9972/10000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 209.3256 - mae: 14.0665 - val_loss: 207.7431 - val_mae: 14.1143\n",
            "Epoch 9973/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 209.2991 - mae: 14.0655 - val_loss: 207.7162 - val_mae: 14.1134\n",
            "Epoch 9974/10000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 209.2727 - mae: 14.0646 - val_loss: 207.6892 - val_mae: 14.1124\n",
            "Epoch 9975/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 209.2463 - mae: 14.0637 - val_loss: 207.6622 - val_mae: 14.1115\n",
            "Epoch 9976/10000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 209.2199 - mae: 14.0627 - val_loss: 207.6353 - val_mae: 14.1105\n",
            "Epoch 9977/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 209.1935 - mae: 14.0618 - val_loss: 207.6083 - val_mae: 14.1096\n",
            "Epoch 9978/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 209.1671 - mae: 14.0609 - val_loss: 207.5813 - val_mae: 14.1086\n",
            "Epoch 9979/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 209.1406 - mae: 14.0599 - val_loss: 207.5544 - val_mae: 14.1077\n",
            "Epoch 9980/10000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 209.1142 - mae: 14.0590 - val_loss: 207.5274 - val_mae: 14.1067\n",
            "Epoch 9981/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 209.0878 - mae: 14.0580 - val_loss: 207.5005 - val_mae: 14.1058\n",
            "Epoch 9982/10000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 209.0614 - mae: 14.0571 - val_loss: 207.4735 - val_mae: 14.1048\n",
            "Epoch 9983/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 209.0350 - mae: 14.0562 - val_loss: 207.4466 - val_mae: 14.1038\n",
            "Epoch 9984/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 209.0086 - mae: 14.0552 - val_loss: 207.4196 - val_mae: 14.1029\n",
            "Epoch 9985/10000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 208.9822 - mae: 14.0543 - val_loss: 207.3927 - val_mae: 14.1019\n",
            "Epoch 9986/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 208.9558 - mae: 14.0534 - val_loss: 207.3658 - val_mae: 14.1010\n",
            "Epoch 9987/10000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 208.9294 - mae: 14.0524 - val_loss: 207.3388 - val_mae: 14.1000\n",
            "Epoch 9988/10000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 208.9030 - mae: 14.0515 - val_loss: 207.3119 - val_mae: 14.0991\n",
            "Epoch 9989/10000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 208.8766 - mae: 14.0506 - val_loss: 207.2849 - val_mae: 14.0981\n",
            "Epoch 9990/10000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 208.8502 - mae: 14.0496 - val_loss: 207.2580 - val_mae: 14.0972\n",
            "Epoch 9991/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 208.8238 - mae: 14.0487 - val_loss: 207.2311 - val_mae: 14.0962\n",
            "Epoch 9992/10000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 208.7974 - mae: 14.0477 - val_loss: 207.2041 - val_mae: 14.0953\n",
            "Epoch 9993/10000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 208.7710 - mae: 14.0468 - val_loss: 207.1772 - val_mae: 14.0943\n",
            "Epoch 9994/10000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 208.7446 - mae: 14.0459 - val_loss: 207.1503 - val_mae: 14.0934\n",
            "Epoch 9995/10000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 208.7183 - mae: 14.0449 - val_loss: 207.1234 - val_mae: 14.0924\n",
            "Epoch 9996/10000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 208.6919 - mae: 14.0440 - val_loss: 207.0965 - val_mae: 14.0915\n",
            "Epoch 9997/10000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 208.6655 - mae: 14.0431 - val_loss: 207.0695 - val_mae: 14.0905\n",
            "Epoch 9998/10000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 208.6391 - mae: 14.0421 - val_loss: 207.0426 - val_mae: 14.0895\n",
            "Epoch 9999/10000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 208.6127 - mae: 14.0412 - val_loss: 207.0157 - val_mae: 14.0886\n",
            "Epoch 10000/10000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 208.5863 - mae: 14.0403 - val_loss: 206.9888 - val_mae: 14.0876\n",
            "1/1 - 0s - loss: 275235744.0000 - mae: 15951.0703 - 167ms/epoch - 167ms/step\n",
            "Mean Squared Error (MSE): 275235744.0\n"
          ]
        }
      ],
      "source": [
        "# 데이터 표준화\n",
        "# 데이터 split\n",
        "from  tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "train_input, test_input, train_target, test_target = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "ss = StandardScaler()\n",
        "train_scaled = ss.fit_transform(train_input)\n",
        "test_scaled = ss.transform(test_input)\n",
        "\n",
        "# Optimizer - Stochastic gradient descent - 확률적 경사 하강법\n",
        "# sgd = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "\n",
        "\n",
        "model = keras.Sequential() # 도화지 한장 만드는, 인공신경망을 만들기 위한...\n",
        "model.add(keras.layers.Dense(7, input_shape = (9,))) # input_shape은 입력층임, 한개의 입력층에서 하나의 출력층으로 간다는 뜻)\n",
        "\n",
        "# 총 컴퓨터가 학습해야 되는 파라미터는 10개!! 9개의 컬럼과 1개의 절편. model.summary() 코드로 확인가능!!!\n",
        "model.compile(loss= 'mse', optimizer = 'adam', metrics = 'mae') # adam은 학습률을 직접 자동으로 조절해준다!! # metrics = 'mae' 절대 오차를 보여준다.\n",
        "# 컴퓨터한테 mse 방법으로 계산해달라고 하고, 학습률을 자동으로 맞춰주게 amda을 사용하였고, 거기서 내가 보고 싶은 데이터인 절대오차를 보여달라고 metrics = 'mae'를 사용한거\n",
        "\n",
        "# MSE 평균제곱오차\n",
        "\n",
        "es = keras.callbacks.EarlyStopping(patience=5, restore_best_weights = True) # patience=5 : 컴퓨터가 참는 횟수(과대적합이 이어지는 수 현재는 5번연속 과대적합일때, 5번연속 모델이 좋아지지 않았을때, 주기!),\n",
        "# restore_best_weights = True, 과대적합이(모델이 5번연속 모델이 좋아지지 않앗을때) 5번 연속 일어났을때, 그것을 제외하고(이전의) 모델을 보여줘!라는 뜻\n",
        "\n",
        "hist = model.fit(train_scaled, train_target, epochs = 10000, validation_data = (test_scaled, test_target), callbacks=[es], batch_size = 3000) # epochs 학습 횟수!\n",
        "# validation_data = (test_scaled, test_target) # 쪽지시험, 훈련을 한번 할때마다 쪽지 시험, 훈련데이터는 떨어지는, 쪽지시험은 올라가는 과대적합을 확인 할 수 있음!!\n",
        "# val_loss인 쪽지시험의 결과를 확인 해야된다!!! - > 과대적합을 확인했을 경우 -> 얼리스탑핑 적용, 이렇게 하여, 최적의 모델을 확인 할 수 있음??!\n",
        "\n",
        "\n",
        "\n",
        "# 손실 함수 계산\n",
        "loss, mse = model.evaluate(train_input, train_target, batch_size=3000, verbose=2)\n",
        "print('Mean Squared Error (MSE):', loss)\n",
        "\n",
        "\n",
        "# MSE는 평균 제곱 오차를 나타냅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "6913d3ba",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6913d3ba",
        "outputId": "204a7f52-09af-43e2-c277-e6e199fd08b5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 7)                 70        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 70 (280.00 Byte)\n",
            "Trainable params: 70 (280.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "a9d95a10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9d95a10",
        "outputId": "bd69b343-e785-413a-8c1e-7086fba168ef"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 5ms/step - loss: 277888704.0000 - mae: 15985.1465\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[277888704.0, 15985.146484375]"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_input, test_target)\n",
        "\n",
        "# 1 번째 [17,370,756.0, 4,028.35888671875]\n",
        "# 2 번째 [17,784,066.0, 3556.08984375] 노드 수 증가(32), batch 수 증가 (50)\n",
        "# 3 번째 [488,604,064.0, 16541.791015625] , - layer추가 , 노드 수 증가(100), batch 수 증가\n",
        "# 4 번쨰 [19,545,324.0, 3,618.091796875] , 1층 , batch_size=100\n",
        "# 5 번째 [83,356,568.0, 8,674.251953125] , 1층 , SGD 사용 , activation = 'linear', batch_size=100\n",
        "# 6 번째 [20,712,244.0, 3,883.132,080,078,125], 1층, adam 사용, activation = 'linear', batch_size=100\n",
        "# 7 번째 [15,668,128.0, 3,406.31,298,828,125],  1층, adam사용, activation='없음', batch_size=100, epochs = 1000\n",
        "# 8 번째 [18,041,990.0, 3,678.059326171875], 1층 , adam사용, activation='없음', batch_size=500, epochs = 3000\n",
        "# 9 번째 [17,900,314.0, 3416.20849609375] , 1층, adam사용, activation='없음', batch_size=100, epochs = 1000, epochs = 1000, 노드 14개\n",
        "# 10 번째  , 1층 , adam사용, activation='없음', batch_size=100, epochs = 1000, 노드 1개\n",
        "# 11 번째, [29,574,182.0, 4,019.82080078125], 노드 1개\n",
        "# 12 번째, [16,696,080.0, 3,279.92333984375], 노드 64개\n",
        "# 13번째 , [14,905,614.0, 3,380.693359375], 노드 7개, adam사용, avtivation='없음' , 배치:100, 에폭:1000,\n",
        "# 14번째, [19,363,676.0, 3,983.610107421875], 노드 4개, adam사용, activation='없음', 배치:100, 에폭:1000\n",
        "# 15번째, [17,679,988.0, 3,634.688232421875], 노드 9개, adam사용, activation='없음', 배치:100, 에폭:1000\n",
        "# 16번쨰, [172,240,864.0, 12,587.046875] , 노드 7개, 2층 노드7개, adam사용, activation='없음', 배치:100, 에폭:1000\n",
        "# 17번째, [162,252,000.0, 12,270.5830078125], 1층 노드 7개, adam사용, activation='없음', 배치:1000, 에폭:5000\n",
        "# 18번째,   1층 노드 7개, adam사용, activation='없음', 배치:1000, 에폭:1000\n",
        "# 19번째, [9,435,014.0, 2,556.25390625], origin 전처리, 1층 노드 7개, adam사용, activation='없음', 배치:1000, 에폭:1000\n",
        "# 20번째, [277,888,704.0, 15,985.146484375], origin 전처리, 1층 노드 7개, adam사용, activation='없음', 배치:3000, 에폭:10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "b64bbaae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "b64bbaae",
        "outputId": "45c36611-bc29-49a0-bd95-78acc71db63c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iFVKRq8EPWxi"
      },
      "id": "iFVKRq8EPWxi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다른 방법으로 접근하고, 추가 내용 공부!"
      ],
      "metadata": {
        "id": "c75M4-NIPXpN"
      },
      "id": "c75M4-NIPXpN"
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ion8Vc6h__O2",
        "outputId": "a3112065-fd58-484c-ee4d-c0107d633c47"
      },
      "id": "Ion8Vc6h__O2",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      18.0\n",
              "1      15.0\n",
              "2      18.0\n",
              "3      16.0\n",
              "4      17.0\n",
              "       ... \n",
              "393    27.0\n",
              "394    44.0\n",
              "395    32.0\n",
              "396    28.0\n",
              "397    31.0\n",
              "Name: mpg, Length: 398, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# train_scaled와 train_target을 DataFrame으로 변환\n",
        "train_scaled_df = pd.DataFrame(train_scaled, columns=train_input.columns)\n",
        "train_target_df = pd.DataFrame(train_target, columns=['target'])\n",
        "\n",
        "# train_scaled_df와 train_target_df를 수평으로 결합하여 train_dataset 생성\n",
        "train_dataset = pd.concat([train_scaled_df, train_target_df], axis=1)\n"
      ],
      "metadata": {
        "id": "XZHNGfbJ-fnc"
      },
      "id": "XZHNGfbJ-fnc",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset = train_dataset.drop('target', axis = 1)\n",
        "train_dataset.rename(columns={'mpg': 'MPG'}, inplace=True)\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "lBiDbB9E-5VI",
        "outputId": "53a7d95f-e097-4e06-e8c6-9dadac3a3c4c"
      },
      "id": "lBiDbB9E-5VI",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cylinders  displacement  horsepower    weight  acceleration  model_year  \\\n",
              "0     1.527188      1.090196   -1.097464  0.552826     -1.319334   -1.696667   \n",
              "1    -0.850515     -0.922996    1.108529 -0.999667     -0.413182   -1.696667   \n",
              "2    -0.850515     -0.981350    0.504148 -1.124772      0.927922    1.638975   \n",
              "3    -0.850515     -0.981350    0.262395 -1.392854      0.275493    0.527094   \n",
              "4    -0.850515     -0.747936    1.320063 -0.327675     -0.231952   -0.306816   \n",
              "..         ...           ...         ...       ...           ...         ...   \n",
              "313  -1.444941     -1.185587    1.380501 -0.761372     -0.775643   -1.140727   \n",
              "314   1.527188      1.537573   -1.006807  1.822940     -1.138103   -0.862757   \n",
              "315  -0.850515     -0.563150    1.320063 -0.540949     -0.304444    0.527094   \n",
              "316  -0.850515     -1.000801    0.322833 -1.094985      0.601707    1.361005   \n",
              "317  -0.850515     -0.922996   -0.160672 -1.214133      1.942811   -0.862757   \n",
              "\n",
              "       Europe     Japan       USA target  \n",
              "0   -0.462321 -0.511766  0.788954    NaN  \n",
              "1   -0.462321  1.954017 -1.267500    NaN  \n",
              "2   -0.462321  1.954017 -1.267500    NaN  \n",
              "3   -0.462321  1.954017 -1.267500    NaN  \n",
              "4    2.163001 -0.511766 -1.267500    NaN  \n",
              "..        ...       ...       ...    ...  \n",
              "313 -0.462321  1.954017 -1.267500    NaN  \n",
              "314 -0.462321 -0.511766  0.788954    NaN  \n",
              "315 -0.462321  1.954017 -1.267500    NaN  \n",
              "316 -0.462321  1.954017 -1.267500    NaN  \n",
              "317  2.163001 -0.511766 -1.267500    NaN  \n",
              "\n",
              "[318 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4981713-21e1-45d6-81a1-8c0a9dcf4200\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cylinders</th>\n",
              "      <th>displacement</th>\n",
              "      <th>horsepower</th>\n",
              "      <th>weight</th>\n",
              "      <th>acceleration</th>\n",
              "      <th>model_year</th>\n",
              "      <th>Europe</th>\n",
              "      <th>Japan</th>\n",
              "      <th>USA</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.527188</td>\n",
              "      <td>1.090196</td>\n",
              "      <td>-1.097464</td>\n",
              "      <td>0.552826</td>\n",
              "      <td>-1.319334</td>\n",
              "      <td>-1.696667</td>\n",
              "      <td>-0.462321</td>\n",
              "      <td>-0.511766</td>\n",
              "      <td>0.788954</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.850515</td>\n",
              "      <td>-0.922996</td>\n",
              "      <td>1.108529</td>\n",
              "      <td>-0.999667</td>\n",
              "      <td>-0.413182</td>\n",
              "      <td>-1.696667</td>\n",
              "      <td>-0.462321</td>\n",
              "      <td>1.954017</td>\n",
              "      <td>-1.267500</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.850515</td>\n",
              "      <td>-0.981350</td>\n",
              "      <td>0.504148</td>\n",
              "      <td>-1.124772</td>\n",
              "      <td>0.927922</td>\n",
              "      <td>1.638975</td>\n",
              "      <td>-0.462321</td>\n",
              "      <td>1.954017</td>\n",
              "      <td>-1.267500</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.850515</td>\n",
              "      <td>-0.981350</td>\n",
              "      <td>0.262395</td>\n",
              "      <td>-1.392854</td>\n",
              "      <td>0.275493</td>\n",
              "      <td>0.527094</td>\n",
              "      <td>-0.462321</td>\n",
              "      <td>1.954017</td>\n",
              "      <td>-1.267500</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.850515</td>\n",
              "      <td>-0.747936</td>\n",
              "      <td>1.320063</td>\n",
              "      <td>-0.327675</td>\n",
              "      <td>-0.231952</td>\n",
              "      <td>-0.306816</td>\n",
              "      <td>2.163001</td>\n",
              "      <td>-0.511766</td>\n",
              "      <td>-1.267500</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>-1.444941</td>\n",
              "      <td>-1.185587</td>\n",
              "      <td>1.380501</td>\n",
              "      <td>-0.761372</td>\n",
              "      <td>-0.775643</td>\n",
              "      <td>-1.140727</td>\n",
              "      <td>-0.462321</td>\n",
              "      <td>1.954017</td>\n",
              "      <td>-1.267500</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>1.527188</td>\n",
              "      <td>1.537573</td>\n",
              "      <td>-1.006807</td>\n",
              "      <td>1.822940</td>\n",
              "      <td>-1.138103</td>\n",
              "      <td>-0.862757</td>\n",
              "      <td>-0.462321</td>\n",
              "      <td>-0.511766</td>\n",
              "      <td>0.788954</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>-0.850515</td>\n",
              "      <td>-0.563150</td>\n",
              "      <td>1.320063</td>\n",
              "      <td>-0.540949</td>\n",
              "      <td>-0.304444</td>\n",
              "      <td>0.527094</td>\n",
              "      <td>-0.462321</td>\n",
              "      <td>1.954017</td>\n",
              "      <td>-1.267500</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>-0.850515</td>\n",
              "      <td>-1.000801</td>\n",
              "      <td>0.322833</td>\n",
              "      <td>-1.094985</td>\n",
              "      <td>0.601707</td>\n",
              "      <td>1.361005</td>\n",
              "      <td>-0.462321</td>\n",
              "      <td>1.954017</td>\n",
              "      <td>-1.267500</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>-0.850515</td>\n",
              "      <td>-0.922996</td>\n",
              "      <td>-0.160672</td>\n",
              "      <td>-1.214133</td>\n",
              "      <td>1.942811</td>\n",
              "      <td>-0.862757</td>\n",
              "      <td>2.163001</td>\n",
              "      <td>-0.511766</td>\n",
              "      <td>-1.267500</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>318 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4981713-21e1-45d6-81a1-8c0a9dcf4200')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4981713-21e1-45d6-81a1-8c0a9dcf4200 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4981713-21e1-45d6-81a1-8c0a9dcf4200');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9f281752-cfb0-4062-84f9-5f0c2dd430cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f281752-cfb0-4062-84f9-5f0c2dd430cb')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9f281752-cfb0-4062-84f9-5f0c2dd430cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "5cfbb89c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "5cfbb89c",
        "outputId": "d6811659-4adc-4a74-d697-d50e2dfe7c7e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-ace956f983ac>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MPG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cylinders'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'displacement'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag_kind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kde'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3812\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3813\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3815\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6068\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6070\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6072\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6132\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6133\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6135\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['MPG'] not in index\""
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "sns.pairplot(train_dataset[['MPG', 'cylinders', 'displacement', 'weight']], diag_kind='kde')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 통계도 확인해보겠습니다. 각 특성이 매우 다른 범위를 포괄하고 있는 것에 주목하세요."
      ],
      "metadata": {
        "id": "GgF889pZ-VxS"
      },
      "id": "GgF889pZ-VxS"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "5255e7af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "5255e7af",
        "outputId": "53b0d594-99f4-4a8c-dd8f-3fb53f1b4e51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              count          mean       std       min       25%       50%  \\\n",
              "cylinders     318.0  1.508228e-16  1.001576 -1.444941 -0.850515 -0.850515   \n",
              "displacement  318.0 -4.468822e-17  1.001576 -1.205038 -0.908408 -0.422129   \n",
              "horsepower    318.0 -8.937644e-17  1.001576 -1.248559 -1.102752  0.413490   \n",
              "weight        318.0  2.401992e-16  1.001576 -1.615661 -0.892434 -0.174570   \n",
              "acceleration  318.0 -1.396507e-16  1.001576 -2.769176 -0.630659 -0.050722   \n",
              "model_year    318.0 -1.904835e-15  1.001576 -1.696667 -0.862757 -0.028846   \n",
              "Europe        318.0 -3.351617e-17  1.001576 -0.462321 -0.462321 -0.462321   \n",
              "Japan         318.0 -1.117206e-17  1.001576 -0.511766 -0.511766 -0.511766   \n",
              "USA           318.0  1.005485e-16  1.001576 -1.267500 -1.267500  0.788954   \n",
              "\n",
              "                   75%       max  \n",
              "cylinders     0.338337  1.527188  \n",
              "displacement  0.657409  2.558757  \n",
              "horsepower    0.980098  1.410720  \n",
              "weight        0.748526  2.586676  \n",
              "acceleration  0.601707  3.320162  \n",
              "model_year    0.805065  1.638975  \n",
              "Europe       -0.462321  2.163001  \n",
              "Japan        -0.511766  1.954017  \n",
              "USA           0.788954  0.788954  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7cf3ca87-3c6b-415e-ac49-b1772060ce0d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cylinders</th>\n",
              "      <td>318.0</td>\n",
              "      <td>1.508228e-16</td>\n",
              "      <td>1.001576</td>\n",
              "      <td>-1.444941</td>\n",
              "      <td>-0.850515</td>\n",
              "      <td>-0.850515</td>\n",
              "      <td>0.338337</td>\n",
              "      <td>1.527188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>displacement</th>\n",
              "      <td>318.0</td>\n",
              "      <td>-4.468822e-17</td>\n",
              "      <td>1.001576</td>\n",
              "      <td>-1.205038</td>\n",
              "      <td>-0.908408</td>\n",
              "      <td>-0.422129</td>\n",
              "      <td>0.657409</td>\n",
              "      <td>2.558757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>horsepower</th>\n",
              "      <td>318.0</td>\n",
              "      <td>-8.937644e-17</td>\n",
              "      <td>1.001576</td>\n",
              "      <td>-1.248559</td>\n",
              "      <td>-1.102752</td>\n",
              "      <td>0.413490</td>\n",
              "      <td>0.980098</td>\n",
              "      <td>1.410720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight</th>\n",
              "      <td>318.0</td>\n",
              "      <td>2.401992e-16</td>\n",
              "      <td>1.001576</td>\n",
              "      <td>-1.615661</td>\n",
              "      <td>-0.892434</td>\n",
              "      <td>-0.174570</td>\n",
              "      <td>0.748526</td>\n",
              "      <td>2.586676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acceleration</th>\n",
              "      <td>318.0</td>\n",
              "      <td>-1.396507e-16</td>\n",
              "      <td>1.001576</td>\n",
              "      <td>-2.769176</td>\n",
              "      <td>-0.630659</td>\n",
              "      <td>-0.050722</td>\n",
              "      <td>0.601707</td>\n",
              "      <td>3.320162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_year</th>\n",
              "      <td>318.0</td>\n",
              "      <td>-1.904835e-15</td>\n",
              "      <td>1.001576</td>\n",
              "      <td>-1.696667</td>\n",
              "      <td>-0.862757</td>\n",
              "      <td>-0.028846</td>\n",
              "      <td>0.805065</td>\n",
              "      <td>1.638975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Europe</th>\n",
              "      <td>318.0</td>\n",
              "      <td>-3.351617e-17</td>\n",
              "      <td>1.001576</td>\n",
              "      <td>-0.462321</td>\n",
              "      <td>-0.462321</td>\n",
              "      <td>-0.462321</td>\n",
              "      <td>-0.462321</td>\n",
              "      <td>2.163001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Japan</th>\n",
              "      <td>318.0</td>\n",
              "      <td>-1.117206e-17</td>\n",
              "      <td>1.001576</td>\n",
              "      <td>-0.511766</td>\n",
              "      <td>-0.511766</td>\n",
              "      <td>-0.511766</td>\n",
              "      <td>-0.511766</td>\n",
              "      <td>1.954017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>USA</th>\n",
              "      <td>318.0</td>\n",
              "      <td>1.005485e-16</td>\n",
              "      <td>1.001576</td>\n",
              "      <td>-1.267500</td>\n",
              "      <td>-1.267500</td>\n",
              "      <td>0.788954</td>\n",
              "      <td>0.788954</td>\n",
              "      <td>0.788954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7cf3ca87-3c6b-415e-ac49-b1772060ce0d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7cf3ca87-3c6b-415e-ac49-b1772060ce0d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7cf3ca87-3c6b-415e-ac49-b1772060ce0d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4e62e565-6c18-4006-bc19-d0be3e568992\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e62e565-6c18-4006-bc19-d0be3e568992')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4e62e565-6c18-4006-bc19-d0be3e568992 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "train_dataset.describe().transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 정규화\n",
        "\n",
        "통계 표에서 각 특성의 범위가 얼마나 다른지 쉽게 알 수 있습니다."
      ],
      "metadata": {
        "id": "fkgcLNh6AYtx"
      },
      "id": "fkgcLNh6AYtx"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "bc0006cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "bc0006cf",
        "outputId": "6b284588-4df6-4e18-b72e-b4382181da40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      mean       std\n",
              "cylinders     1.508228e-16  1.001576\n",
              "displacement -4.468822e-17  1.001576\n",
              "horsepower   -8.937644e-17  1.001576\n",
              "weight        2.401992e-16  1.001576\n",
              "acceleration -1.396507e-16  1.001576\n",
              "model_year   -1.904835e-15  1.001576\n",
              "Europe       -3.351617e-17  1.001576\n",
              "Japan        -1.117206e-17  1.001576\n",
              "USA           1.005485e-16  1.001576"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd62cdda-4145-4c06-aac7-81033f77fe18\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cylinders</th>\n",
              "      <td>1.508228e-16</td>\n",
              "      <td>1.001576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>displacement</th>\n",
              "      <td>-4.468822e-17</td>\n",
              "      <td>1.001576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>horsepower</th>\n",
              "      <td>-8.937644e-17</td>\n",
              "      <td>1.001576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight</th>\n",
              "      <td>2.401992e-16</td>\n",
              "      <td>1.001576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acceleration</th>\n",
              "      <td>-1.396507e-16</td>\n",
              "      <td>1.001576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_year</th>\n",
              "      <td>-1.904835e-15</td>\n",
              "      <td>1.001576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Europe</th>\n",
              "      <td>-3.351617e-17</td>\n",
              "      <td>1.001576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Japan</th>\n",
              "      <td>-1.117206e-17</td>\n",
              "      <td>1.001576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>USA</th>\n",
              "      <td>1.005485e-16</td>\n",
              "      <td>1.001576</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd62cdda-4145-4c06-aac7-81033f77fe18')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd62cdda-4145-4c06-aac7-81033f77fe18 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd62cdda-4145-4c06-aac7-81033f77fe18');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0c7a7089-bb9c-4b08-9e2c-0f258f87d971\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c7a7089-bb9c-4b08-9e2c-0f258f87d971')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0c7a7089-bb9c-4b08-9e2c-0f258f87d971 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "train_dataset.describe().transpose()[['mean', 'std']]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "특성의 스케일과 범위가 다르면 정규화(normalization)하는 것이 권장됩니다. 특성을 정규화하지 않아도 모델이 *수렴할 수 있지만*, 훈련시키기 어렵고 입력 단위에 의존적인 모델이 만들어집니다.\n",
        "\n",
        "이것이 중요한 한 가지 이유는 특성에 모델 가중치가 곱해지기 때문입니다. 따라서 출력의 스케일과 그래디언트의 스케일은 입력 스케일의 영향을 받습니다.\n",
        "\n",
        "모델은 특성 정규화 없이 수렴할 *수도* 있지만 정규화는 훈련을 훨씬 더 안정적으로 만듭니다.\n",
        "\n",
        "참고: 원-핫 기능을 정규화하는 데에는 이점이 없습니다. 여기서는 단순성을 위해 수행했습니다."
      ],
      "metadata": {
        "id": "9x34-xLJAgy6"
      },
      "id": "9x34-xLJAgy6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정규화 레이어\n",
        "\n",
        "`tf.keras.layers.Normalization`은 모델에 특성 정규화를 추가하는 깔끔하고 간단한 방법입니다.\n",
        "\n",
        "첫 번째 단계는 레이어를 만드는 것입니다."
      ],
      "metadata": {
        "id": "wZAM7r6YMhif"
      },
      "id": "wZAM7r6YMhif"
    },
    {
      "cell_type": "code",
      "source": [
        "from  tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)"
      ],
      "metadata": {
        "id": "5H-S3vn7AUyN"
      },
      "id": "5H-S3vn7AUyN",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "\n",
        "\n",
        "train_labels = train_features.pop('MPG')\n",
        "test_labels = test_features.pop('MPG')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "mtmMDUO6MWCT",
        "outputId": "292d2f01-af81-416f-dee7-6095ed7bd7cb"
      },
      "id": "mtmMDUO6MWCT",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-9ee58476f7ae>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MPG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그런 다음 `Normalization.adapt`를 호출하여 전처리 레이어의 상태를 데이터에 맞춥니다."
      ],
      "metadata": {
        "id": "Hs7jSCzCMmzS"
      },
      "id": "Hs7jSCzCMmzS"
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer.adapt(np.array(train_features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "UuehGydkAnid",
        "outputId": "dddbf173-1d2b-49c7-c249-d83c4b7c1616"
      },
      "id": "UuehGydkAnid",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-87f1bea74834>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/normalization.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    285\u001b[0m               \u001b[0margument\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0marray\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m     ):\n\u001b[1;32m    252\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    255\u001b[0m             \u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_modes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_single_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m   \"\"\"\n\u001b[0;32m--> 624\u001b[0;31m   return nest_util.map_structure(\n\u001b[0m\u001b[1;32m    625\u001b[0m       \u001b[0mnest_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1052\u001b[0m   \"\"\"\n\u001b[1;32m   1053\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_core_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_data_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1092\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_single_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "평균과 분산을 계산하고 레이어에 저장합니다."
      ],
      "metadata": {
        "id": "p8ZuIpZCMqVg"
      },
      "id": "p8ZuIpZCMqVg"
    },
    {
      "cell_type": "code",
      "source": [
        "print(normalizer.mean.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "yTNeviGjAonX",
        "outputId": "06415f62-9bee-422a-9f28-b30997d331d9"
      },
      "id": "yTNeviGjAonX",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-327a6b7a2a1a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Normalization' object has no attribute 'mean'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first = np.array(train_features[:1])\n",
        "\n",
        "with np.printoptions(precision=2, suppress=True):\n",
        "  print('First example:', first)\n",
        "  print()\n",
        "  print('Normalized:', normalizer(first).numpy())"
      ],
      "metadata": {
        "id": "vhpjV6tzMssA"
      },
      "id": "vhpjV6tzMssA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(units=1)\n",
        "])"
      ],
      "metadata": {
        "id": "f2YeYB9sMwdr"
      },
      "id": "f2YeYB9sMwdr",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.predict(train_features[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "oFJYSPvDM0QR",
        "outputId": "25670960-4292-4961-8ee6-da8455f1953e"
      },
      "id": "oFJYSPvDM0QR",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-34a39df2b575>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.layers[1].kernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "8WbWL3rvM1l-",
        "outputId": "dd91ac29-43b2-47d5-82c9-522ddf5936c6"
      },
      "id": "8WbWL3rvM1l-",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-097a101b27b4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Dense' object has no attribute 'kernel'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')"
      ],
      "metadata": {
        "id": "oaKVwj5GM2-t"
      },
      "id": "oaKVwj5GM2-t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = linear_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    epochs=100,\n",
        "    # Suppress logging.\n",
        "    verbose=0,\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    validation_split = 0.2)"
      ],
      "metadata": {
        "id": "tIrs4qKOM4LT"
      },
      "id": "tIrs4qKOM4LT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q2_aHTHMM5GH"
      },
      "id": "q2_aHTHMM5GH",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}